{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Node Classifier Explainer Mutag.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPZHMfthl2dCWlKTaf3e9C+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KingGuzman/Node-Classifier-Explainer/blob/main/Node_Classifier_Explainer_Mutag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run all the cells one after another"
      ],
      "metadata": {
        "id": "4_xjsQ6oxzYL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1op-CbyLuN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dfe1d81-3ae0-4bd1-97ea-2ae78a8e76ed"
      },
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def visualize(h, color):\n",
        "    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())\n",
        "\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
        "    plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 9.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 9.3 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3pv0RhCNxyPV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MlFlxfL5dgn2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "import torch_geometric as torch_geometric\n",
        "import math\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "#from tensorboardX import SummaryWriter\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.nn import GCNConv,GINConv\n",
        "from torch.distributions import Bernoulli,Categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imGrKO5YH11-"
      },
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import networkx as nx\n",
        "\n",
        "import math\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "import time\n",
        "from datetime import datetime\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.colors as colors\n",
        "\n",
        "\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "#from tensorboardX import SummaryWriter\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.nn import GCNConv,GINConv\n",
        "from torch.distributions import Bernoulli,Categorical\n",
        "import matplotlib.cm as cmx\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask=random.sample(range(0, 3000), 3000)\n",
        "test_mask=random.sample(range(3001,3371),370)"
      ],
      "metadata": {
        "id": "cQ-_fTOqf1YN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1=torch_geometric.datasets.TUDataset(root='/tmp/Entities',name=\"MUTAG\")\n",
        "dataset2=torch_geometric.datasets.TUDataset(root='/tmp/Entities1',name=\"MUTAG\",transform=torch_geometric.transforms.OneHotDegree(4,cat=False))\n",
        "#dataset1=torch_geometric.datasets.Coauthor(root='/tmp/Coauthor',name=\"CS\")\n",
        "\n",
        "dir(dataset2)\n",
        "#print(dataset.url)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqB8WgungXuB",
        "outputId": "856d0301-4ac1-45de-8bfb-a872a9c696a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Extracting /tmp/Entities/MUTAG/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n",
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Extracting /tmp/Entities1/MUTAG/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__add__',\n",
              " '__class__',\n",
              " '__class_getitem__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__orig_bases__',\n",
              " '__parameters__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_data_list',\n",
              " '_download',\n",
              " '_indices',\n",
              " '_process',\n",
              " 'cleaned',\n",
              " 'cleaned_url',\n",
              " 'collate',\n",
              " 'copy',\n",
              " 'data',\n",
              " 'download',\n",
              " 'get',\n",
              " 'index_select',\n",
              " 'indices',\n",
              " 'len',\n",
              " 'name',\n",
              " 'num_classes',\n",
              " 'num_edge_attributes',\n",
              " 'num_edge_features',\n",
              " 'num_edge_labels',\n",
              " 'num_features',\n",
              " 'num_node_attributes',\n",
              " 'num_node_features',\n",
              " 'num_node_labels',\n",
              " 'pre_filter',\n",
              " 'pre_transform',\n",
              " 'process',\n",
              " 'processed_dir',\n",
              " 'processed_file_names',\n",
              " 'processed_paths',\n",
              " 'raw_dir',\n",
              " 'raw_file_names',\n",
              " 'raw_paths',\n",
              " 'root',\n",
              " 'shuffle',\n",
              " 'sizes',\n",
              " 'slices',\n",
              " 'transform',\n",
              " 'url']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dat=dataset2.data\n",
        "print(dat)\n",
        "\n",
        "\n",
        "print(dat.edge_index.size())\n",
        "\n",
        "print(dat.y)\n",
        "x=dat.x\n",
        "print(x)\n",
        "print(len(x[0]))\n",
        "x1=torch.argmax(x,dim=1)\n",
        "\n",
        "newdatx=x\n",
        "print(len(newdatx))\n",
        "print(x1[0:300])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV4Dewlvm4B0",
        "outputId": "6b408f0d-f306-41db-c0c6-e6b603f5c9c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[3371, 7], edge_index=[2, 7442], edge_attr=[7442, 4], y=[188])\n",
            "torch.Size([2, 7442])\n",
            "tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
            "        0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
            "        1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
            "        1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])\n",
            "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.]])\n",
            "7\n",
            "3371\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 3, 1, 2, 2,\n",
            "        3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1,\n",
            "        2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
            "        2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 0, 1, 0,\n",
            "        0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2,\n",
            "        2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqcid0jmnLVC",
        "outputId": "8766db79-18a8-4e09-c7b3-1364e3450a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dat=dataset1.data\n",
        "print(dat)\n",
        "#print(dat.y)\n",
        "x=dat.x\n",
        "print(x)\n",
        "print(len(x[0]))\n",
        "x1=torch.argmax(x,dim=1)\n",
        "newdatx=x\n",
        "newdaty=x1\n",
        "print(x1[0:30])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cP-pebDr0le",
        "outputId": "45cc7fcd-052c-4d25-9a13-a1332fd8502f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[3371, 7], edge_index=[2, 7442], edge_attr=[7442, 4], y=[188])\n",
            "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 1.,  ..., 0., 0., 0.]])\n",
            "7\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 1, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cont=np.loadtxt(\"/content/MUTAG_A.txt\",dtype='str')\n",
        "with open(\"/content/MUTAG_A.txt\") as infile, open(\"outfile.txt\", \"w\") as outfile:\n",
        "    for line in infile:\n",
        "        outfile.write(line.replace(\",\", \" \"))\n",
        "\n",
        "\n",
        "cont=np.loadtxt(\"/content/outfile.txt\",dtype=int)\n",
        "\n",
        "cont=cont-1\n",
        "print(cont)\n",
        "edgeind=torch.from_numpy(cont)\n",
        "edgeind=torch.transpose(edgeind,0,1)\n",
        "edgeind=edgeind.long()\n",
        "\n",
        "print(len(edgeind[0]))\n",
        "print(edgeind[0][1:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erxvS4_GOrBq",
        "outputId": "bd21e94c-a68b-49cc-d4b9-1d850a2c2148"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   1    0]\n",
            " [   0    1]\n",
            " [   2    1]\n",
            " ...\n",
            " [3368 3369]\n",
            " [3370 3368]\n",
            " [3368 3370]]\n",
            "7442\n",
            "tensor([0, 2, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(edgeind.size())\n",
        "print(type(edgeind))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA0pLu2avNli",
        "outputId": "0ddd5314-8c91-422f-ed6f-07613dda3da1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 7442])\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newdat=Data(x=newdatx,edge_index=edgeind,y=newdaty)\n",
        "print(newdat.edge_index[0][1:5])\n",
        "print(len(newdat.x))\n",
        "print(len(newdat.y))\n",
        "\n",
        "\n",
        "newdataset=[]\n",
        "newdataset.append(newdat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XL66fEF-4OH",
        "outputId": "7085c2c5-eed4-47db-d522-213fda599f52"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 2, 1, 3])\n",
            "3371\n",
            "3371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_nN_m_krJh7V"
      },
      "outputs": [],
      "source": [
        "class GNNStack(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, task='node'):\n",
        "        super(GNNStack, self).__init__()\n",
        "        self.task = task\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
        "        self.lns = nn.ModuleList()\n",
        "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
        "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
        "        for l in range(3):\n",
        "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
        "            self.lns.append(nn.LayerNorm(hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        self.post_mp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25), \n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "        if not (self.task == 'node' or self.task == 'graph'):\n",
        "            raise RuntimeError('Unknown task.')\n",
        "\n",
        "        self.dropout = 0.25\n",
        "        self.num_layers = 3\n",
        "\n",
        "    def build_conv_model(self, input_dim, hidden_dim):\n",
        "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
        "        if self.task == 'node':\n",
        "            return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
        "        else:\n",
        "            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
        "                                  nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        if data.num_node_features == 0:\n",
        "          x = torch.ones(data.num_nodes, 1)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            emb = x\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "            if not i == self.num_layers - 1:\n",
        "                x = self.lns[i](x)\n",
        "\n",
        "        if self.task == 'graph':\n",
        "            x = pyg_nn.global_mean_pool(x, batch)\n",
        "\n",
        "        x = self.post_mp(x)\n",
        "        reward=F.softmax(x,dim=1)\n",
        "        \n",
        "\n",
        "        return emb,reward,F.log_softmax(x, dim=1)\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)\n",
        "        #F.nll_loss(pred, label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, task):\n",
        "    torch.manual_seed(2)\n",
        "    if task == 'graph':\n",
        "        data_size = len(dataset)\n",
        "        loader = DataLoader(dataset[:int(data_size * 0.8)], batch_size=64, shuffle=True)\n",
        "        test_loader = DataLoader(dataset[int(data_size * 0.8):], batch_size=64, shuffle=True)\n",
        "    else:\n",
        "         loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(max(num_node_features, 1), 64, 7, task=task)\n",
        "    opt = optim.Adam(model.parameters(), lr=0.01)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model=model.to(device)\n",
        "    \n",
        "    # train\n",
        "    for epoch in range(250):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in loader:\n",
        "            #print(batch.train_mask, '----')\n",
        "            opt.zero_grad()\n",
        "            batch=batch.to(device)\n",
        "            embedding,reward,pred = model(batch)\n",
        "            \n",
        "            label = batch.y\n",
        "            #label=label.float()\n",
        "            #labelonehot=torch.nn.functional.one_hot(label,num_classes=2)\n",
        "            #labelonehot=labelonehot.float()\n",
        "            #labelonehot=torch.zeros_like(label)\n",
        "            #labelonehot=labelonehot.scatter(1,label, 1)\n",
        "            #pred = pred[batch.train_mask]\n",
        "            #label = label[batch.train_mask]\n",
        "            \n",
        "            loss = model.loss(pred[train_mask], label[train_mask])\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "        total_loss /= len(loader.dataset)\n",
        "        #writer.add_scalar(\"loss\", total_loss, epoch)\n",
        "\n",
        "        if epoch % 20 == 0:\n",
        "          print(epoch)\n",
        "          #print(reward)\n",
        "          print(loss*100)\n",
        "          #print(pred.shape)\n",
        "            #test_acc = test(test_loader, model)\n",
        "            #print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(\n",
        "                #epoch, total_loss, test_acc))\n",
        "            #writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "MMqiUZLl_Wv8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(loader, model, task='node'):\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total=0\n",
        "    for data in loader:\n",
        "        with torch.no_grad():\n",
        "            emb, reward,pred = model(data)\n",
        "            pred = pred.argmax(dim=1)\n",
        "            label = data.y\n",
        "            \n",
        "\n",
        "        #if task == 'node':\n",
        "            #mask = data.val_mask if is_validation else data.test_mask\n",
        "            # node classification: only evaluate on nodes in test set\n",
        "            #pred = pred[mask]\n",
        "            #label = data.y[mask]\n",
        "            \n",
        "        correct += pred.eq(label).sum().item()\n",
        "        total+=len(label)\n",
        "    \n",
        "    #if task == 'graph':\n",
        "     #   total = len(loader.dataset) \n",
        "    #else:\n",
        "        #total = len(loader.dataset)*50\n",
        "        \n",
        "    return correct / total,total,correct"
      ],
      "metadata": {
        "id": "IcM5KzB2_b2E"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(newdataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6JFq6gt1wO8",
        "outputId": "c69a4aa7-98c1-4584-8097-b3087f60e2da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Data(x=[3371, 7], edge_index=[2, 7442], y=[3371])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for finding nodes of any label you want to. Not necessary to run"
      ],
      "metadata": {
        "id": "cX85jmtxq5M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "laba=newdataset[0]\n",
        "\n",
        "laba1=laba.y.tolist()\n",
        "print(laba1)\n",
        "f=[]\n",
        "for i in range(len(laba1)):\n",
        "  if (laba1[i]==1):\n",
        "    f.append(i)\n",
        "print(f)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QykCu21Bq0BX",
        "outputId": "150b29bb-4b17-4473-8e29-e10afe46c2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 3, 1, 2, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 6, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 3, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 3, 3, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 5, 5, 2, 0, 0, 0, 0, 0, 0, 5, 1, 2, 2, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 5, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 5, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 5, 5, 1, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 5, 5, 5, 1, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 5, 1, 2, 2, 5, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 1, 0, 0, 1, 0, 0, 2, 1, 2, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 6, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 5, 5, 2, 0, 0, 0, 0, 0, 0, 5, 5, 1, 2, 2, 5, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 0, 0, 1, 0, 0, 0, 0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 3, 1, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2]\n",
            "[14, 23, 27, 37, 40, 59, 69, 89, 92, 95, 98, 108, 134, 140, 142, 146, 163, 180, 199, 200, 219, 222, 226, 234, 235, 254, 273, 276, 285, 286, 289, 304, 315, 317, 327, 335, 344, 353, 362, 393, 420, 429, 446, 449, 473, 482, 499, 510, 513, 536, 555, 558, 573, 576, 579, 582, 591, 605, 618, 627, 635, 649, 666, 681, 692, 696, 709, 718, 730, 738, 739, 758, 775, 784, 787, 806, 827, 832, 849, 858, 861, 868, 869, 880, 885, 908, 911, 934, 937, 946, 956, 965, 989, 998, 1005, 1006, 1021, 1024, 1027, 1043, 1075, 1088, 1091, 1094, 1103, 1120, 1124, 1134, 1135, 1142, 1145, 1154, 1165, 1178, 1181, 1190, 1199, 1217, 1240, 1249, 1259, 1268, 1275, 1296, 1299, 1315, 1330, 1331, 1354, 1369, 1372, 1381, 1397, 1400, 1414, 1431, 1450, 1459, 1462, 1481, 1484, 1487, 1494, 1503, 1514, 1537, 1560, 1576, 1588, 1592, 1599, 1603, 1624, 1643, 1666, 1691, 1710, 1723, 1726, 1729, 1748, 1751, 1754, 1772, 1779, 1785, 1800, 1809, 1816, 1839, 1856, 1859, 1862, 1865, 1884, 1907, 1919, 1922, 1924, 1944, 1963, 1966, 1969, 1988, 2013, 2016, 2025, 2034, 2037, 2040, 2051, 2066, 2075, 2078, 2081, 2094, 2097, 2104, 2116, 2126, 2135, 2138, 2157, 2176, 2179, 2182, 2186, 2194, 2195, 2214, 2217, 2220, 2241, 2258, 2269, 2288, 2297, 2300, 2307, 2308, 2317, 2326, 2329, 2342, 2353, 2356, 2359, 2360, 2369, 2388, 2399, 2418, 2439, 2442, 2451, 2473, 2492, 2495, 2499, 2500, 2508, 2518, 2521, 2532, 2535, 2546, 2566, 2578, 2588, 2598, 2605, 2620, 2623, 2626, 2633, 2634, 2649, 2658, 2661, 2668, 2669, 2674, 2677, 2681, 2688, 2689, 2693, 2712, 2715, 2728, 2737, 2739, 2740, 2753, 2756, 2765, 2768, 2788, 2794, 2808, 2827, 2837, 2840, 2842, 2865, 2868, 2883, 2886, 2889, 2892, 2911, 2914, 2933, 2936, 2955, 2978, 2997, 3000, 3011, 3020, 3023, 3033, 3040, 3041, 3050, 3053, 3062, 3065, 3073, 3074, 3077, 3092, 3095, 3098, 3117, 3120, 3140, 3151, 3163, 3166, 3169, 3174, 3178, 3179, 3187, 3206, 3209, 3234, 3237, 3246, 3247, 3250, 3261, 3262, 3281, 3284, 3303, 3306, 3316, 3319, 3328, 3333, 3352, 3359, 3368]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Node Classifier Training Code"
      ],
      "metadata": {
        "id": "PBckMzor25Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = 'node'\n",
        "num_node_features=7\n",
        "\n",
        "model = train(newdataset, task)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gx2Vkdk_fPo",
        "outputId": "51399822-054f-4b6a-9274-d4e64e3d614f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "tensor(184.7082, grad_fn=<MulBackward0>)\n",
            "20\n",
            "tensor(14.3967, grad_fn=<MulBackward0>)\n",
            "40\n",
            "tensor(7.6119, grad_fn=<MulBackward0>)\n",
            "60\n",
            "tensor(5.7904, grad_fn=<MulBackward0>)\n",
            "80\n",
            "tensor(4.8927, grad_fn=<MulBackward0>)\n",
            "100\n",
            "tensor(4.4260, grad_fn=<MulBackward0>)\n",
            "120\n",
            "tensor(4.2981, grad_fn=<MulBackward0>)\n",
            "140\n",
            "tensor(3.4687, grad_fn=<MulBackward0>)\n",
            "160\n",
            "tensor(3.3538, grad_fn=<MulBackward0>)\n",
            "180\n",
            "tensor(2.8423, grad_fn=<MulBackward0>)\n",
            "200\n",
            "tensor(2.1948, grad_fn=<MulBackward0>)\n",
            "220\n",
            "tensor(2.6317, grad_fn=<MulBackward0>)\n",
            "240\n",
            "tensor(1.9734, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding,reward,pred = model(newdat)\n",
        "pred=pred.argmax(dim=1)\n",
        "label=newdat.y\n",
        "correct=pred[test_mask].eq(label[test_mask]).sum().item()\n",
        "total=len(label[test_mask])\n",
        "accuracy=correct/total\n",
        "print(accuracy)\n",
        "print(total)"
      ],
      "metadata": {
        "id": "8wo2w4rqHoBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e24fb0df-316c-4e8b-c593-8f237a72973d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9756756756756757\n",
            "370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCNPolicy(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(GCNPolicy, self).__init__()\n",
        "    self.conv1=GCNConv(num_gennode_features,num_hidden_features)\n",
        "    self.conv2=GCNConv(num_hidden_features,num_hidden_features)\n",
        "    self.conv3=GCNConv(num_hidden_features,num_gennode_features)\n",
        "    self.lin1=nn.Sequential(nn.Linear((num_gennodes)*num_gennode_features, num_hidden_features),nn.ReLU(),nn.Linear(num_hidden_features,num_hidden_features),nn.ReLU(),nn.Linear(num_hidden_features,num_gennodes-1))\n",
        "  def forward(self,gendata):\n",
        "        x, edge_index = gendata.x, gendata.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        #x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x=F.relu(x)\n",
        "        x=self.conv3(x,edge_index)\n",
        "        x=F.relu(x)\n",
        "        x=torch.flatten(x)\n",
        "        x=self.lin1(x)\n",
        "        x=F.softmax(x/temp)\n",
        "        #x=Bernoulli(x)\n",
        "        #action=x.sample()\n",
        "       \n",
        "        return x"
      ],
      "metadata": {
        "id": "bZHN8k0qEAhq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining colormap before plotting"
      ],
      "metadata": {
        "id": "O0ennbReF0GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cmap = colors.ListedColormap(['blue', 'black','red','yellow','orange','green','purple'])\n",
        "ColorLegend = {'Carbon': 0,'Nitrogen': 1,'Oxygen': 2,'Fluorine': 3,'Iodine':4,'Chlorine':5,'Bromine':6}\n",
        "cNorm  = colors.Normalize(vmin=0, vmax=6)\n",
        "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
        "print(cmap.colors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWRQhMRiFzc0",
        "outputId": "973a5743-b1a6-471c-f1ac-2aad582efdc6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['blue', 'black', 'red', 'yellow', 'orange', 'green', 'purple']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Templates and Query nodes \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6deVF64T8Y1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nodeid=[2050,492,452,728]\n",
        "graphlist=[]\n",
        "lisdataset=[]\n",
        "classid=[]\n",
        "for ind in range(len(nodeid)):\n",
        "  keepnodes=torch.tensor(5)\n",
        "  subgraphy=torch.tensor(5)\n",
        "  subgraphx=torch.tensor(5)\n",
        "  newfeatures=torch.tensor(5)\n",
        "  newy=torch.tensor(5)\n",
        "  count=0\n",
        "  count1=0\n",
        "  subgraphind=[]\n",
        "  edgeind=newdat.edge_index\n",
        "\n",
        "  subgraph=pyg_utils.k_hop_subgraph(nodeid[ind],16,edgeind,relabel_nodes=False)\n",
        "  subgraph1=pyg_utils.k_hop_subgraph(nodeid[ind],16,edgeind,relabel_nodes=True)\n",
        "  if count==0:\n",
        "    keepnodes=subgraph[0]\n",
        "    count=1\n",
        "  else:\n",
        "\n",
        "    keepnodes=torch.cat([keepnodes,subgraph[0]],dim=0)\n",
        "  print(subgraph[0])\n",
        "\n",
        "  #print(len(subgraph[0]))\n",
        "\n",
        "  print(subgraph[2])\n",
        "  x=newdat.x\n",
        "  y=newdat.y\n",
        "  #print(y)\n",
        "  features=[x[i] for i in subgraph[0]]\n",
        "  features=torch.stack(features)\n",
        "  #print(subgraphx)\n",
        "  subgraphind=subgraph1[1]\n",
        "  print(subgraphind)\n",
        "  k=[y[i] for i in subgraph[0]]\n",
        "  k=torch.stack(k)\n",
        "  if count1==0:\n",
        "    subgraphy=k\n",
        "    subgraphx=features\n",
        "    count1=1\n",
        "  else:\n",
        "    subgraphy=torch.cat([subgraphy,k],dim=0)\n",
        "    subgraphx=torch.cat([subgraphx,features],dim=0)\n",
        "    #lis=list(set(list(flatten(L))))\n",
        "  print(subgraphx.shape)\n",
        "  print(subgraphy)\n",
        "  nodelabels=subgraphy\n",
        "  #print(len(subgraphy))\n",
        "  newdata=Data(x=subgraphx,edge_index=subgraphind,y=subgraphy)\n",
        "  G=pyg_utils.to_networkx(newdata)\n",
        "  v=torch.sort(keepnodes)\n",
        "  newkeep=v[0]\n",
        "  x=newdat.x\n",
        "  y=newdat.y\n",
        "  #print(y)\n",
        "  newfeatures=[x[i] for i in newkeep]\n",
        "  newfeatures=torch.stack(newfeatures)\n",
        "  newy=[y[i] for i in newkeep]\n",
        "  newy=torch.stack(newy)\n",
        "\n",
        "\n",
        "  print(v[0])\n",
        "  subgraphedge=pyg_utils.subgraph(keepnodes,edgeind,relabel_nodes=True)\n",
        "  print(subgraphedge[0])\n",
        "  subgraphdata=Data(x=newfeatures,edge_index=subgraphedge[0],y=newy)\n",
        "  H=pyg_utils.to_networkx(subgraphdata,to_undirected=True)\n",
        "  print(subgraphdata.y)\n",
        "\n",
        "  nodelabels=subgraphdata.y\n",
        "  print(nodelabels)\n",
        "  plt.figure(ind+1)\n",
        "  nx.draw_networkx(H,node_size=150,node_color=nodelabels,cmap=cmap,vmin=0,vmax=6,with_labels=False)\n",
        "  deletedsubgraphnodes=newkeep[0:len(newkeep)-1]\n",
        "  deletedsubgraphind1=pyg_utils.subgraph(deletedsubgraphnodes,newdat.edge_index)\n",
        "  deletedsubgraphind2=pyg_utils.subgraph(deletedsubgraphnodes,deletedsubgraphind1[0],relabel_nodes=True)\n",
        "  deletedsubgraphdata=Data(x=newfeatures,edge_index=deletedsubgraphind2[0],y=newy)\n",
        "  L=pyg_utils.to_networkx(deletedsubgraphdata,to_undirected=True)\n",
        "  nodelabels=deletedsubgraphdata.y\n",
        "  lisdataset.append(deletedsubgraphdata)\n",
        "  graphlist.append(L)\n",
        "  classid.append(nodelabels[-1])\n",
        "  plt.figure(10*(ind+1))\n",
        "  nx.draw_networkx(L,node_size=70,node_color=nodelabels,cmap=cmap,vmin=0,vmax=6,with_labels=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4fgiO7ms8dKP",
        "outputId": "8f524015-fd00-4552-b9ae-ca3264d27e50"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053])\n",
            "tensor([7])\n",
            "tensor([[ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  5,  0,  6,  5,  7,  6,  8,  2,\n",
            "          9,  8, 10,  8],\n",
            "        [ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  0,  5,  5,  6,  6,  7,  2,  8,\n",
            "          8,  9,  8, 10]])\n",
            "torch.Size([11, 7])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2])\n",
            "tensor([2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053])\n",
            "tensor([[ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  5,  0,  6,  5,  7,  6,  8,  2,\n",
            "          9,  8, 10,  8],\n",
            "        [ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  0,  5,  5,  6,  6,  7,  2,  8,\n",
            "          8,  9,  8, 10]])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2])\n",
            "tensor([476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
            "        490, 491, 492])\n",
            "tensor([16])\n",
            "tensor([[ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  5,  0,  6,  5,  7,  6,  8,  6,\n",
            "          9,  3, 10,  9, 11, 10, 11,  2, 12, 11, 13, 12, 14, 13, 15, 14, 15, 10,\n",
            "         16, 14],\n",
            "        [ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  0,  5,  5,  6,  6,  7,  6,  8,\n",
            "          3,  9,  9, 10, 10, 11,  2, 11, 11, 12, 12, 13, 13, 14, 14, 15, 10, 15,\n",
            "         14, 16]])\n",
            "torch.Size([17, 7])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3])\n",
            "tensor([476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
            "        490, 491, 492])\n",
            "tensor([[ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  5,  0,  6,  5,  7,  6,  8,  6,\n",
            "          9,  3, 10,  9, 11, 10, 11,  2, 12, 11, 13, 12, 14, 13, 15, 14, 15, 10,\n",
            "         16, 14],\n",
            "        [ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  0,  5,  5,  6,  6,  7,  6,  8,\n",
            "          3,  9,  9, 10, 10, 11,  2, 11, 11, 12, 12, 13, 13, 14, 14, 15, 10, 15,\n",
            "         14, 16]])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3])\n",
            "tensor([440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452])\n",
            "tensor([12])\n",
            "tensor([[ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  5,  0,  6,  5,  7,  6,  8,  6,\n",
            "          9,  3, 10,  9, 11,  9, 12,  2],\n",
            "        [ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  0,  5,  5,  6,  6,  7,  6,  8,\n",
            "          3,  9,  9, 10,  9, 11,  2, 12]])\n",
            "torch.Size([13, 7])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 5])\n",
            "tensor([440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452])\n",
            "tensor([[ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  5,  0,  6,  5,  7,  6,  8,  6,\n",
            "          9,  3, 10,  9, 11,  9, 12,  2],\n",
            "        [ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  0,  5,  5,  6,  6,  7,  6,  8,\n",
            "          3,  9,  9, 10,  9, 11,  2, 12]])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 5])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 5])\n",
            "tensor([712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725,\n",
            "        726, 727, 728])\n",
            "tensor([16])\n",
            "tensor([[ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  5,  0,  6,  5,  7,  6,  8,  6,\n",
            "          9,  3, 10,  9, 11, 10, 11,  2, 12, 11, 13, 12, 14, 13, 15, 14, 15, 10,\n",
            "         16, 14],\n",
            "        [ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  0,  5,  5,  6,  6,  7,  6,  8,\n",
            "          3,  9,  9, 10, 10, 11,  2, 11, 11, 12, 12, 13, 13, 14, 14, 15, 10, 15,\n",
            "         14, 16]])\n",
            "torch.Size([17, 7])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 6])\n",
            "tensor([712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725,\n",
            "        726, 727, 728])\n",
            "tensor([[ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  5,  0,  6,  5,  7,  6,  8,  6,\n",
            "          9,  3, 10,  9, 11, 10, 11,  2, 12, 11, 13, 12, 14, 13, 15, 14, 15, 10,\n",
            "         16, 14],\n",
            "        [ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  0,  5,  5,  6,  6,  7,  6,  8,\n",
            "          3,  9,  9, 10, 10, 11,  2, 11, 11, 12, 12, 13, 13, 14, 14, 15, 10, 15,\n",
            "         14, 16]])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 6])\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 6])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking class labels of query nodes in each template"
      ],
      "metadata": {
        "id": "xAhlZQgT3CLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classid)\n",
        "waok=lisdataset[0]\n",
        "print(waok)"
      ],
      "metadata": {
        "id": "8kUccs2YKw3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1ee81f-1785-412a-ee1e-71da91d6afd4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor(2), tensor(3), tensor(5), tensor(6)]\n",
            "Data(x=[11, 7], edge_index=[2, 20], y=[11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def takeFirst(elem):\n",
        "  return elem[0]"
      ],
      "metadata": {
        "id": "5M9c5Bttaqsv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for Neigborhood Generator below:-"
      ],
      "metadata": {
        "id": "80vkabw9gnXp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VGlh91dqRLAm",
        "outputId": "e4d77353-3a61-4387-bfda-6d67ff8631ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(9)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(2)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(6)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0988, 0.0987, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(2)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0988, 0.0987, 0.0993, 0.1015, 0.1004, 0.1011, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(9)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(7)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(3)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(5)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(5)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(0)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0988, 0.0987, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(3)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(4)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0988, 0.0987, 0.0993, 0.1015, 0.1004, 0.1011, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(5)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(2)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0988, 0.0987, 0.0993, 0.1015, 0.1004, 0.1011, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(7)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0988, 0.0987, 0.0993, 0.1015, 0.1004, 0.1011, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(0)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0988, 0.0988, 0.0993, 0.1015, 0.1004, 0.1012, 0.0999, 0.1000, 0.0994,\n",
            "        0.1007], grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(8)\n",
            "for loop newdegree counter\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0183, 0.1295, 0.0173, 0.0642, 0.0908, 0.0500, 0.0069, 0.0394, 0.0071,\n",
            "        0.0972, 0.0735, 0.0429, 0.0619, 0.0459, 0.1257, 0.1294],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(12)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0188, 0.1283, 0.0178, 0.0645, 0.0905, 0.0504, 0.0072, 0.0399, 0.0075,\n",
            "        0.0968, 0.0735, 0.0434, 0.0622, 0.0463, 0.1245, 0.1283],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(4)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0183, 0.1295, 0.0173, 0.0642, 0.0908, 0.0500, 0.0069, 0.0394, 0.0071,\n",
            "        0.0972, 0.0735, 0.0429, 0.0619, 0.0459, 0.1257, 0.1294],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(9)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0188, 0.1283, 0.0178, 0.0645, 0.0905, 0.0504, 0.0072, 0.0399, 0.0074,\n",
            "        0.0968, 0.0735, 0.0434, 0.0622, 0.0463, 0.1246, 0.1283],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(2)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0183, 0.1295, 0.0173, 0.0642, 0.0908, 0.0500, 0.0069, 0.0394, 0.0071,\n",
            "        0.0972, 0.0735, 0.0429, 0.0619, 0.0459, 0.1257, 0.1294],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(10)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0188, 0.1282, 0.0178, 0.0645, 0.0905, 0.0505, 0.0072, 0.0399, 0.0075,\n",
            "        0.0967, 0.0735, 0.0434, 0.0622, 0.0464, 0.1245, 0.1283],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(4)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0183, 0.1295, 0.0173, 0.0642, 0.0908, 0.0500, 0.0069, 0.0394, 0.0071,\n",
            "        0.0972, 0.0735, 0.0429, 0.0619, 0.0459, 0.1257, 0.1294],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(4)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0187, 0.1285, 0.0178, 0.0645, 0.0905, 0.0504, 0.0072, 0.0398, 0.0074,\n",
            "        0.0968, 0.0735, 0.0433, 0.0622, 0.0463, 0.1247, 0.1285],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0183, 0.1295, 0.0173, 0.0642, 0.0908, 0.0500, 0.0069, 0.0394, 0.0071,\n",
            "        0.0972, 0.0735, 0.0429, 0.0619, 0.0459, 0.1257, 0.1294],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0188, 0.1283, 0.0178, 0.0644, 0.0906, 0.0504, 0.0072, 0.0399, 0.0074,\n",
            "        0.0968, 0.0735, 0.0434, 0.0622, 0.0463, 0.1246, 0.1283],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(10)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0183, 0.1295, 0.0173, 0.0642, 0.0908, 0.0500, 0.0069, 0.0394, 0.0071,\n",
            "        0.0972, 0.0735, 0.0429, 0.0619, 0.0459, 0.1257, 0.1294],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(9)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0188, 0.1283, 0.0178, 0.0645, 0.0905, 0.0504, 0.0072, 0.0399, 0.0074,\n",
            "        0.0968, 0.0735, 0.0434, 0.0622, 0.0463, 0.1246, 0.1283],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(6)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0183, 0.1295, 0.0173, 0.0642, 0.0908, 0.0500, 0.0069, 0.0394, 0.0071,\n",
            "        0.0972, 0.0735, 0.0429, 0.0619, 0.0459, 0.1257, 0.1294],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0188, 0.1282, 0.0179, 0.0645, 0.0905, 0.0505, 0.0072, 0.0399, 0.0075,\n",
            "        0.0967, 0.0735, 0.0434, 0.0622, 0.0464, 0.1244, 0.1282],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0183, 0.1295, 0.0173, 0.0642, 0.0908, 0.0500, 0.0069, 0.0394, 0.0071,\n",
            "        0.0972, 0.0735, 0.0429, 0.0619, 0.0459, 0.1257, 0.1294],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(13)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0188, 0.1283, 0.0178, 0.0645, 0.0905, 0.0504, 0.0072, 0.0399, 0.0074,\n",
            "        0.0968, 0.0736, 0.0433, 0.0622, 0.0463, 0.1246, 0.1284],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(13)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0183, 0.1295, 0.0173, 0.0642, 0.0908, 0.0500, 0.0069, 0.0394, 0.0071,\n",
            "        0.0972, 0.0735, 0.0429, 0.0619, 0.0459, 0.1257, 0.1294],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(12)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0188, 0.1283, 0.0178, 0.0645, 0.0905, 0.0504, 0.0072, 0.0399, 0.0075,\n",
            "        0.0968, 0.0735, 0.0434, 0.0622, 0.0463, 0.1245, 0.1283],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(11)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.4297, grad_fn=<SubBackward0>), tensor(-0.5000, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-0.9356)\n",
            "return\n",
            "tensor(-0.6585)\n",
            "return\n",
            "tensor(0.2966)\n",
            "return\n",
            "tensor(-0.6585)\n",
            "return\n",
            "tensor(0.0017)\n",
            "return\n",
            "tensor(-0.6432)\n",
            "return\n",
            "tensor(-1.4664)\n",
            "return\n",
            "tensor(-0.6585)\n",
            "return\n",
            "tensor(0.0906)\n",
            "return\n",
            "tensor(-0.6585)\n",
            "return\n",
            "tensor(0.4999)\n",
            "return\n",
            "tensor(-0.6585)\n",
            "return\n",
            "tensor(0.1685)\n",
            "return\n",
            "tensor(-0.3749)\n",
            "return\n",
            "tensor(1.3145)\n",
            "return\n",
            "tensor(0.1300)\n",
            "return\n",
            "tensor(2.7891)\n",
            "return\n",
            "tensor(1.6549)\n",
            "return\n",
            "tensor(0.4253)\n",
            "return\n",
            "tensor(-0.6585)\n",
            "loss\n",
            "tensor(0.0468, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0124, 0.1412, 0.0106, 0.0530, 0.0847, 0.0524, 0.0035, 0.0279, 0.0037,\n",
            "        0.0949, 0.0609, 0.0325, 0.0649, 0.0469, 0.1508, 0.1596],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(9)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0128, 0.1400, 0.0110, 0.0534, 0.0847, 0.0529, 0.0037, 0.0285, 0.0039,\n",
            "        0.0947, 0.0613, 0.0331, 0.0652, 0.0474, 0.1493, 0.1582],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(12)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0124, 0.1412, 0.0106, 0.0530, 0.0847, 0.0524, 0.0035, 0.0279, 0.0037,\n",
            "        0.0949, 0.0609, 0.0325, 0.0649, 0.0469, 0.1508, 0.1596],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0128, 0.1400, 0.0111, 0.0535, 0.0847, 0.0529, 0.0038, 0.0285, 0.0039,\n",
            "        0.0947, 0.0613, 0.0332, 0.0652, 0.0474, 0.1491, 0.1580],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0124, 0.1412, 0.0106, 0.0530, 0.0847, 0.0524, 0.0035, 0.0279, 0.0037,\n",
            "        0.0949, 0.0609, 0.0325, 0.0649, 0.0469, 0.1508, 0.1596],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(2)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0128, 0.1399, 0.0111, 0.0535, 0.0847, 0.0529, 0.0038, 0.0285, 0.0039,\n",
            "        0.0947, 0.0613, 0.0331, 0.0652, 0.0475, 0.1492, 0.1580],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(3)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0124, 0.1412, 0.0106, 0.0530, 0.0847, 0.0524, 0.0035, 0.0279, 0.0037,\n",
            "        0.0949, 0.0609, 0.0325, 0.0649, 0.0469, 0.1508, 0.1596],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(13)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0128, 0.1400, 0.0110, 0.0534, 0.0846, 0.0528, 0.0037, 0.0284, 0.0039,\n",
            "        0.0947, 0.0613, 0.0331, 0.0652, 0.0474, 0.1493, 0.1582],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(5)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0124, 0.1412, 0.0106, 0.0530, 0.0847, 0.0524, 0.0035, 0.0279, 0.0037,\n",
            "        0.0949, 0.0609, 0.0325, 0.0649, 0.0469, 0.1508, 0.1596],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0128, 0.1400, 0.0111, 0.0535, 0.0847, 0.0529, 0.0038, 0.0285, 0.0039,\n",
            "        0.0947, 0.0613, 0.0332, 0.0652, 0.0474, 0.1491, 0.1580],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0124, 0.1412, 0.0106, 0.0530, 0.0847, 0.0524, 0.0035, 0.0279, 0.0037,\n",
            "        0.0949, 0.0609, 0.0325, 0.0649, 0.0469, 0.1508, 0.1596],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0128, 0.1400, 0.0110, 0.0534, 0.0847, 0.0528, 0.0037, 0.0285, 0.0039,\n",
            "        0.0947, 0.0613, 0.0331, 0.0652, 0.0474, 0.1493, 0.1581],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(13)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0124, 0.1412, 0.0106, 0.0530, 0.0847, 0.0524, 0.0035, 0.0279, 0.0037,\n",
            "        0.0949, 0.0609, 0.0325, 0.0649, 0.0469, 0.1508, 0.1596],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0128, 0.1401, 0.0110, 0.0534, 0.0846, 0.0528, 0.0037, 0.0284, 0.0039,\n",
            "        0.0947, 0.0612, 0.0331, 0.0652, 0.0474, 0.1493, 0.1583],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(12)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0124, 0.1412, 0.0106, 0.0530, 0.0847, 0.0524, 0.0035, 0.0279, 0.0037,\n",
            "        0.0949, 0.0609, 0.0325, 0.0649, 0.0469, 0.1508, 0.1596],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(5)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0128, 0.1400, 0.0111, 0.0535, 0.0847, 0.0529, 0.0038, 0.0285, 0.0039,\n",
            "        0.0947, 0.0613, 0.0331, 0.0652, 0.0474, 0.1492, 0.1580],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0124, 0.1412, 0.0106, 0.0530, 0.0847, 0.0524, 0.0035, 0.0279, 0.0037,\n",
            "        0.0949, 0.0609, 0.0325, 0.0649, 0.0469, 0.1508, 0.1596],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(2)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0128, 0.1399, 0.0111, 0.0535, 0.0847, 0.0529, 0.0038, 0.0285, 0.0039,\n",
            "        0.0947, 0.0613, 0.0331, 0.0652, 0.0475, 0.1492, 0.1580],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0124, 0.1412, 0.0106, 0.0530, 0.0847, 0.0524, 0.0035, 0.0279, 0.0037,\n",
            "        0.0949, 0.0609, 0.0325, 0.0649, 0.0469, 0.1508, 0.1596],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0128, 0.1400, 0.0111, 0.0535, 0.0847, 0.0529, 0.0038, 0.0285, 0.0039,\n",
            "        0.0947, 0.0613, 0.0332, 0.0652, 0.0474, 0.1491, 0.1580],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(12)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(-0.4830, grad_fn=<SubBackward0>), tensor(-0.5000, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-1.4251)\n",
            "return\n",
            "tensor(0.0393)\n",
            "return\n",
            "tensor(1.8500)\n",
            "return\n",
            "tensor(1.5140)\n",
            "return\n",
            "tensor(-1.5337)\n",
            "return\n",
            "tensor(0.0394)\n",
            "return\n",
            "tensor(-0.1238)\n",
            "return\n",
            "tensor(0.0393)\n",
            "return\n",
            "tensor(1.5613)\n",
            "return\n",
            "tensor(1.5940)\n",
            "return\n",
            "tensor(-0.4436)\n",
            "return\n",
            "tensor(0.0393)\n",
            "return\n",
            "tensor(-0.7161)\n",
            "return\n",
            "tensor(0.0393)\n",
            "return\n",
            "tensor(-0.1333)\n",
            "return\n",
            "tensor(0.0393)\n",
            "return\n",
            "tensor(-0.9584)\n",
            "return\n",
            "tensor(0.0393)\n",
            "return\n",
            "tensor(-1.5000)\n",
            "return\n",
            "tensor(0.0393)\n",
            "loss\n",
            "tensor(-0.7309, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0057, 0.1488, 0.0041, 0.0381, 0.0758, 0.0472, 0.0010, 0.0150, 0.0010,\n",
            "        0.0783, 0.0432, 0.0196, 0.0632, 0.0413, 0.2163, 0.2012],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(3)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0060, 0.1479, 0.0044, 0.0387, 0.0762, 0.0478, 0.0011, 0.0156, 0.0011,\n",
            "        0.0787, 0.0439, 0.0202, 0.0638, 0.0420, 0.2137, 0.1991],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0057, 0.1488, 0.0041, 0.0381, 0.0758, 0.0472, 0.0010, 0.0150, 0.0010,\n",
            "        0.0783, 0.0432, 0.0196, 0.0632, 0.0413, 0.2163, 0.2012],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0060, 0.1480, 0.0044, 0.0387, 0.0762, 0.0478, 0.0011, 0.0155, 0.0011,\n",
            "        0.0787, 0.0438, 0.0202, 0.0638, 0.0420, 0.2135, 0.1992],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(12)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0057, 0.1488, 0.0041, 0.0381, 0.0758, 0.0472, 0.0010, 0.0150, 0.0010,\n",
            "        0.0783, 0.0432, 0.0196, 0.0632, 0.0413, 0.2163, 0.2012],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0060, 0.1480, 0.0044, 0.0387, 0.0762, 0.0478, 0.0011, 0.0155, 0.0011,\n",
            "        0.0787, 0.0438, 0.0202, 0.0638, 0.0420, 0.2135, 0.1992],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0057, 0.1488, 0.0041, 0.0381, 0.0758, 0.0472, 0.0010, 0.0150, 0.0010,\n",
            "        0.0783, 0.0432, 0.0196, 0.0632, 0.0413, 0.2163, 0.2012],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0060, 0.1481, 0.0044, 0.0386, 0.0761, 0.0477, 0.0010, 0.0155, 0.0011,\n",
            "        0.0787, 0.0437, 0.0201, 0.0637, 0.0419, 0.2139, 0.1995],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0057, 0.1488, 0.0041, 0.0381, 0.0758, 0.0472, 0.0010, 0.0150, 0.0010,\n",
            "        0.0783, 0.0432, 0.0196, 0.0632, 0.0413, 0.2163, 0.2012],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(4)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0060, 0.1482, 0.0043, 0.0386, 0.0761, 0.0477, 0.0010, 0.0154, 0.0011,\n",
            "        0.0786, 0.0437, 0.0201, 0.0636, 0.0418, 0.2141, 0.1996],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0057, 0.1488, 0.0041, 0.0381, 0.0758, 0.0472, 0.0010, 0.0150, 0.0010,\n",
            "        0.0783, 0.0432, 0.0196, 0.0632, 0.0413, 0.2163, 0.2012],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0060, 0.1481, 0.0044, 0.0386, 0.0761, 0.0477, 0.0010, 0.0155, 0.0011,\n",
            "        0.0787, 0.0437, 0.0201, 0.0637, 0.0419, 0.2139, 0.1995],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(5)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0057, 0.1488, 0.0041, 0.0381, 0.0758, 0.0472, 0.0010, 0.0150, 0.0010,\n",
            "        0.0783, 0.0432, 0.0196, 0.0632, 0.0413, 0.2163, 0.2012],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(5)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0060, 0.1480, 0.0044, 0.0387, 0.0762, 0.0478, 0.0011, 0.0155, 0.0011,\n",
            "        0.0787, 0.0438, 0.0202, 0.0638, 0.0419, 0.2136, 0.1992],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(3)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0057, 0.1488, 0.0041, 0.0381, 0.0758, 0.0472, 0.0010, 0.0150, 0.0010,\n",
            "        0.0783, 0.0432, 0.0196, 0.0632, 0.0413, 0.2163, 0.2012],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(10)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0060, 0.1479, 0.0044, 0.0387, 0.0762, 0.0478, 0.0011, 0.0156, 0.0011,\n",
            "        0.0787, 0.0438, 0.0202, 0.0638, 0.0420, 0.2135, 0.1992],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(9)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0057, 0.1488, 0.0041, 0.0381, 0.0758, 0.0472, 0.0010, 0.0150, 0.0010,\n",
            "        0.0783, 0.0432, 0.0196, 0.0632, 0.0413, 0.2163, 0.2012],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(13)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0060, 0.1480, 0.0043, 0.0386, 0.0761, 0.0477, 0.0010, 0.0155, 0.0011,\n",
            "        0.0787, 0.0438, 0.0201, 0.0637, 0.0419, 0.2139, 0.1995],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0057, 0.1488, 0.0041, 0.0381, 0.0758, 0.0472, 0.0010, 0.0150, 0.0010,\n",
            "        0.0783, 0.0432, 0.0196, 0.0632, 0.0413, 0.2163, 0.2012],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0060, 0.1481, 0.0044, 0.0386, 0.0761, 0.0477, 0.0010, 0.0155, 0.0011,\n",
            "        0.0787, 0.0437, 0.0201, 0.0637, 0.0419, 0.2139, 0.1995],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.4939, grad_fn=<SubBackward0>), tensor(-0.5000, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-0.5399)\n",
            "return\n",
            "tensor(-0.5920)\n",
            "return\n",
            "tensor(0.5681)\n",
            "return\n",
            "tensor(-0.5920)\n",
            "return\n",
            "tensor(2.8121)\n",
            "return\n",
            "tensor(1.7019)\n",
            "return\n",
            "tensor(0.0644)\n",
            "return\n",
            "tensor(1.1650)\n",
            "return\n",
            "tensor(-0.3503)\n",
            "return\n",
            "tensor(-0.5920)\n",
            "return\n",
            "tensor(-1.0219)\n",
            "return\n",
            "tensor(-0.5920)\n",
            "return\n",
            "tensor(-1.1877)\n",
            "return\n",
            "tensor(-0.5919)\n",
            "return\n",
            "tensor(0.3035)\n",
            "return\n",
            "tensor(-0.5917)\n",
            "return\n",
            "tensor(0.5780)\n",
            "return\n",
            "tensor(-0.5920)\n",
            "return\n",
            "tensor(0.6425)\n",
            "return\n",
            "tensor(-0.5920)\n",
            "loss\n",
            "tensor(-0.4925, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.5940e-03, 1.4170e-01, 8.4979e-04, 1.7962e-02, 5.4411e-02, 2.7674e-02,\n",
            "        1.2075e-04, 5.2249e-03, 1.3858e-04, 4.6655e-02, 2.3677e-02, 8.0359e-03,\n",
            "        4.7105e-02, 3.0728e-02, 3.9758e-01, 1.9655e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.7131e-03, 1.4203e-01, 9.2184e-04, 1.8581e-02, 5.5274e-02, 2.8402e-02,\n",
            "        1.3522e-04, 5.5088e-03, 1.5472e-04, 4.7528e-02, 2.4363e-02, 8.4205e-03,\n",
            "        4.7976e-02, 3.1489e-02, 3.9142e-01, 1.9608e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.5940e-03, 1.4170e-01, 8.4979e-04, 1.7962e-02, 5.4411e-02, 2.7674e-02,\n",
            "        1.2075e-04, 5.2249e-03, 1.3858e-04, 4.6655e-02, 2.3677e-02, 8.0359e-03,\n",
            "        4.7105e-02, 3.0728e-02, 3.9758e-01, 1.9655e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(3)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.7144e-03, 1.4188e-01, 9.2221e-04, 1.8589e-02, 5.5311e-02, 2.8418e-02,\n",
            "        1.3536e-04, 5.5157e-03, 1.5491e-04, 4.7547e-02, 2.4393e-02, 8.4229e-03,\n",
            "        4.8017e-02, 3.1507e-02, 3.9157e-01, 1.9591e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.5940e-03, 1.4170e-01, 8.4979e-04, 1.7962e-02, 5.4411e-02, 2.7674e-02,\n",
            "        1.2075e-04, 5.2249e-03, 1.3858e-04, 4.6655e-02, 2.3677e-02, 8.0359e-03,\n",
            "        4.7105e-02, 3.0728e-02, 3.9758e-01, 1.9655e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.6967e-03, 1.4193e-01, 9.1301e-04, 1.8498e-02, 5.5132e-02, 2.8316e-02,\n",
            "        1.3326e-04, 5.4706e-03, 1.5253e-04, 4.7420e-02, 2.4266e-02, 8.3648e-03,\n",
            "        4.7911e-02, 3.1378e-02, 3.9219e-01, 1.9624e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.5940e-03, 1.4170e-01, 8.4979e-04, 1.7962e-02, 5.4411e-02, 2.7674e-02,\n",
            "        1.2075e-04, 5.2249e-03, 1.3858e-04, 4.6655e-02, 2.3677e-02, 8.0359e-03,\n",
            "        4.7105e-02, 3.0728e-02, 3.9758e-01, 1.9655e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(5)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.7082e-03, 1.4197e-01, 9.1904e-04, 1.8564e-02, 5.5252e-02, 2.8389e-02,\n",
            "        1.3458e-04, 5.4996e-03, 1.5406e-04, 4.7526e-02, 2.4349e-02, 8.4048e-03,\n",
            "        4.7978e-02, 3.1468e-02, 3.9160e-01, 1.9608e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.5940e-03, 1.4170e-01, 8.4979e-04, 1.7962e-02, 5.4411e-02, 2.7674e-02,\n",
            "        1.2075e-04, 5.2249e-03, 1.3858e-04, 4.6655e-02, 2.3677e-02, 8.0359e-03,\n",
            "        4.7105e-02, 3.0728e-02, 3.9758e-01, 1.9655e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(4)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.6867e-03, 1.4202e-01, 9.0704e-04, 1.8454e-02, 5.5021e-02, 2.8257e-02,\n",
            "        1.3197e-04, 5.4468e-03, 1.5124e-04, 4.7358e-02, 2.4207e-02, 8.3308e-03,\n",
            "        4.7795e-02, 3.1318e-02, 3.9267e-01, 1.9624e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.5940e-03, 1.4170e-01, 8.4979e-04, 1.7962e-02, 5.4411e-02, 2.7674e-02,\n",
            "        1.2075e-04, 5.2249e-03, 1.3858e-04, 4.6655e-02, 2.3677e-02, 8.0359e-03,\n",
            "        4.7105e-02, 3.0728e-02, 3.9758e-01, 1.9655e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.6999e-03, 1.4185e-01, 9.1370e-04, 1.8496e-02, 5.5203e-02, 2.8330e-02,\n",
            "        1.3376e-04, 5.4801e-03, 1.5293e-04, 4.7446e-02, 2.4274e-02, 8.3750e-03,\n",
            "        4.7899e-02, 3.1406e-02, 3.9226e-01, 1.9608e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.5940e-03, 1.4170e-01, 8.4979e-04, 1.7962e-02, 5.4411e-02, 2.7674e-02,\n",
            "        1.2075e-04, 5.2249e-03, 1.3858e-04, 4.6655e-02, 2.3677e-02, 8.0359e-03,\n",
            "        4.7105e-02, 3.0728e-02, 3.9758e-01, 1.9655e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.7131e-03, 1.4203e-01, 9.2184e-04, 1.8581e-02, 5.5274e-02, 2.8402e-02,\n",
            "        1.3522e-04, 5.5088e-03, 1.5472e-04, 4.7528e-02, 2.4363e-02, 8.4205e-03,\n",
            "        4.7976e-02, 3.1489e-02, 3.9142e-01, 1.9608e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(11)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.5940e-03, 1.4170e-01, 8.4979e-04, 1.7962e-02, 5.4411e-02, 2.7674e-02,\n",
            "        1.2075e-04, 5.2249e-03, 1.3858e-04, 4.6655e-02, 2.3677e-02, 8.0359e-03,\n",
            "        4.7105e-02, 3.0728e-02, 3.9758e-01, 1.9655e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(12)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.7017e-03, 1.4201e-01, 9.1489e-04, 1.8521e-02, 5.5196e-02, 2.8331e-02,\n",
            "        1.3376e-04, 5.4810e-03, 1.5318e-04, 4.7461e-02, 2.4290e-02, 8.3826e-03,\n",
            "        4.7921e-02, 3.1424e-02, 3.9203e-01, 1.9605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.5940e-03, 1.4170e-01, 8.4979e-04, 1.7962e-02, 5.4411e-02, 2.7674e-02,\n",
            "        1.2075e-04, 5.2249e-03, 1.3858e-04, 4.6655e-02, 2.3677e-02, 8.0359e-03,\n",
            "        4.7105e-02, 3.0728e-02, 3.9758e-01, 1.9655e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(13)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.6912e-03, 1.4184e-01, 9.0982e-04, 1.8477e-02, 5.5107e-02, 2.8297e-02,\n",
            "        1.3258e-04, 5.4640e-03, 1.5186e-04, 4.7395e-02, 2.4272e-02, 8.3489e-03,\n",
            "        4.7883e-02, 3.1367e-02, 3.9246e-01, 1.9620e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(10)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.5940e-03, 1.4170e-01, 8.4979e-04, 1.7962e-02, 5.4411e-02, 2.7674e-02,\n",
            "        1.2075e-04, 5.2249e-03, 1.3858e-04, 4.6655e-02, 2.3677e-02, 8.0359e-03,\n",
            "        4.7105e-02, 3.0728e-02, 3.9758e-01, 1.9655e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.7131e-03, 1.4203e-01, 9.2184e-04, 1.8581e-02, 5.5274e-02, 2.8402e-02,\n",
            "        1.3522e-04, 5.5088e-03, 1.5472e-04, 4.7528e-02, 2.4363e-02, 8.4205e-03,\n",
            "        4.7976e-02, 3.1489e-02, 3.9142e-01, 1.9608e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.1509, grad_fn=<SubBackward0>), tensor(-0.5000, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(2.6332)\n",
            "return\n",
            "tensor(1.9188)\n",
            "return\n",
            "tensor(0.2026)\n",
            "return\n",
            "tensor(-0.6393)\n",
            "return\n",
            "tensor(0.8028)\n",
            "return\n",
            "tensor(-0.6655)\n",
            "return\n",
            "tensor(-0.1147)\n",
            "return\n",
            "tensor(-0.4157)\n",
            "return\n",
            "tensor(0.5998)\n",
            "return\n",
            "tensor(-0.6522)\n",
            "return\n",
            "tensor(0.6436)\n",
            "return\n",
            "tensor(-0.6655)\n",
            "return\n",
            "tensor(-1.6075)\n",
            "return\n",
            "tensor(-0.6655)\n",
            "return\n",
            "tensor(0.0301)\n",
            "return\n",
            "tensor(-0.6655)\n",
            "return\n",
            "tensor(0.7896)\n",
            "return\n",
            "tensor(-0.6655)\n",
            "return\n",
            "tensor(-0.1978)\n",
            "return\n",
            "tensor(-0.6655)\n",
            "loss\n",
            "tensor(-0.0938, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.2424e-04, 7.8730e-02, 7.7239e-05, 4.7979e-03, 3.0110e-02, 9.4201e-03,\n",
            "        6.1204e-06, 9.7857e-04, 7.5953e-06, 1.6011e-02, 6.4473e-03, 1.5543e-03,\n",
            "        2.3692e-02, 1.7081e-02, 6.4481e-01, 1.6605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([2.4779e-04, 8.0274e-02, 8.6567e-05, 5.0807e-03, 3.1053e-02, 9.8697e-03,\n",
            "        7.1128e-06, 1.0588e-03, 8.7926e-06, 1.6668e-02, 6.7912e-03, 1.6724e-03,\n",
            "        2.4524e-02, 1.7752e-02, 6.3727e-01, 1.6764e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.2424e-04, 7.8730e-02, 7.7239e-05, 4.7979e-03, 3.0110e-02, 9.4201e-03,\n",
            "        6.1204e-06, 9.7857e-04, 7.5953e-06, 1.6011e-02, 6.4473e-03, 1.5543e-03,\n",
            "        2.3692e-02, 1.7081e-02, 6.4481e-01, 1.6605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([2.4502e-04, 7.9983e-02, 8.5451e-05, 5.0413e-03, 3.0957e-02, 9.8194e-03,\n",
            "        7.0057e-06, 1.0500e-03, 8.6514e-06, 1.6595e-02, 6.7458e-03, 1.6577e-03,\n",
            "        2.4435e-02, 1.7671e-02, 6.3833e-01, 1.6737e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.2424e-04, 7.8730e-02, 7.7239e-05, 4.7979e-03, 3.0110e-02, 9.4201e-03,\n",
            "        6.1204e-06, 9.7857e-04, 7.5953e-06, 1.6011e-02, 6.4473e-03, 1.5543e-03,\n",
            "        2.3692e-02, 1.7081e-02, 6.4481e-01, 1.6605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([2.4779e-04, 8.0274e-02, 8.6567e-05, 5.0807e-03, 3.1053e-02, 9.8697e-03,\n",
            "        7.1128e-06, 1.0588e-03, 8.7926e-06, 1.6668e-02, 6.7912e-03, 1.6724e-03,\n",
            "        2.4524e-02, 1.7752e-02, 6.3727e-01, 1.6764e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.2424e-04, 7.8730e-02, 7.7239e-05, 4.7979e-03, 3.0110e-02, 9.4201e-03,\n",
            "        6.1204e-06, 9.7857e-04, 7.5953e-06, 1.6011e-02, 6.4473e-03, 1.5543e-03,\n",
            "        2.3692e-02, 1.7081e-02, 6.4481e-01, 1.6605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([2.4442e-04, 8.0018e-02, 8.5336e-05, 5.0409e-03, 3.0908e-02, 9.8105e-03,\n",
            "        6.9695e-06, 1.0475e-03, 8.6209e-06, 1.6578e-02, 6.7424e-03, 1.6548e-03,\n",
            "        2.4442e-02, 1.7653e-02, 6.3825e-01, 1.6751e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.2424e-04, 7.8730e-02, 7.7239e-05, 4.7979e-03, 3.0110e-02, 9.4201e-03,\n",
            "        6.1204e-06, 9.7857e-04, 7.5953e-06, 1.6011e-02, 6.4473e-03, 1.5543e-03,\n",
            "        2.3692e-02, 1.7081e-02, 6.4481e-01, 1.6605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([2.4779e-04, 8.0274e-02, 8.6567e-05, 5.0807e-03, 3.1053e-02, 9.8697e-03,\n",
            "        7.1128e-06, 1.0588e-03, 8.7926e-06, 1.6668e-02, 6.7912e-03, 1.6724e-03,\n",
            "        2.4524e-02, 1.7752e-02, 6.3727e-01, 1.6764e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.2424e-04, 7.8730e-02, 7.7239e-05, 4.7979e-03, 3.0110e-02, 9.4201e-03,\n",
            "        6.1204e-06, 9.7857e-04, 7.5953e-06, 1.6011e-02, 6.4473e-03, 1.5543e-03,\n",
            "        2.3692e-02, 1.7081e-02, 6.4481e-01, 1.6605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(4)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([2.4221e-04, 7.9979e-02, 8.4486e-05, 5.0185e-03, 3.0794e-02, 9.7714e-03,\n",
            "        6.8721e-06, 1.0401e-03, 8.5136e-06, 1.6526e-02, 6.7105e-03, 1.6436e-03,\n",
            "        2.4343e-02, 1.7594e-02, 6.3887e-01, 1.6737e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.2424e-04, 7.8730e-02, 7.7239e-05, 4.7979e-03, 3.0110e-02, 9.4201e-03,\n",
            "        6.1204e-06, 9.7857e-04, 7.5953e-06, 1.6011e-02, 6.4473e-03, 1.5543e-03,\n",
            "        2.3692e-02, 1.7081e-02, 6.4481e-01, 1.6605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(12)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([2.4532e-04, 8.0126e-02, 8.5563e-05, 5.0507e-03, 3.0960e-02, 9.8218e-03,\n",
            "        7.0014e-06, 1.0502e-03, 8.6654e-06, 1.6606e-02, 6.7536e-03, 1.6596e-03,\n",
            "        2.4458e-02, 1.7688e-02, 6.3808e-01, 1.6740e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(12)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.2424e-04, 7.8730e-02, 7.7239e-05, 4.7979e-03, 3.0110e-02, 9.4201e-03,\n",
            "        6.1204e-06, 9.7857e-04, 7.5953e-06, 1.6011e-02, 6.4473e-03, 1.5543e-03,\n",
            "        2.3692e-02, 1.7081e-02, 6.4481e-01, 1.6605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([2.4442e-04, 8.0018e-02, 8.5336e-05, 5.0409e-03, 3.0908e-02, 9.8105e-03,\n",
            "        6.9695e-06, 1.0475e-03, 8.6209e-06, 1.6578e-02, 6.7424e-03, 1.6548e-03,\n",
            "        2.4442e-02, 1.7653e-02, 6.3825e-01, 1.6751e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(15)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.2424e-04, 7.8730e-02, 7.7239e-05, 4.7979e-03, 3.0110e-02, 9.4201e-03,\n",
            "        6.1204e-06, 9.7857e-04, 7.5953e-06, 1.6011e-02, 6.4473e-03, 1.5543e-03,\n",
            "        2.3692e-02, 1.7081e-02, 6.4481e-01, 1.6605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([2.4779e-04, 8.0274e-02, 8.6567e-05, 5.0807e-03, 3.1053e-02, 9.8697e-03,\n",
            "        7.1128e-06, 1.0588e-03, 8.7926e-06, 1.6668e-02, 6.7912e-03, 1.6724e-03,\n",
            "        2.4524e-02, 1.7752e-02, 6.3727e-01, 1.6764e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.2424e-04, 7.8730e-02, 7.7239e-05, 4.7979e-03, 3.0110e-02, 9.4201e-03,\n",
            "        6.1204e-06, 9.7857e-04, 7.5953e-06, 1.6011e-02, 6.4473e-03, 1.5543e-03,\n",
            "        2.3692e-02, 1.7081e-02, 6.4481e-01, 1.6605e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([2.4779e-04, 8.0274e-02, 8.6567e-05, 5.0807e-03, 3.1053e-02, 9.8697e-03,\n",
            "        7.1128e-06, 1.0588e-03, 8.7926e-06, 1.6668e-02, 6.7912e-03, 1.6724e-03,\n",
            "        2.4524e-02, 1.7752e-02, 6.3727e-01, 1.6764e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(-0.0855, grad_fn=<SubBackward0>), tensor(0.3000, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(1.9742)\n",
            "return\n",
            "tensor(0.9439)\n",
            "return\n",
            "tensor(-0.9036)\n",
            "return\n",
            "tensor(-1.0476)\n",
            "return\n",
            "tensor(1.7478)\n",
            "return\n",
            "tensor(1.0208)\n",
            "return\n",
            "tensor(-1.2651)\n",
            "return\n",
            "tensor(-1.0477)\n",
            "return\n",
            "tensor(-0.0226)\n",
            "return\n",
            "tensor(1.0539)\n",
            "return\n",
            "tensor(-1.0165)\n",
            "return\n",
            "tensor(-1.0477)\n",
            "return\n",
            "tensor(-0.1196)\n",
            "return\n",
            "tensor(-0.0329)\n",
            "return\n",
            "tensor(-0.0129)\n",
            "return\n",
            "tensor(-1.0476)\n",
            "return\n",
            "tensor(0.2724)\n",
            "return\n",
            "tensor(-0.6145)\n",
            "return\n",
            "tensor(0.4907)\n",
            "return\n",
            "tensor(0.6747)\n",
            "loss\n",
            "tensor(-0.8938, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.3604e-06, 1.2889e-02, 1.1245e-06, 3.3928e-04, 4.9281e-03, 9.6396e-04,\n",
            "        3.7722e-08, 4.1362e-05, 5.4758e-08, 1.5823e-03, 4.7777e-04, 6.7692e-05,\n",
            "        3.8427e-03, 3.7563e-03, 9.2530e-01, 4.5799e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.3102e-06, 1.3545e-02, 1.3184e-06, 3.7190e-04, 5.2265e-03, 1.0420e-03,\n",
            "        4.6101e-08, 4.6451e-05, 6.6554e-08, 1.7024e-03, 5.2081e-04, 7.5663e-05,\n",
            "        4.0889e-03, 3.9959e-03, 9.2195e-01, 4.7427e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.3604e-06, 1.2889e-02, 1.1245e-06, 3.3928e-04, 4.9281e-03, 9.6396e-04,\n",
            "        3.7722e-08, 4.1362e-05, 5.4758e-08, 1.5823e-03, 4.7777e-04, 6.7692e-05,\n",
            "        3.8427e-03, 3.7563e-03, 9.2530e-01, 4.5799e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.3102e-06, 1.3545e-02, 1.3184e-06, 3.7190e-04, 5.2265e-03, 1.0420e-03,\n",
            "        4.6101e-08, 4.6451e-05, 6.6554e-08, 1.7024e-03, 5.2081e-04, 7.5663e-05,\n",
            "        4.0889e-03, 3.9959e-03, 9.2195e-01, 4.7427e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.3604e-06, 1.2889e-02, 1.1245e-06, 3.3928e-04, 4.9281e-03, 9.6396e-04,\n",
            "        3.7722e-08, 4.1362e-05, 5.4758e-08, 1.5823e-03, 4.7777e-04, 6.7692e-05,\n",
            "        3.8427e-03, 3.7563e-03, 9.2530e-01, 4.5799e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.3102e-06, 1.3545e-02, 1.3184e-06, 3.7190e-04, 5.2265e-03, 1.0420e-03,\n",
            "        4.6101e-08, 4.6451e-05, 6.6554e-08, 1.7024e-03, 5.2081e-04, 7.5663e-05,\n",
            "        4.0889e-03, 3.9959e-03, 9.2195e-01, 4.7427e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.3604e-06, 1.2889e-02, 1.1245e-06, 3.3928e-04, 4.9281e-03, 9.6396e-04,\n",
            "        3.7722e-08, 4.1362e-05, 5.4758e-08, 1.5823e-03, 4.7777e-04, 6.7692e-05,\n",
            "        3.8427e-03, 3.7563e-03, 9.2530e-01, 4.5799e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.3102e-06, 1.3545e-02, 1.3184e-06, 3.7190e-04, 5.2265e-03, 1.0420e-03,\n",
            "        4.6101e-08, 4.6451e-05, 6.6554e-08, 1.7024e-03, 5.2081e-04, 7.5663e-05,\n",
            "        4.0889e-03, 3.9959e-03, 9.2195e-01, 4.7427e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.3604e-06, 1.2889e-02, 1.1245e-06, 3.3928e-04, 4.9281e-03, 9.6396e-04,\n",
            "        3.7722e-08, 4.1362e-05, 5.4758e-08, 1.5823e-03, 4.7777e-04, 6.7692e-05,\n",
            "        3.8427e-03, 3.7563e-03, 9.2530e-01, 4.5799e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.3102e-06, 1.3545e-02, 1.3184e-06, 3.7190e-04, 5.2265e-03, 1.0420e-03,\n",
            "        4.6101e-08, 4.6451e-05, 6.6554e-08, 1.7024e-03, 5.2081e-04, 7.5663e-05,\n",
            "        4.0889e-03, 3.9959e-03, 9.2195e-01, 4.7427e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.3604e-06, 1.2889e-02, 1.1245e-06, 3.3928e-04, 4.9281e-03, 9.6396e-04,\n",
            "        3.7722e-08, 4.1362e-05, 5.4758e-08, 1.5823e-03, 4.7777e-04, 6.7692e-05,\n",
            "        3.8427e-03, 3.7563e-03, 9.2530e-01, 4.5799e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.3102e-06, 1.3545e-02, 1.3184e-06, 3.7190e-04, 5.2265e-03, 1.0420e-03,\n",
            "        4.6101e-08, 4.6451e-05, 6.6554e-08, 1.7024e-03, 5.2081e-04, 7.5663e-05,\n",
            "        4.0889e-03, 3.9959e-03, 9.2195e-01, 4.7427e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.3604e-06, 1.2889e-02, 1.1245e-06, 3.3928e-04, 4.9281e-03, 9.6396e-04,\n",
            "        3.7722e-08, 4.1362e-05, 5.4758e-08, 1.5823e-03, 4.7777e-04, 6.7692e-05,\n",
            "        3.8427e-03, 3.7563e-03, 9.2530e-01, 4.5799e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.3102e-06, 1.3545e-02, 1.3184e-06, 3.7190e-04, 5.2265e-03, 1.0420e-03,\n",
            "        4.6101e-08, 4.6451e-05, 6.6554e-08, 1.7024e-03, 5.2081e-04, 7.5663e-05,\n",
            "        4.0889e-03, 3.9959e-03, 9.2195e-01, 4.7427e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.3604e-06, 1.2889e-02, 1.1245e-06, 3.3928e-04, 4.9281e-03, 9.6396e-04,\n",
            "        3.7722e-08, 4.1362e-05, 5.4758e-08, 1.5823e-03, 4.7777e-04, 6.7692e-05,\n",
            "        3.8427e-03, 3.7563e-03, 9.2530e-01, 4.5799e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(1)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.1657e-06, 1.3439e-02, 1.2907e-06, 3.6702e-04, 5.1802e-03, 1.0308e-03,\n",
            "        4.4797e-08, 4.5696e-05, 6.4740e-08, 1.6847e-03, 5.1440e-04, 7.4422e-05,\n",
            "        4.0603e-03, 3.9590e-03, 9.2241e-01, 4.7223e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.3604e-06, 1.2889e-02, 1.1245e-06, 3.3928e-04, 4.9281e-03, 9.6396e-04,\n",
            "        3.7722e-08, 4.1362e-05, 5.4758e-08, 1.5823e-03, 4.7777e-04, 6.7692e-05,\n",
            "        3.8427e-03, 3.7563e-03, 9.2530e-01, 4.5799e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.3102e-06, 1.3545e-02, 1.3184e-06, 3.7190e-04, 5.2265e-03, 1.0420e-03,\n",
            "        4.6101e-08, 4.6451e-05, 6.6554e-08, 1.7024e-03, 5.2081e-04, 7.5663e-05,\n",
            "        4.0889e-03, 3.9959e-03, 9.2195e-01, 4.7427e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.3604e-06, 1.2889e-02, 1.1245e-06, 3.3928e-04, 4.9281e-03, 9.6396e-04,\n",
            "        3.7722e-08, 4.1362e-05, 5.4758e-08, 1.5823e-03, 4.7777e-04, 6.7692e-05,\n",
            "        3.8427e-03, 3.7563e-03, 9.2530e-01, 4.5799e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.3102e-06, 1.3545e-02, 1.3184e-06, 3.7190e-04, 5.2265e-03, 1.0420e-03,\n",
            "        4.6101e-08, 4.6451e-05, 6.6554e-08, 1.7024e-03, 5.2081e-04, 7.5663e-05,\n",
            "        4.0889e-03, 3.9959e-03, 9.2195e-01, 4.7427e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.4922, grad_fn=<SubBackward0>), tensor(-0.2713, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-2.2156)\n",
            "return\n",
            "tensor(-1.2513)\n",
            "return\n",
            "tensor(0.6049)\n",
            "return\n",
            "tensor(0.9063)\n",
            "return\n",
            "tensor(1.6321)\n",
            "return\n",
            "tensor(0.7051)\n",
            "return\n",
            "tensor(0.0142)\n",
            "return\n",
            "tensor(-0.4581)\n",
            "return\n",
            "tensor(1.6063)\n",
            "return\n",
            "tensor(0.7232)\n",
            "return\n",
            "tensor(0.1171)\n",
            "return\n",
            "tensor(0.6470)\n",
            "return\n",
            "tensor(-0.1930)\n",
            "return\n",
            "tensor(-1.0656)\n",
            "return\n",
            "tensor(-0.3717)\n",
            "return\n",
            "tensor(-1.3928)\n",
            "return\n",
            "tensor(-0.0716)\n",
            "return\n",
            "tensor(0.5933)\n",
            "return\n",
            "tensor(0.3196)\n",
            "return\n",
            "tensor(-0.8495)\n",
            "loss\n",
            "tensor(-0.1593, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5850e-08, 5.0224e-04, 2.5576e-09, 5.7819e-06, 2.5091e-04, 2.6013e-05,\n",
            "        2.9840e-11, 3.8481e-07, 5.4473e-11, 3.9477e-05, 8.4463e-06, 6.0440e-07,\n",
            "        1.9949e-04, 3.1245e-04, 9.9437e-01, 4.2875e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.2734e-08, 5.4391e-04, 3.1291e-09, 6.5455e-06, 2.7296e-04, 2.8948e-05,\n",
            "        3.8244e-11, 4.4733e-07, 6.9308e-11, 4.3816e-05, 9.5083e-06, 7.0037e-07,\n",
            "        2.1760e-04, 3.3907e-04, 9.9399e-01, 4.5449e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5850e-08, 5.0224e-04, 2.5576e-09, 5.7819e-06, 2.5091e-04, 2.6013e-05,\n",
            "        2.9840e-11, 3.8481e-07, 5.4473e-11, 3.9477e-05, 8.4463e-06, 6.0440e-07,\n",
            "        1.9949e-04, 3.1245e-04, 9.9437e-01, 4.2875e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.2734e-08, 5.4391e-04, 3.1291e-09, 6.5455e-06, 2.7296e-04, 2.8948e-05,\n",
            "        3.8244e-11, 4.4733e-07, 6.9308e-11, 4.3816e-05, 9.5083e-06, 7.0037e-07,\n",
            "        2.1760e-04, 3.3907e-04, 9.9399e-01, 4.5449e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5850e-08, 5.0224e-04, 2.5576e-09, 5.7819e-06, 2.5091e-04, 2.6013e-05,\n",
            "        2.9840e-11, 3.8481e-07, 5.4473e-11, 3.9477e-05, 8.4463e-06, 6.0440e-07,\n",
            "        1.9949e-04, 3.1245e-04, 9.9437e-01, 4.2875e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.2734e-08, 5.4391e-04, 3.1291e-09, 6.5455e-06, 2.7296e-04, 2.8948e-05,\n",
            "        3.8244e-11, 4.4733e-07, 6.9308e-11, 4.3816e-05, 9.5083e-06, 7.0037e-07,\n",
            "        2.1760e-04, 3.3907e-04, 9.9399e-01, 4.5449e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5850e-08, 5.0224e-04, 2.5576e-09, 5.7819e-06, 2.5091e-04, 2.6013e-05,\n",
            "        2.9840e-11, 3.8481e-07, 5.4473e-11, 3.9477e-05, 8.4463e-06, 6.0440e-07,\n",
            "        1.9949e-04, 3.1245e-04, 9.9437e-01, 4.2875e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.2734e-08, 5.4391e-04, 3.1291e-09, 6.5455e-06, 2.7296e-04, 2.8948e-05,\n",
            "        3.8244e-11, 4.4733e-07, 6.9308e-11, 4.3816e-05, 9.5083e-06, 7.0037e-07,\n",
            "        2.1760e-04, 3.3907e-04, 9.9399e-01, 4.5449e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5850e-08, 5.0224e-04, 2.5576e-09, 5.7819e-06, 2.5091e-04, 2.6013e-05,\n",
            "        2.9840e-11, 3.8481e-07, 5.4473e-11, 3.9477e-05, 8.4463e-06, 6.0440e-07,\n",
            "        1.9949e-04, 3.1245e-04, 9.9437e-01, 4.2875e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.2734e-08, 5.4391e-04, 3.1291e-09, 6.5455e-06, 2.7296e-04, 2.8948e-05,\n",
            "        3.8244e-11, 4.4733e-07, 6.9308e-11, 4.3816e-05, 9.5083e-06, 7.0037e-07,\n",
            "        2.1760e-04, 3.3907e-04, 9.9399e-01, 4.5449e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5850e-08, 5.0224e-04, 2.5576e-09, 5.7819e-06, 2.5091e-04, 2.6013e-05,\n",
            "        2.9840e-11, 3.8481e-07, 5.4473e-11, 3.9477e-05, 8.4463e-06, 6.0440e-07,\n",
            "        1.9949e-04, 3.1245e-04, 9.9437e-01, 4.2875e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.2734e-08, 5.4391e-04, 3.1291e-09, 6.5455e-06, 2.7296e-04, 2.8948e-05,\n",
            "        3.8244e-11, 4.4733e-07, 6.9308e-11, 4.3816e-05, 9.5083e-06, 7.0037e-07,\n",
            "        2.1760e-04, 3.3907e-04, 9.9399e-01, 4.5449e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5850e-08, 5.0224e-04, 2.5576e-09, 5.7819e-06, 2.5091e-04, 2.6013e-05,\n",
            "        2.9840e-11, 3.8481e-07, 5.4473e-11, 3.9477e-05, 8.4463e-06, 6.0440e-07,\n",
            "        1.9949e-04, 3.1245e-04, 9.9437e-01, 4.2875e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.2734e-08, 5.4391e-04, 3.1291e-09, 6.5455e-06, 2.7296e-04, 2.8948e-05,\n",
            "        3.8244e-11, 4.4733e-07, 6.9308e-11, 4.3816e-05, 9.5083e-06, 7.0037e-07,\n",
            "        2.1760e-04, 3.3907e-04, 9.9399e-01, 4.5449e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5850e-08, 5.0224e-04, 2.5576e-09, 5.7819e-06, 2.5091e-04, 2.6013e-05,\n",
            "        2.9840e-11, 3.8481e-07, 5.4473e-11, 3.9477e-05, 8.4463e-06, 6.0440e-07,\n",
            "        1.9949e-04, 3.1245e-04, 9.9437e-01, 4.2875e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.2734e-08, 5.4391e-04, 3.1291e-09, 6.5455e-06, 2.7296e-04, 2.8948e-05,\n",
            "        3.8244e-11, 4.4733e-07, 6.9308e-11, 4.3816e-05, 9.5083e-06, 7.0037e-07,\n",
            "        2.1760e-04, 3.3907e-04, 9.9399e-01, 4.5449e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5850e-08, 5.0224e-04, 2.5576e-09, 5.7819e-06, 2.5091e-04, 2.6013e-05,\n",
            "        2.9840e-11, 3.8481e-07, 5.4473e-11, 3.9477e-05, 8.4463e-06, 6.0440e-07,\n",
            "        1.9949e-04, 3.1245e-04, 9.9437e-01, 4.2875e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.2734e-08, 5.4391e-04, 3.1291e-09, 6.5455e-06, 2.7296e-04, 2.8948e-05,\n",
            "        3.8244e-11, 4.4733e-07, 6.9308e-11, 4.3816e-05, 9.5083e-06, 7.0037e-07,\n",
            "        2.1760e-04, 3.3907e-04, 9.9399e-01, 4.5449e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5850e-08, 5.0224e-04, 2.5576e-09, 5.7819e-06, 2.5091e-04, 2.6013e-05,\n",
            "        2.9840e-11, 3.8481e-07, 5.4473e-11, 3.9477e-05, 8.4463e-06, 6.0440e-07,\n",
            "        1.9949e-04, 3.1245e-04, 9.9437e-01, 4.2875e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.2734e-08, 5.4391e-04, 3.1291e-09, 6.5455e-06, 2.7296e-04, 2.8948e-05,\n",
            "        3.8244e-11, 4.4733e-07, 6.9308e-11, 4.3816e-05, 9.5083e-06, 7.0037e-07,\n",
            "        2.1760e-04, 3.3907e-04, 9.9399e-01, 4.5449e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.3934, grad_fn=<SubBackward0>), tensor(0.1184, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-0.1596)\n",
            "return\n",
            "tensor(0.6268)\n",
            "return\n",
            "tensor(-0.0822)\n",
            "return\n",
            "tensor(-1.4535)\n",
            "return\n",
            "tensor(-1.1652)\n",
            "return\n",
            "tensor(-0.5417)\n",
            "return\n",
            "tensor(-0.2533)\n",
            "return\n",
            "tensor(-0.3669)\n",
            "return\n",
            "tensor(1.5820)\n",
            "return\n",
            "tensor(0.4586)\n",
            "return\n",
            "tensor(-0.8900)\n",
            "return\n",
            "tensor(-0.3860)\n",
            "return\n",
            "tensor(1.9611)\n",
            "return\n",
            "tensor(0.6629)\n",
            "return\n",
            "tensor(-0.5228)\n",
            "return\n",
            "tensor(-1.8545)\n",
            "return\n",
            "tensor(1.3525)\n",
            "return\n",
            "tensor(0.6603)\n",
            "return\n",
            "tensor(0.7453)\n",
            "return\n",
            "tensor(-0.3740)\n",
            "loss\n",
            "tensor(-9.6898e-05, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.1087e-11, 6.6236e-06, 1.4014e-12, 3.5446e-08, 5.5417e-06, 2.5460e-07,\n",
            "        4.8969e-15, 1.2000e-09, 1.2399e-14, 3.5006e-07, 5.2158e-08, 1.6040e-09,\n",
            "        4.7763e-06, 1.4247e-05, 9.9979e-01, 1.7770e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.5786e-11, 7.4059e-06, 1.7974e-12, 4.1511e-08, 6.1878e-06, 2.9228e-07,\n",
            "        6.6202e-15, 1.4472e-09, 1.6600e-14, 4.0145e-07, 6.0745e-08, 1.9328e-09,\n",
            "        5.3427e-06, 1.5770e-05, 9.9977e-01, 1.9291e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.1087e-11, 6.6236e-06, 1.4014e-12, 3.5446e-08, 5.5417e-06, 2.5460e-07,\n",
            "        4.8969e-15, 1.2000e-09, 1.2399e-14, 3.5006e-07, 5.2158e-08, 1.6040e-09,\n",
            "        4.7763e-06, 1.4247e-05, 9.9979e-01, 1.7770e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.5786e-11, 7.4059e-06, 1.7974e-12, 4.1511e-08, 6.1878e-06, 2.9228e-07,\n",
            "        6.6202e-15, 1.4472e-09, 1.6600e-14, 4.0145e-07, 6.0745e-08, 1.9328e-09,\n",
            "        5.3427e-06, 1.5770e-05, 9.9977e-01, 1.9291e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.1087e-11, 6.6236e-06, 1.4014e-12, 3.5446e-08, 5.5417e-06, 2.5460e-07,\n",
            "        4.8969e-15, 1.2000e-09, 1.2399e-14, 3.5006e-07, 5.2158e-08, 1.6040e-09,\n",
            "        4.7763e-06, 1.4247e-05, 9.9979e-01, 1.7770e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.5786e-11, 7.4059e-06, 1.7974e-12, 4.1511e-08, 6.1878e-06, 2.9228e-07,\n",
            "        6.6202e-15, 1.4472e-09, 1.6600e-14, 4.0145e-07, 6.0745e-08, 1.9328e-09,\n",
            "        5.3427e-06, 1.5770e-05, 9.9977e-01, 1.9291e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.1087e-11, 6.6236e-06, 1.4014e-12, 3.5446e-08, 5.5417e-06, 2.5460e-07,\n",
            "        4.8969e-15, 1.2000e-09, 1.2399e-14, 3.5006e-07, 5.2158e-08, 1.6040e-09,\n",
            "        4.7763e-06, 1.4247e-05, 9.9979e-01, 1.7770e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.5786e-11, 7.4059e-06, 1.7974e-12, 4.1511e-08, 6.1878e-06, 2.9228e-07,\n",
            "        6.6202e-15, 1.4472e-09, 1.6600e-14, 4.0145e-07, 6.0745e-08, 1.9328e-09,\n",
            "        5.3427e-06, 1.5770e-05, 9.9977e-01, 1.9291e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.1087e-11, 6.6236e-06, 1.4014e-12, 3.5446e-08, 5.5417e-06, 2.5460e-07,\n",
            "        4.8969e-15, 1.2000e-09, 1.2399e-14, 3.5006e-07, 5.2158e-08, 1.6040e-09,\n",
            "        4.7763e-06, 1.4247e-05, 9.9979e-01, 1.7770e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.5786e-11, 7.4059e-06, 1.7974e-12, 4.1511e-08, 6.1878e-06, 2.9228e-07,\n",
            "        6.6202e-15, 1.4472e-09, 1.6600e-14, 4.0145e-07, 6.0745e-08, 1.9328e-09,\n",
            "        5.3427e-06, 1.5770e-05, 9.9977e-01, 1.9291e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.1087e-11, 6.6236e-06, 1.4014e-12, 3.5446e-08, 5.5417e-06, 2.5460e-07,\n",
            "        4.8969e-15, 1.2000e-09, 1.2399e-14, 3.5006e-07, 5.2158e-08, 1.6040e-09,\n",
            "        4.7763e-06, 1.4247e-05, 9.9979e-01, 1.7770e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.5786e-11, 7.4059e-06, 1.7974e-12, 4.1511e-08, 6.1878e-06, 2.9228e-07,\n",
            "        6.6202e-15, 1.4472e-09, 1.6600e-14, 4.0145e-07, 6.0745e-08, 1.9328e-09,\n",
            "        5.3427e-06, 1.5770e-05, 9.9977e-01, 1.9291e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.1087e-11, 6.6236e-06, 1.4014e-12, 3.5446e-08, 5.5417e-06, 2.5460e-07,\n",
            "        4.8969e-15, 1.2000e-09, 1.2399e-14, 3.5006e-07, 5.2158e-08, 1.6040e-09,\n",
            "        4.7763e-06, 1.4247e-05, 9.9979e-01, 1.7770e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.5786e-11, 7.4059e-06, 1.7974e-12, 4.1511e-08, 6.1878e-06, 2.9228e-07,\n",
            "        6.6202e-15, 1.4472e-09, 1.6600e-14, 4.0145e-07, 6.0745e-08, 1.9328e-09,\n",
            "        5.3427e-06, 1.5770e-05, 9.9977e-01, 1.9291e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.1087e-11, 6.6236e-06, 1.4014e-12, 3.5446e-08, 5.5417e-06, 2.5460e-07,\n",
            "        4.8969e-15, 1.2000e-09, 1.2399e-14, 3.5006e-07, 5.2158e-08, 1.6040e-09,\n",
            "        4.7763e-06, 1.4247e-05, 9.9979e-01, 1.7770e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.5786e-11, 7.4059e-06, 1.7974e-12, 4.1511e-08, 6.1878e-06, 2.9228e-07,\n",
            "        6.6202e-15, 1.4472e-09, 1.6600e-14, 4.0145e-07, 6.0745e-08, 1.9328e-09,\n",
            "        5.3427e-06, 1.5770e-05, 9.9977e-01, 1.9291e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.1087e-11, 6.6236e-06, 1.4014e-12, 3.5446e-08, 5.5417e-06, 2.5460e-07,\n",
            "        4.8969e-15, 1.2000e-09, 1.2399e-14, 3.5006e-07, 5.2158e-08, 1.6040e-09,\n",
            "        4.7763e-06, 1.4247e-05, 9.9979e-01, 1.7770e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.5786e-11, 7.4059e-06, 1.7974e-12, 4.1511e-08, 6.1878e-06, 2.9228e-07,\n",
            "        6.6202e-15, 1.4472e-09, 1.6600e-14, 4.0145e-07, 6.0745e-08, 1.9328e-09,\n",
            "        5.3427e-06, 1.5770e-05, 9.9977e-01, 1.9291e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([6.1087e-11, 6.6236e-06, 1.4014e-12, 3.5446e-08, 5.5417e-06, 2.5460e-07,\n",
            "        4.8969e-15, 1.2000e-09, 1.2399e-14, 3.5006e-07, 5.2158e-08, 1.6040e-09,\n",
            "        4.7763e-06, 1.4247e-05, 9.9979e-01, 1.7770e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([7.5786e-11, 7.4059e-06, 1.7974e-12, 4.1511e-08, 6.1878e-06, 2.9228e-07,\n",
            "        6.6202e-15, 1.4472e-09, 1.6600e-14, 4.0145e-07, 6.0745e-08, 1.9328e-09,\n",
            "        5.3427e-06, 1.5770e-05, 9.9977e-01, 1.9291e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.4617, grad_fn=<SubBackward0>), tensor(0.4728, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(0.2815)\n",
            "return\n",
            "tensor(-0.5969)\n",
            "return\n",
            "tensor(0.8812)\n",
            "return\n",
            "tensor(-0.3753)\n",
            "return\n",
            "tensor(-0.4995)\n",
            "return\n",
            "tensor(-1.8462)\n",
            "return\n",
            "tensor(-0.8792)\n",
            "return\n",
            "tensor(0.1021)\n",
            "return\n",
            "tensor(1.1590)\n",
            "return\n",
            "tensor(-0.0584)\n",
            "return\n",
            "tensor(1.3183)\n",
            "return\n",
            "tensor(0.1300)\n",
            "return\n",
            "tensor(1.5829)\n",
            "return\n",
            "tensor(0.3461)\n",
            "return\n",
            "tensor(-0.6651)\n",
            "return\n",
            "tensor(-1.6900)\n",
            "return\n",
            "tensor(0.0989)\n",
            "return\n",
            "tensor(-1.2113)\n",
            "return\n",
            "tensor(1.6154)\n",
            "return\n",
            "tensor(0.3064)\n",
            "loss\n",
            "tensor(-9.2191e-06, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5795e-14, 3.2823e-08, 2.1717e-16, 8.5681e-11, 5.5586e-08, 1.0211e-09,\n",
            "        1.9879e-19, 1.3638e-12, 7.8768e-19, 1.2013e-09, 1.1766e-10, 1.3870e-12,\n",
            "        5.7711e-08, 4.0059e-07, 1.0000e+00, 3.5590e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.6349e-14, 3.7985e-08, 2.9296e-16, 1.0402e-10, 6.3843e-08, 1.2121e-09,\n",
            "        2.8453e-19, 1.7107e-12, 1.1128e-18, 1.4269e-09, 1.4218e-10, 1.7437e-12,\n",
            "        6.6284e-08, 4.5256e-07, 1.0000e+00, 3.9637e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5795e-14, 3.2823e-08, 2.1717e-16, 8.5681e-11, 5.5586e-08, 1.0211e-09,\n",
            "        1.9879e-19, 1.3638e-12, 7.8768e-19, 1.2013e-09, 1.1766e-10, 1.3870e-12,\n",
            "        5.7711e-08, 4.0059e-07, 1.0000e+00, 3.5590e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.6349e-14, 3.7985e-08, 2.9296e-16, 1.0402e-10, 6.3843e-08, 1.2121e-09,\n",
            "        2.8453e-19, 1.7107e-12, 1.1128e-18, 1.4269e-09, 1.4218e-10, 1.7437e-12,\n",
            "        6.6284e-08, 4.5256e-07, 1.0000e+00, 3.9637e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5795e-14, 3.2823e-08, 2.1717e-16, 8.5681e-11, 5.5586e-08, 1.0211e-09,\n",
            "        1.9879e-19, 1.3638e-12, 7.8768e-19, 1.2013e-09, 1.1766e-10, 1.3870e-12,\n",
            "        5.7711e-08, 4.0059e-07, 1.0000e+00, 3.5590e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.6349e-14, 3.7985e-08, 2.9296e-16, 1.0402e-10, 6.3843e-08, 1.2121e-09,\n",
            "        2.8453e-19, 1.7107e-12, 1.1128e-18, 1.4269e-09, 1.4218e-10, 1.7437e-12,\n",
            "        6.6284e-08, 4.5256e-07, 1.0000e+00, 3.9637e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5795e-14, 3.2823e-08, 2.1717e-16, 8.5681e-11, 5.5586e-08, 1.0211e-09,\n",
            "        1.9879e-19, 1.3638e-12, 7.8768e-19, 1.2013e-09, 1.1766e-10, 1.3870e-12,\n",
            "        5.7711e-08, 4.0059e-07, 1.0000e+00, 3.5590e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.6349e-14, 3.7985e-08, 2.9296e-16, 1.0402e-10, 6.3843e-08, 1.2121e-09,\n",
            "        2.8453e-19, 1.7107e-12, 1.1128e-18, 1.4269e-09, 1.4218e-10, 1.7437e-12,\n",
            "        6.6284e-08, 4.5256e-07, 1.0000e+00, 3.9637e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5795e-14, 3.2823e-08, 2.1717e-16, 8.5681e-11, 5.5586e-08, 1.0211e-09,\n",
            "        1.9879e-19, 1.3638e-12, 7.8768e-19, 1.2013e-09, 1.1766e-10, 1.3870e-12,\n",
            "        5.7711e-08, 4.0059e-07, 1.0000e+00, 3.5590e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.6349e-14, 3.7985e-08, 2.9296e-16, 1.0402e-10, 6.3843e-08, 1.2121e-09,\n",
            "        2.8453e-19, 1.7107e-12, 1.1128e-18, 1.4269e-09, 1.4218e-10, 1.7437e-12,\n",
            "        6.6284e-08, 4.5256e-07, 1.0000e+00, 3.9637e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5795e-14, 3.2823e-08, 2.1717e-16, 8.5681e-11, 5.5586e-08, 1.0211e-09,\n",
            "        1.9879e-19, 1.3638e-12, 7.8768e-19, 1.2013e-09, 1.1766e-10, 1.3870e-12,\n",
            "        5.7711e-08, 4.0059e-07, 1.0000e+00, 3.5590e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.6349e-14, 3.7985e-08, 2.9296e-16, 1.0402e-10, 6.3843e-08, 1.2121e-09,\n",
            "        2.8453e-19, 1.7107e-12, 1.1128e-18, 1.4269e-09, 1.4218e-10, 1.7437e-12,\n",
            "        6.6284e-08, 4.5256e-07, 1.0000e+00, 3.9637e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5795e-14, 3.2823e-08, 2.1717e-16, 8.5681e-11, 5.5586e-08, 1.0211e-09,\n",
            "        1.9879e-19, 1.3638e-12, 7.8768e-19, 1.2013e-09, 1.1766e-10, 1.3870e-12,\n",
            "        5.7711e-08, 4.0059e-07, 1.0000e+00, 3.5590e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.6349e-14, 3.7985e-08, 2.9296e-16, 1.0402e-10, 6.3843e-08, 1.2121e-09,\n",
            "        2.8453e-19, 1.7107e-12, 1.1128e-18, 1.4269e-09, 1.4218e-10, 1.7437e-12,\n",
            "        6.6284e-08, 4.5256e-07, 1.0000e+00, 3.9637e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5795e-14, 3.2823e-08, 2.1717e-16, 8.5681e-11, 5.5586e-08, 1.0211e-09,\n",
            "        1.9879e-19, 1.3638e-12, 7.8768e-19, 1.2013e-09, 1.1766e-10, 1.3870e-12,\n",
            "        5.7711e-08, 4.0059e-07, 1.0000e+00, 3.5590e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.6349e-14, 3.7985e-08, 2.9296e-16, 1.0402e-10, 6.3843e-08, 1.2121e-09,\n",
            "        2.8453e-19, 1.7107e-12, 1.1128e-18, 1.4269e-09, 1.4218e-10, 1.7437e-12,\n",
            "        6.6284e-08, 4.5256e-07, 1.0000e+00, 3.9637e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5795e-14, 3.2823e-08, 2.1717e-16, 8.5681e-11, 5.5586e-08, 1.0211e-09,\n",
            "        1.9879e-19, 1.3638e-12, 7.8768e-19, 1.2013e-09, 1.1766e-10, 1.3870e-12,\n",
            "        5.7711e-08, 4.0059e-07, 1.0000e+00, 3.5590e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.6349e-14, 3.7985e-08, 2.9296e-16, 1.0402e-10, 6.3843e-08, 1.2121e-09,\n",
            "        2.8453e-19, 1.7107e-12, 1.1128e-18, 1.4269e-09, 1.4218e-10, 1.7437e-12,\n",
            "        6.6284e-08, 4.5256e-07, 1.0000e+00, 3.9637e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.5795e-14, 3.2823e-08, 2.1717e-16, 8.5681e-11, 5.5586e-08, 1.0211e-09,\n",
            "        1.9879e-19, 1.3638e-12, 7.8768e-19, 1.2013e-09, 1.1766e-10, 1.3870e-12,\n",
            "        5.7711e-08, 4.0059e-07, 1.0000e+00, 3.5590e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([4.6349e-14, 3.7985e-08, 2.9296e-16, 1.0402e-10, 6.3843e-08, 1.2121e-09,\n",
            "        2.8453e-19, 1.7107e-12, 1.1128e-18, 1.4269e-09, 1.4218e-10, 1.7437e-12,\n",
            "        6.6284e-08, 4.5256e-07, 1.0000e+00, 3.9637e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.2697, grad_fn=<SubBackward0>), tensor(0.4630, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-1.6427)\n",
            "return\n",
            "tensor(-0.5817)\n",
            "return\n",
            "tensor(-1.3853)\n",
            "return\n",
            "tensor(-0.4340)\n",
            "return\n",
            "tensor(-1.0424)\n",
            "return\n",
            "tensor(-1.2558)\n",
            "return\n",
            "tensor(1.5129)\n",
            "return\n",
            "tensor(0.5240)\n",
            "return\n",
            "tensor(0.8853)\n",
            "return\n",
            "tensor(0.4504)\n",
            "return\n",
            "tensor(1.5139)\n",
            "return\n",
            "tensor(0.6768)\n",
            "return\n",
            "tensor(-0.3465)\n",
            "return\n",
            "tensor(-1.3988)\n",
            "return\n",
            "tensor(0.8504)\n",
            "return\n",
            "tensor(0.2353)\n",
            "return\n",
            "tensor(-0.4851)\n",
            "return\n",
            "tensor(0.1218)\n",
            "return\n",
            "tensor(1.1870)\n",
            "return\n",
            "tensor(0.6145)\n",
            "loss\n",
            "tensor(-4.3703e-08, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.9975e-18, 6.4848e-11, 1.0204e-20, 8.6369e-14, 2.6123e-10, 1.7470e-12,\n",
            "        2.2087e-24, 6.1899e-16, 1.5254e-23, 1.7074e-12, 1.0205e-13, 4.2631e-16,\n",
            "        3.6394e-10, 7.4151e-09, 1.0000e+00, 3.6670e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.0794e-17, 7.7708e-11, 1.4465e-20, 1.0868e-13, 3.0873e-10, 2.1442e-12,\n",
            "        3.3420e-24, 8.0680e-16, 2.2703e-23, 2.1003e-12, 1.2796e-13, 5.5880e-16,\n",
            "        4.2918e-10, 8.5419e-09, 1.0000e+00, 4.1899e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.9975e-18, 6.4848e-11, 1.0204e-20, 8.6369e-14, 2.6123e-10, 1.7470e-12,\n",
            "        2.2087e-24, 6.1899e-16, 1.5254e-23, 1.7074e-12, 1.0205e-13, 4.2631e-16,\n",
            "        3.6394e-10, 7.4151e-09, 1.0000e+00, 3.6670e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.0794e-17, 7.7708e-11, 1.4465e-20, 1.0868e-13, 3.0873e-10, 2.1442e-12,\n",
            "        3.3420e-24, 8.0680e-16, 2.2703e-23, 2.1003e-12, 1.2796e-13, 5.5880e-16,\n",
            "        4.2918e-10, 8.5419e-09, 1.0000e+00, 4.1899e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.9975e-18, 6.4848e-11, 1.0204e-20, 8.6369e-14, 2.6123e-10, 1.7470e-12,\n",
            "        2.2087e-24, 6.1899e-16, 1.5254e-23, 1.7074e-12, 1.0205e-13, 4.2631e-16,\n",
            "        3.6394e-10, 7.4151e-09, 1.0000e+00, 3.6670e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.0794e-17, 7.7708e-11, 1.4465e-20, 1.0868e-13, 3.0873e-10, 2.1442e-12,\n",
            "        3.3420e-24, 8.0680e-16, 2.2703e-23, 2.1003e-12, 1.2796e-13, 5.5880e-16,\n",
            "        4.2918e-10, 8.5419e-09, 1.0000e+00, 4.1899e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.9975e-18, 6.4848e-11, 1.0204e-20, 8.6369e-14, 2.6123e-10, 1.7470e-12,\n",
            "        2.2087e-24, 6.1899e-16, 1.5254e-23, 1.7074e-12, 1.0205e-13, 4.2631e-16,\n",
            "        3.6394e-10, 7.4151e-09, 1.0000e+00, 3.6670e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.0794e-17, 7.7708e-11, 1.4465e-20, 1.0868e-13, 3.0873e-10, 2.1442e-12,\n",
            "        3.3420e-24, 8.0680e-16, 2.2703e-23, 2.1003e-12, 1.2796e-13, 5.5880e-16,\n",
            "        4.2918e-10, 8.5419e-09, 1.0000e+00, 4.1899e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.9975e-18, 6.4848e-11, 1.0204e-20, 8.6369e-14, 2.6123e-10, 1.7470e-12,\n",
            "        2.2087e-24, 6.1899e-16, 1.5254e-23, 1.7074e-12, 1.0205e-13, 4.2631e-16,\n",
            "        3.6394e-10, 7.4151e-09, 1.0000e+00, 3.6670e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.0794e-17, 7.7708e-11, 1.4465e-20, 1.0868e-13, 3.0873e-10, 2.1442e-12,\n",
            "        3.3420e-24, 8.0680e-16, 2.2703e-23, 2.1003e-12, 1.2796e-13, 5.5880e-16,\n",
            "        4.2918e-10, 8.5419e-09, 1.0000e+00, 4.1899e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.9975e-18, 6.4848e-11, 1.0204e-20, 8.6369e-14, 2.6123e-10, 1.7470e-12,\n",
            "        2.2087e-24, 6.1899e-16, 1.5254e-23, 1.7074e-12, 1.0205e-13, 4.2631e-16,\n",
            "        3.6394e-10, 7.4151e-09, 1.0000e+00, 3.6670e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.0794e-17, 7.7708e-11, 1.4465e-20, 1.0868e-13, 3.0873e-10, 2.1442e-12,\n",
            "        3.3420e-24, 8.0680e-16, 2.2703e-23, 2.1003e-12, 1.2796e-13, 5.5880e-16,\n",
            "        4.2918e-10, 8.5419e-09, 1.0000e+00, 4.1899e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.9975e-18, 6.4848e-11, 1.0204e-20, 8.6369e-14, 2.6123e-10, 1.7470e-12,\n",
            "        2.2087e-24, 6.1899e-16, 1.5254e-23, 1.7074e-12, 1.0205e-13, 4.2631e-16,\n",
            "        3.6394e-10, 7.4151e-09, 1.0000e+00, 3.6670e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.0794e-17, 7.7708e-11, 1.4465e-20, 1.0868e-13, 3.0873e-10, 2.1442e-12,\n",
            "        3.3420e-24, 8.0680e-16, 2.2703e-23, 2.1003e-12, 1.2796e-13, 5.5880e-16,\n",
            "        4.2918e-10, 8.5419e-09, 1.0000e+00, 4.1899e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.9975e-18, 6.4848e-11, 1.0204e-20, 8.6369e-14, 2.6123e-10, 1.7470e-12,\n",
            "        2.2087e-24, 6.1899e-16, 1.5254e-23, 1.7074e-12, 1.0205e-13, 4.2631e-16,\n",
            "        3.6394e-10, 7.4151e-09, 1.0000e+00, 3.6670e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.0794e-17, 7.7708e-11, 1.4465e-20, 1.0868e-13, 3.0873e-10, 2.1442e-12,\n",
            "        3.3420e-24, 8.0680e-16, 2.2703e-23, 2.1003e-12, 1.2796e-13, 5.5880e-16,\n",
            "        4.2918e-10, 8.5419e-09, 1.0000e+00, 4.1899e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.9975e-18, 6.4848e-11, 1.0204e-20, 8.6369e-14, 2.6123e-10, 1.7470e-12,\n",
            "        2.2087e-24, 6.1899e-16, 1.5254e-23, 1.7074e-12, 1.0205e-13, 4.2631e-16,\n",
            "        3.6394e-10, 7.4151e-09, 1.0000e+00, 3.6670e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.0794e-17, 7.7708e-11, 1.4465e-20, 1.0868e-13, 3.0873e-10, 2.1442e-12,\n",
            "        3.3420e-24, 8.0680e-16, 2.2703e-23, 2.1003e-12, 1.2796e-13, 5.5880e-16,\n",
            "        4.2918e-10, 8.5419e-09, 1.0000e+00, 4.1899e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.9975e-18, 6.4848e-11, 1.0204e-20, 8.6369e-14, 2.6123e-10, 1.7470e-12,\n",
            "        2.2087e-24, 6.1899e-16, 1.5254e-23, 1.7074e-12, 1.0205e-13, 4.2631e-16,\n",
            "        3.6394e-10, 7.4151e-09, 1.0000e+00, 3.6670e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.0794e-17, 7.7708e-11, 1.4465e-20, 1.0868e-13, 3.0873e-10, 2.1442e-12,\n",
            "        3.3420e-24, 8.0680e-16, 2.2703e-23, 2.1003e-12, 1.2796e-13, 5.5880e-16,\n",
            "        4.2918e-10, 8.5419e-09, 1.0000e+00, 4.1899e-08],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(-0.4997, grad_fn=<SubBackward0>), tensor(0.4449, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-0.6496)\n",
            "return\n",
            "tensor(0.5478)\n",
            "return\n",
            "tensor(-1.1664)\n",
            "return\n",
            "tensor(-1.2052)\n",
            "return\n",
            "tensor(-1.9207)\n",
            "return\n",
            "tensor(-0.6126)\n",
            "return\n",
            "tensor(0.9971)\n",
            "return\n",
            "tensor(0.7134)\n",
            "return\n",
            "tensor(-0.4397)\n",
            "return\n",
            "tensor(0.5807)\n",
            "return\n",
            "tensor(1.5800)\n",
            "return\n",
            "tensor(0.4076)\n",
            "return\n",
            "tensor(1.7755)\n",
            "return\n",
            "tensor(0.7354)\n",
            "return\n",
            "tensor(-0.8467)\n",
            "return\n",
            "tensor(0.4561)\n",
            "return\n",
            "tensor(0.2242)\n",
            "return\n",
            "tensor(-1.0740)\n",
            "return\n",
            "tensor(-0.7138)\n",
            "return\n",
            "tensor(0.6109)\n",
            "loss\n",
            "tensor(1.2079e-14, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.8790e-22, 5.4189e-14, 1.6913e-25, 3.9680e-17, 6.1886e-13, 1.3950e-15,\n",
            "        8.1415e-30, 1.2564e-19, 1.0572e-28, 1.0893e-15, 3.8025e-17, 5.2907e-20,\n",
            "        1.2705e-12, 9.5585e-11, 1.0000e+00, 2.0233e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1096e-21, 6.7362e-14, 2.5235e-25, 5.1815e-17, 7.5354e-13, 1.7727e-15,\n",
            "        1.3041e-29, 1.7038e-19, 1.6599e-28, 1.3898e-15, 4.9546e-17, 7.2420e-20,\n",
            "        1.5398e-12, 1.1232e-10, 1.0000e+00, 2.3751e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.8790e-22, 5.4189e-14, 1.6913e-25, 3.9680e-17, 6.1886e-13, 1.3950e-15,\n",
            "        8.1415e-30, 1.2564e-19, 1.0572e-28, 1.0893e-15, 3.8025e-17, 5.2907e-20,\n",
            "        1.2705e-12, 9.5585e-11, 1.0000e+00, 2.0233e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1096e-21, 6.7362e-14, 2.5235e-25, 5.1815e-17, 7.5354e-13, 1.7727e-15,\n",
            "        1.3041e-29, 1.7038e-19, 1.6599e-28, 1.3898e-15, 4.9546e-17, 7.2420e-20,\n",
            "        1.5398e-12, 1.1232e-10, 1.0000e+00, 2.3751e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.8790e-22, 5.4189e-14, 1.6913e-25, 3.9680e-17, 6.1886e-13, 1.3950e-15,\n",
            "        8.1415e-30, 1.2564e-19, 1.0572e-28, 1.0893e-15, 3.8025e-17, 5.2907e-20,\n",
            "        1.2705e-12, 9.5585e-11, 1.0000e+00, 2.0233e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1096e-21, 6.7362e-14, 2.5235e-25, 5.1815e-17, 7.5354e-13, 1.7727e-15,\n",
            "        1.3041e-29, 1.7038e-19, 1.6599e-28, 1.3898e-15, 4.9546e-17, 7.2420e-20,\n",
            "        1.5398e-12, 1.1232e-10, 1.0000e+00, 2.3751e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.8790e-22, 5.4189e-14, 1.6913e-25, 3.9680e-17, 6.1886e-13, 1.3950e-15,\n",
            "        8.1415e-30, 1.2564e-19, 1.0572e-28, 1.0893e-15, 3.8025e-17, 5.2907e-20,\n",
            "        1.2705e-12, 9.5585e-11, 1.0000e+00, 2.0233e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1096e-21, 6.7362e-14, 2.5235e-25, 5.1815e-17, 7.5354e-13, 1.7727e-15,\n",
            "        1.3041e-29, 1.7038e-19, 1.6599e-28, 1.3898e-15, 4.9546e-17, 7.2420e-20,\n",
            "        1.5398e-12, 1.1232e-10, 1.0000e+00, 2.3751e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.8790e-22, 5.4189e-14, 1.6913e-25, 3.9680e-17, 6.1886e-13, 1.3950e-15,\n",
            "        8.1415e-30, 1.2564e-19, 1.0572e-28, 1.0893e-15, 3.8025e-17, 5.2907e-20,\n",
            "        1.2705e-12, 9.5585e-11, 1.0000e+00, 2.0233e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1096e-21, 6.7362e-14, 2.5235e-25, 5.1815e-17, 7.5354e-13, 1.7727e-15,\n",
            "        1.3041e-29, 1.7038e-19, 1.6599e-28, 1.3898e-15, 4.9546e-17, 7.2420e-20,\n",
            "        1.5398e-12, 1.1232e-10, 1.0000e+00, 2.3751e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.8790e-22, 5.4189e-14, 1.6913e-25, 3.9680e-17, 6.1886e-13, 1.3950e-15,\n",
            "        8.1415e-30, 1.2564e-19, 1.0572e-28, 1.0893e-15, 3.8025e-17, 5.2907e-20,\n",
            "        1.2705e-12, 9.5585e-11, 1.0000e+00, 2.0233e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1096e-21, 6.7362e-14, 2.5235e-25, 5.1815e-17, 7.5354e-13, 1.7727e-15,\n",
            "        1.3041e-29, 1.7038e-19, 1.6599e-28, 1.3898e-15, 4.9546e-17, 7.2420e-20,\n",
            "        1.5398e-12, 1.1232e-10, 1.0000e+00, 2.3751e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.8790e-22, 5.4189e-14, 1.6913e-25, 3.9680e-17, 6.1886e-13, 1.3950e-15,\n",
            "        8.1415e-30, 1.2564e-19, 1.0572e-28, 1.0893e-15, 3.8025e-17, 5.2907e-20,\n",
            "        1.2705e-12, 9.5585e-11, 1.0000e+00, 2.0233e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1096e-21, 6.7362e-14, 2.5235e-25, 5.1815e-17, 7.5354e-13, 1.7727e-15,\n",
            "        1.3041e-29, 1.7038e-19, 1.6599e-28, 1.3898e-15, 4.9546e-17, 7.2420e-20,\n",
            "        1.5398e-12, 1.1232e-10, 1.0000e+00, 2.3751e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.8790e-22, 5.4189e-14, 1.6913e-25, 3.9680e-17, 6.1886e-13, 1.3950e-15,\n",
            "        8.1415e-30, 1.2564e-19, 1.0572e-28, 1.0893e-15, 3.8025e-17, 5.2907e-20,\n",
            "        1.2705e-12, 9.5585e-11, 1.0000e+00, 2.0233e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1096e-21, 6.7362e-14, 2.5235e-25, 5.1815e-17, 7.5354e-13, 1.7727e-15,\n",
            "        1.3041e-29, 1.7038e-19, 1.6599e-28, 1.3898e-15, 4.9546e-17, 7.2420e-20,\n",
            "        1.5398e-12, 1.1232e-10, 1.0000e+00, 2.3751e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.8790e-22, 5.4189e-14, 1.6913e-25, 3.9680e-17, 6.1886e-13, 1.3950e-15,\n",
            "        8.1415e-30, 1.2564e-19, 1.0572e-28, 1.0893e-15, 3.8025e-17, 5.2907e-20,\n",
            "        1.2705e-12, 9.5585e-11, 1.0000e+00, 2.0233e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1096e-21, 6.7362e-14, 2.5235e-25, 5.1815e-17, 7.5354e-13, 1.7727e-15,\n",
            "        1.3041e-29, 1.7038e-19, 1.6599e-28, 1.3898e-15, 4.9546e-17, 7.2420e-20,\n",
            "        1.5398e-12, 1.1232e-10, 1.0000e+00, 2.3751e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([7.8790e-22, 5.4189e-14, 1.6913e-25, 3.9680e-17, 6.1886e-13, 1.3950e-15,\n",
            "        8.1415e-30, 1.2564e-19, 1.0572e-28, 1.0893e-15, 3.8025e-17, 5.2907e-20,\n",
            "        1.2705e-12, 9.5585e-11, 1.0000e+00, 2.0233e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1096e-21, 6.7362e-14, 2.5235e-25, 5.1815e-17, 7.5354e-13, 1.7727e-15,\n",
            "        1.3041e-29, 1.7038e-19, 1.6599e-28, 1.3898e-15, 4.9546e-17, 7.2420e-20,\n",
            "        1.5398e-12, 1.1232e-10, 1.0000e+00, 2.3751e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.3752, grad_fn=<SubBackward0>), tensor(0.3456, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(1.5929)\n",
            "return\n",
            "tensor(0.3370)\n",
            "return\n",
            "tensor(0.0199)\n",
            "return\n",
            "tensor(0.5095)\n",
            "return\n",
            "tensor(1.2583)\n",
            "return\n",
            "tensor(0.0680)\n",
            "return\n",
            "tensor(-0.5952)\n",
            "return\n",
            "tensor(-1.7811)\n",
            "return\n",
            "tensor(-0.9771)\n",
            "return\n",
            "tensor(-1.8213)\n",
            "return\n",
            "tensor(-0.5357)\n",
            "return\n",
            "tensor(0.6082)\n",
            "return\n",
            "tensor(-1.4170)\n",
            "return\n",
            "tensor(-0.3451)\n",
            "return\n",
            "tensor(0.7171)\n",
            "return\n",
            "tensor(-0.4405)\n",
            "return\n",
            "tensor(1.1310)\n",
            "return\n",
            "tensor(-0.0363)\n",
            "return\n",
            "tensor(1.3396)\n",
            "return\n",
            "tensor(0.3679)\n",
            "loss\n",
            "tensor(-8.8818e-15, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.9674e-26, 2.1197e-17, 1.2059e-30, 9.4567e-21, 8.1949e-16, 5.9032e-19,\n",
            "        1.2394e-35, 1.2966e-23, 3.2341e-34, 3.4841e-19, 6.9765e-21, 3.0521e-24,\n",
            "        2.7168e-15, 9.1627e-13, 1.0000e+00, 6.3714e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([5.8207e-26, 2.7330e-17, 1.8904e-30, 1.2803e-20, 1.0276e-15, 7.7612e-19,\n",
            "        2.0968e-35, 1.8272e-23, 5.3444e-34, 4.6076e-19, 9.4385e-21, 4.3581e-24,\n",
            "        3.3816e-15, 1.0974e-12, 1.0000e+00, 7.6835e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.9674e-26, 2.1197e-17, 1.2059e-30, 9.4567e-21, 8.1949e-16, 5.9032e-19,\n",
            "        1.2394e-35, 1.2966e-23, 3.2341e-34, 3.4841e-19, 6.9765e-21, 3.0521e-24,\n",
            "        2.7168e-15, 9.1627e-13, 1.0000e+00, 6.3714e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([5.8207e-26, 2.7330e-17, 1.8904e-30, 1.2803e-20, 1.0276e-15, 7.7612e-19,\n",
            "        2.0968e-35, 1.8272e-23, 5.3444e-34, 4.6076e-19, 9.4385e-21, 4.3581e-24,\n",
            "        3.3816e-15, 1.0974e-12, 1.0000e+00, 7.6835e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.9674e-26, 2.1197e-17, 1.2059e-30, 9.4567e-21, 8.1949e-16, 5.9032e-19,\n",
            "        1.2394e-35, 1.2966e-23, 3.2341e-34, 3.4841e-19, 6.9765e-21, 3.0521e-24,\n",
            "        2.7168e-15, 9.1627e-13, 1.0000e+00, 6.3714e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([5.8207e-26, 2.7330e-17, 1.8904e-30, 1.2803e-20, 1.0276e-15, 7.7612e-19,\n",
            "        2.0968e-35, 1.8272e-23, 5.3444e-34, 4.6076e-19, 9.4385e-21, 4.3581e-24,\n",
            "        3.3816e-15, 1.0974e-12, 1.0000e+00, 7.6835e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.9674e-26, 2.1197e-17, 1.2059e-30, 9.4567e-21, 8.1949e-16, 5.9032e-19,\n",
            "        1.2394e-35, 1.2966e-23, 3.2341e-34, 3.4841e-19, 6.9765e-21, 3.0521e-24,\n",
            "        2.7168e-15, 9.1627e-13, 1.0000e+00, 6.3714e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([5.8207e-26, 2.7330e-17, 1.8904e-30, 1.2803e-20, 1.0276e-15, 7.7612e-19,\n",
            "        2.0968e-35, 1.8272e-23, 5.3444e-34, 4.6076e-19, 9.4385e-21, 4.3581e-24,\n",
            "        3.3816e-15, 1.0974e-12, 1.0000e+00, 7.6835e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.9674e-26, 2.1197e-17, 1.2059e-30, 9.4567e-21, 8.1949e-16, 5.9032e-19,\n",
            "        1.2394e-35, 1.2966e-23, 3.2341e-34, 3.4841e-19, 6.9765e-21, 3.0521e-24,\n",
            "        2.7168e-15, 9.1627e-13, 1.0000e+00, 6.3714e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([5.8207e-26, 2.7330e-17, 1.8904e-30, 1.2803e-20, 1.0276e-15, 7.7612e-19,\n",
            "        2.0968e-35, 1.8272e-23, 5.3444e-34, 4.6076e-19, 9.4385e-21, 4.3581e-24,\n",
            "        3.3816e-15, 1.0974e-12, 1.0000e+00, 7.6835e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.9674e-26, 2.1197e-17, 1.2059e-30, 9.4567e-21, 8.1949e-16, 5.9032e-19,\n",
            "        1.2394e-35, 1.2966e-23, 3.2341e-34, 3.4841e-19, 6.9765e-21, 3.0521e-24,\n",
            "        2.7168e-15, 9.1627e-13, 1.0000e+00, 6.3714e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([5.8207e-26, 2.7330e-17, 1.8904e-30, 1.2803e-20, 1.0276e-15, 7.7612e-19,\n",
            "        2.0968e-35, 1.8272e-23, 5.3444e-34, 4.6076e-19, 9.4385e-21, 4.3581e-24,\n",
            "        3.3816e-15, 1.0974e-12, 1.0000e+00, 7.6835e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.9674e-26, 2.1197e-17, 1.2059e-30, 9.4567e-21, 8.1949e-16, 5.9032e-19,\n",
            "        1.2394e-35, 1.2966e-23, 3.2341e-34, 3.4841e-19, 6.9765e-21, 3.0521e-24,\n",
            "        2.7168e-15, 9.1627e-13, 1.0000e+00, 6.3714e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([5.8207e-26, 2.7330e-17, 1.8904e-30, 1.2803e-20, 1.0276e-15, 7.7612e-19,\n",
            "        2.0968e-35, 1.8272e-23, 5.3444e-34, 4.6076e-19, 9.4385e-21, 4.3581e-24,\n",
            "        3.3816e-15, 1.0974e-12, 1.0000e+00, 7.6835e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.9674e-26, 2.1197e-17, 1.2059e-30, 9.4567e-21, 8.1949e-16, 5.9032e-19,\n",
            "        1.2394e-35, 1.2966e-23, 3.2341e-34, 3.4841e-19, 6.9765e-21, 3.0521e-24,\n",
            "        2.7168e-15, 9.1627e-13, 1.0000e+00, 6.3714e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([5.8207e-26, 2.7330e-17, 1.8904e-30, 1.2803e-20, 1.0276e-15, 7.7612e-19,\n",
            "        2.0968e-35, 1.8272e-23, 5.3444e-34, 4.6076e-19, 9.4385e-21, 4.3581e-24,\n",
            "        3.3816e-15, 1.0974e-12, 1.0000e+00, 7.6835e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.9674e-26, 2.1197e-17, 1.2059e-30, 9.4567e-21, 8.1949e-16, 5.9032e-19,\n",
            "        1.2394e-35, 1.2966e-23, 3.2341e-34, 3.4841e-19, 6.9765e-21, 3.0521e-24,\n",
            "        2.7168e-15, 9.1627e-13, 1.0000e+00, 6.3714e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([5.8207e-26, 2.7330e-17, 1.8904e-30, 1.2803e-20, 1.0276e-15, 7.7612e-19,\n",
            "        2.0968e-35, 1.8272e-23, 5.3444e-34, 4.6076e-19, 9.4385e-21, 4.3581e-24,\n",
            "        3.3816e-15, 1.0974e-12, 1.0000e+00, 7.6835e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([3.9674e-26, 2.1197e-17, 1.2059e-30, 9.4567e-21, 8.1949e-16, 5.9032e-19,\n",
            "        1.2394e-35, 1.2966e-23, 3.2341e-34, 3.4841e-19, 6.9765e-21, 3.0521e-24,\n",
            "        2.7168e-15, 9.1627e-13, 1.0000e+00, 6.3714e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([5.8207e-26, 2.7330e-17, 1.8904e-30, 1.2803e-20, 1.0276e-15, 7.7612e-19,\n",
            "        2.0968e-35, 1.8272e-23, 5.3444e-34, 4.6076e-19, 9.4385e-21, 4.3581e-24,\n",
            "        3.3816e-15, 1.0974e-12, 1.0000e+00, 7.6835e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.4914, grad_fn=<SubBackward0>), tensor(0.4286, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(1.1120)\n",
            "return\n",
            "tensor(0.4217)\n",
            "return\n",
            "tensor(-1.8265)\n",
            "return\n",
            "tensor(-0.8563)\n",
            "return\n",
            "tensor(-1.1635)\n",
            "return\n",
            "tensor(-1.5658)\n",
            "return\n",
            "tensor(-0.5453)\n",
            "return\n",
            "tensor(0.0428)\n",
            "return\n",
            "tensor(0.9635)\n",
            "return\n",
            "tensor(0.2758)\n",
            "return\n",
            "tensor(0.6663)\n",
            "return\n",
            "tensor(0.0712)\n",
            "return\n",
            "tensor(0.7501)\n",
            "return\n",
            "tensor(0.3455)\n",
            "return\n",
            "tensor(-1.5714)\n",
            "return\n",
            "tensor(-0.7266)\n",
            "return\n",
            "tensor(1.4399)\n",
            "return\n",
            "tensor(0.4638)\n",
            "return\n",
            "tensor(1.3715)\n",
            "return\n",
            "tensor(0.3314)\n",
            "loss\n",
            "tensor(1.4566e-14, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.1885e-30, 4.4064e-21, 4.4368e-36, 1.3321e-24, 6.7338e-19, 1.4969e-22,\n",
            "        9.5498e-42, 7.8327e-28, 5.2871e-40, 6.3458e-23, 7.2181e-25, 9.5297e-29,\n",
            "        3.9228e-18, 7.0235e-15, 1.0000e+00, 1.2570e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.8201e-30, 5.9037e-21, 7.3252e-36, 1.8731e-24, 8.7095e-19, 2.0396e-22,\n",
            "        1.7110e-41, 1.1493e-27, 9.2191e-40, 8.7144e-23, 1.0159e-24, 1.4224e-28,\n",
            "        5.0212e-18, 8.5801e-15, 1.0000e+00, 1.5593e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.1885e-30, 4.4064e-21, 4.4368e-36, 1.3321e-24, 6.7338e-19, 1.4969e-22,\n",
            "        9.5498e-42, 7.8327e-28, 5.2871e-40, 6.3458e-23, 7.2181e-25, 9.5297e-29,\n",
            "        3.9228e-18, 7.0235e-15, 1.0000e+00, 1.2570e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.8201e-30, 5.9037e-21, 7.3252e-36, 1.8731e-24, 8.7095e-19, 2.0396e-22,\n",
            "        1.7110e-41, 1.1493e-27, 9.2191e-40, 8.7144e-23, 1.0159e-24, 1.4224e-28,\n",
            "        5.0212e-18, 8.5801e-15, 1.0000e+00, 1.5593e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.1885e-30, 4.4064e-21, 4.4368e-36, 1.3321e-24, 6.7338e-19, 1.4969e-22,\n",
            "        9.5498e-42, 7.8327e-28, 5.2871e-40, 6.3458e-23, 7.2181e-25, 9.5297e-29,\n",
            "        3.9228e-18, 7.0235e-15, 1.0000e+00, 1.2570e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.8201e-30, 5.9037e-21, 7.3252e-36, 1.8731e-24, 8.7095e-19, 2.0396e-22,\n",
            "        1.7110e-41, 1.1493e-27, 9.2191e-40, 8.7144e-23, 1.0159e-24, 1.4224e-28,\n",
            "        5.0212e-18, 8.5801e-15, 1.0000e+00, 1.5593e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.1885e-30, 4.4064e-21, 4.4368e-36, 1.3321e-24, 6.7338e-19, 1.4969e-22,\n",
            "        9.5498e-42, 7.8327e-28, 5.2871e-40, 6.3458e-23, 7.2181e-25, 9.5297e-29,\n",
            "        3.9228e-18, 7.0235e-15, 1.0000e+00, 1.2570e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.8201e-30, 5.9037e-21, 7.3252e-36, 1.8731e-24, 8.7095e-19, 2.0396e-22,\n",
            "        1.7110e-41, 1.1493e-27, 9.2191e-40, 8.7144e-23, 1.0159e-24, 1.4224e-28,\n",
            "        5.0212e-18, 8.5801e-15, 1.0000e+00, 1.5593e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.1885e-30, 4.4064e-21, 4.4368e-36, 1.3321e-24, 6.7338e-19, 1.4969e-22,\n",
            "        9.5498e-42, 7.8327e-28, 5.2871e-40, 6.3458e-23, 7.2181e-25, 9.5297e-29,\n",
            "        3.9228e-18, 7.0235e-15, 1.0000e+00, 1.2570e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.8201e-30, 5.9037e-21, 7.3252e-36, 1.8731e-24, 8.7095e-19, 2.0396e-22,\n",
            "        1.7110e-41, 1.1493e-27, 9.2191e-40, 8.7144e-23, 1.0159e-24, 1.4224e-28,\n",
            "        5.0212e-18, 8.5801e-15, 1.0000e+00, 1.5593e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.1885e-30, 4.4064e-21, 4.4368e-36, 1.3321e-24, 6.7338e-19, 1.4969e-22,\n",
            "        9.5498e-42, 7.8327e-28, 5.2871e-40, 6.3458e-23, 7.2181e-25, 9.5297e-29,\n",
            "        3.9228e-18, 7.0235e-15, 1.0000e+00, 1.2570e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.8201e-30, 5.9037e-21, 7.3252e-36, 1.8731e-24, 8.7095e-19, 2.0396e-22,\n",
            "        1.7110e-41, 1.1493e-27, 9.2191e-40, 8.7144e-23, 1.0159e-24, 1.4224e-28,\n",
            "        5.0212e-18, 8.5801e-15, 1.0000e+00, 1.5593e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.1885e-30, 4.4064e-21, 4.4368e-36, 1.3321e-24, 6.7338e-19, 1.4969e-22,\n",
            "        9.5498e-42, 7.8327e-28, 5.2871e-40, 6.3458e-23, 7.2181e-25, 9.5297e-29,\n",
            "        3.9228e-18, 7.0235e-15, 1.0000e+00, 1.2570e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.8201e-30, 5.9037e-21, 7.3252e-36, 1.8731e-24, 8.7095e-19, 2.0396e-22,\n",
            "        1.7110e-41, 1.1493e-27, 9.2191e-40, 8.7144e-23, 1.0159e-24, 1.4224e-28,\n",
            "        5.0212e-18, 8.5801e-15, 1.0000e+00, 1.5593e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.1885e-30, 4.4064e-21, 4.4368e-36, 1.3321e-24, 6.7338e-19, 1.4969e-22,\n",
            "        9.5498e-42, 7.8327e-28, 5.2871e-40, 6.3458e-23, 7.2181e-25, 9.5297e-29,\n",
            "        3.9228e-18, 7.0235e-15, 1.0000e+00, 1.2570e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.8201e-30, 5.9037e-21, 7.3252e-36, 1.8731e-24, 8.7095e-19, 2.0396e-22,\n",
            "        1.7110e-41, 1.1493e-27, 9.2191e-40, 8.7144e-23, 1.0159e-24, 1.4224e-28,\n",
            "        5.0212e-18, 8.5801e-15, 1.0000e+00, 1.5593e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.1885e-30, 4.4064e-21, 4.4368e-36, 1.3321e-24, 6.7338e-19, 1.4969e-22,\n",
            "        9.5498e-42, 7.8327e-28, 5.2871e-40, 6.3458e-23, 7.2181e-25, 9.5297e-29,\n",
            "        3.9228e-18, 7.0235e-15, 1.0000e+00, 1.2570e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.8201e-30, 5.9037e-21, 7.3252e-36, 1.8731e-24, 8.7095e-19, 2.0396e-22,\n",
            "        1.7110e-41, 1.1493e-27, 9.2191e-40, 8.7144e-23, 1.0159e-24, 1.4224e-28,\n",
            "        5.0212e-18, 8.5801e-15, 1.0000e+00, 1.5593e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([1.1885e-30, 4.4064e-21, 4.4368e-36, 1.3321e-24, 6.7338e-19, 1.4969e-22,\n",
            "        9.5498e-42, 7.8327e-28, 5.2871e-40, 6.3458e-23, 7.2181e-25, 9.5297e-29,\n",
            "        3.9228e-18, 7.0235e-15, 1.0000e+00, 1.2570e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.8201e-30, 5.9037e-21, 7.3252e-36, 1.8731e-24, 8.7095e-19, 2.0396e-22,\n",
            "        1.7110e-41, 1.1493e-27, 9.2191e-40, 8.7144e-23, 1.0159e-24, 1.4224e-28,\n",
            "        5.0212e-18, 8.5801e-15, 1.0000e+00, 1.5593e-15],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.4090, grad_fn=<SubBackward0>), tensor(0.4545, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-0.9175)\n",
            "return\n",
            "tensor(-0.7018)\n",
            "return\n",
            "tensor(0.2440)\n",
            "return\n",
            "tensor(-0.7147)\n",
            "return\n",
            "tensor(-1.5946)\n",
            "return\n",
            "tensor(-0.7565)\n",
            "return\n",
            "tensor(2.0024)\n",
            "return\n",
            "tensor(1.0691)\n",
            "return\n",
            "tensor(0.8855)\n",
            "return\n",
            "tensor(0.0820)\n",
            "return\n",
            "tensor(-0.9317)\n",
            "return\n",
            "tensor(-0.8221)\n",
            "return\n",
            "tensor(0.0971)\n",
            "return\n",
            "tensor(-0.8265)\n",
            "return\n",
            "tensor(-0.5317)\n",
            "return\n",
            "tensor(-0.4109)\n",
            "return\n",
            "tensor(0.1252)\n",
            "return\n",
            "tensor(0.7160)\n",
            "return\n",
            "tensor(1.9179)\n",
            "return\n",
            "tensor(1.0687)\n",
            "loss\n",
            "tensor(-8.5265e-15, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.4646e-35, 5.5694e-25, 1.0116e-41, 1.2675e-28, 3.8299e-22, 2.5805e-26,\n",
            "        0.0000e+00, 3.1951e-32, 0.0000e+00, 7.5126e-27, 4.8429e-29, 1.8815e-33,\n",
            "        4.2245e-21, 4.6224e-17, 1.0000e+00, 1.7153e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([3.9434e-35, 7.7635e-25, 1.7614e-41, 1.8530e-28, 5.1142e-22, 3.6474e-26,\n",
            "        0.0000e+00, 4.8866e-32, 1.4013e-45, 1.0725e-26, 7.0983e-29, 2.9391e-33,\n",
            "        5.5650e-21, 5.7622e-17, 1.0000e+00, 2.1910e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.4646e-35, 5.5694e-25, 1.0116e-41, 1.2675e-28, 3.8299e-22, 2.5805e-26,\n",
            "        0.0000e+00, 3.1951e-32, 0.0000e+00, 7.5126e-27, 4.8429e-29, 1.8815e-33,\n",
            "        4.2245e-21, 4.6224e-17, 1.0000e+00, 1.7153e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([3.9434e-35, 7.7635e-25, 1.7614e-41, 1.8530e-28, 5.1142e-22, 3.6474e-26,\n",
            "        0.0000e+00, 4.8866e-32, 1.4013e-45, 1.0725e-26, 7.0983e-29, 2.9391e-33,\n",
            "        5.5650e-21, 5.7622e-17, 1.0000e+00, 2.1910e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.4646e-35, 5.5694e-25, 1.0116e-41, 1.2675e-28, 3.8299e-22, 2.5805e-26,\n",
            "        0.0000e+00, 3.1951e-32, 0.0000e+00, 7.5126e-27, 4.8429e-29, 1.8815e-33,\n",
            "        4.2245e-21, 4.6224e-17, 1.0000e+00, 1.7153e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([3.9434e-35, 7.7635e-25, 1.7614e-41, 1.8530e-28, 5.1142e-22, 3.6474e-26,\n",
            "        0.0000e+00, 4.8866e-32, 1.4013e-45, 1.0725e-26, 7.0983e-29, 2.9391e-33,\n",
            "        5.5650e-21, 5.7622e-17, 1.0000e+00, 2.1910e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.4646e-35, 5.5694e-25, 1.0116e-41, 1.2675e-28, 3.8299e-22, 2.5805e-26,\n",
            "        0.0000e+00, 3.1951e-32, 0.0000e+00, 7.5126e-27, 4.8429e-29, 1.8815e-33,\n",
            "        4.2245e-21, 4.6224e-17, 1.0000e+00, 1.7153e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([3.9434e-35, 7.7635e-25, 1.7614e-41, 1.8530e-28, 5.1142e-22, 3.6474e-26,\n",
            "        0.0000e+00, 4.8866e-32, 1.4013e-45, 1.0725e-26, 7.0983e-29, 2.9391e-33,\n",
            "        5.5650e-21, 5.7622e-17, 1.0000e+00, 2.1910e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.4646e-35, 5.5694e-25, 1.0116e-41, 1.2675e-28, 3.8299e-22, 2.5805e-26,\n",
            "        0.0000e+00, 3.1951e-32, 0.0000e+00, 7.5126e-27, 4.8429e-29, 1.8815e-33,\n",
            "        4.2245e-21, 4.6224e-17, 1.0000e+00, 1.7153e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([3.9434e-35, 7.7635e-25, 1.7614e-41, 1.8530e-28, 5.1142e-22, 3.6474e-26,\n",
            "        0.0000e+00, 4.8866e-32, 1.4013e-45, 1.0725e-26, 7.0983e-29, 2.9391e-33,\n",
            "        5.5650e-21, 5.7622e-17, 1.0000e+00, 2.1910e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.4646e-35, 5.5694e-25, 1.0116e-41, 1.2675e-28, 3.8299e-22, 2.5805e-26,\n",
            "        0.0000e+00, 3.1951e-32, 0.0000e+00, 7.5126e-27, 4.8429e-29, 1.8815e-33,\n",
            "        4.2245e-21, 4.6224e-17, 1.0000e+00, 1.7153e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([3.9434e-35, 7.7635e-25, 1.7614e-41, 1.8530e-28, 5.1142e-22, 3.6474e-26,\n",
            "        0.0000e+00, 4.8866e-32, 1.4013e-45, 1.0725e-26, 7.0983e-29, 2.9391e-33,\n",
            "        5.5650e-21, 5.7622e-17, 1.0000e+00, 2.1910e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.4646e-35, 5.5694e-25, 1.0116e-41, 1.2675e-28, 3.8299e-22, 2.5805e-26,\n",
            "        0.0000e+00, 3.1951e-32, 0.0000e+00, 7.5126e-27, 4.8429e-29, 1.8815e-33,\n",
            "        4.2245e-21, 4.6224e-17, 1.0000e+00, 1.7153e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([3.9434e-35, 7.7635e-25, 1.7614e-41, 1.8530e-28, 5.1142e-22, 3.6474e-26,\n",
            "        0.0000e+00, 4.8866e-32, 1.4013e-45, 1.0725e-26, 7.0983e-29, 2.9391e-33,\n",
            "        5.5650e-21, 5.7622e-17, 1.0000e+00, 2.1910e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.4646e-35, 5.5694e-25, 1.0116e-41, 1.2675e-28, 3.8299e-22, 2.5805e-26,\n",
            "        0.0000e+00, 3.1951e-32, 0.0000e+00, 7.5126e-27, 4.8429e-29, 1.8815e-33,\n",
            "        4.2245e-21, 4.6224e-17, 1.0000e+00, 1.7153e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([3.9434e-35, 7.7635e-25, 1.7614e-41, 1.8530e-28, 5.1142e-22, 3.6474e-26,\n",
            "        0.0000e+00, 4.8866e-32, 1.4013e-45, 1.0725e-26, 7.0983e-29, 2.9391e-33,\n",
            "        5.5650e-21, 5.7622e-17, 1.0000e+00, 2.1910e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.4646e-35, 5.5694e-25, 1.0116e-41, 1.2675e-28, 3.8299e-22, 2.5805e-26,\n",
            "        0.0000e+00, 3.1951e-32, 0.0000e+00, 7.5126e-27, 4.8429e-29, 1.8815e-33,\n",
            "        4.2245e-21, 4.6224e-17, 1.0000e+00, 1.7153e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([3.9434e-35, 7.7635e-25, 1.7614e-41, 1.8530e-28, 5.1142e-22, 3.6474e-26,\n",
            "        0.0000e+00, 4.8866e-32, 1.4013e-45, 1.0725e-26, 7.0983e-29, 2.9391e-33,\n",
            "        5.5650e-21, 5.7622e-17, 1.0000e+00, 2.1910e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([2.4646e-35, 5.5694e-25, 1.0116e-41, 1.2675e-28, 3.8299e-22, 2.5805e-26,\n",
            "        0.0000e+00, 3.1951e-32, 0.0000e+00, 7.5126e-27, 4.8429e-29, 1.8815e-33,\n",
            "        4.2245e-21, 4.6224e-17, 1.0000e+00, 1.7153e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([3.9434e-35, 7.7635e-25, 1.7614e-41, 1.8530e-28, 5.1142e-22, 3.6474e-26,\n",
            "        0.0000e+00, 4.8866e-32, 1.4013e-45, 1.0725e-26, 7.0983e-29, 2.9391e-33,\n",
            "        5.5650e-21, 5.7622e-17, 1.0000e+00, 2.1910e-18],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(-0.4993, grad_fn=<SubBackward0>), tensor(0.4690, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-0.2957)\n",
            "return\n",
            "tensor(0.9462)\n",
            "return\n",
            "tensor(0.4187)\n",
            "return\n",
            "tensor(-0.7736)\n",
            "return\n",
            "tensor(-0.8682)\n",
            "return\n",
            "tensor(0.3755)\n",
            "return\n",
            "tensor(-1.5089)\n",
            "return\n",
            "tensor(-0.6774)\n",
            "return\n",
            "tensor(1.6240)\n",
            "return\n",
            "tensor(0.4481)\n",
            "return\n",
            "tensor(-0.5393)\n",
            "return\n",
            "tensor(-1.3559)\n",
            "return\n",
            "tensor(-0.1321)\n",
            "return\n",
            "tensor(0.8818)\n",
            "return\n",
            "tensor(1.8787)\n",
            "return\n",
            "tensor(0.9614)\n",
            "return\n",
            "tensor(-0.5452)\n",
            "return\n",
            "tensor(-1.4609)\n",
            "return\n",
            "tensor(-0.3097)\n",
            "return\n",
            "tensor(0.9324)\n",
            "loss\n",
            "tensor(1.4211e-15, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([4.0864e-40, 4.8986e-29, 0.0000e+00, 9.2753e-33, 1.6800e-25, 3.4212e-30,\n",
            "        0.0000e+00, 1.0103e-36, 0.0000e+00, 6.5858e-31, 2.4160e-33, 2.7332e-38,\n",
            "        3.7377e-24, 2.7927e-19, 1.0000e+00, 1.7884e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([6.8156e-40, 7.0957e-29, 0.0000e+00, 1.4073e-32, 2.3133e-25, 5.0084e-30,\n",
            "        0.0000e+00, 1.6074e-36, 0.0000e+00, 9.7586e-31, 3.6817e-33, 4.4594e-38,\n",
            "        5.0607e-24, 3.5481e-19, 1.0000e+00, 2.3500e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([4.0864e-40, 4.8986e-29, 0.0000e+00, 9.2753e-33, 1.6800e-25, 3.4212e-30,\n",
            "        0.0000e+00, 1.0103e-36, 0.0000e+00, 6.5858e-31, 2.4160e-33, 2.7332e-38,\n",
            "        3.7377e-24, 2.7927e-19, 1.0000e+00, 1.7884e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([6.8156e-40, 7.0957e-29, 0.0000e+00, 1.4073e-32, 2.3133e-25, 5.0084e-30,\n",
            "        0.0000e+00, 1.6074e-36, 0.0000e+00, 9.7586e-31, 3.6817e-33, 4.4594e-38,\n",
            "        5.0607e-24, 3.5481e-19, 1.0000e+00, 2.3500e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([4.0864e-40, 4.8986e-29, 0.0000e+00, 9.2753e-33, 1.6800e-25, 3.4212e-30,\n",
            "        0.0000e+00, 1.0103e-36, 0.0000e+00, 6.5858e-31, 2.4160e-33, 2.7332e-38,\n",
            "        3.7377e-24, 2.7927e-19, 1.0000e+00, 1.7884e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([6.8156e-40, 7.0957e-29, 0.0000e+00, 1.4073e-32, 2.3133e-25, 5.0084e-30,\n",
            "        0.0000e+00, 1.6074e-36, 0.0000e+00, 9.7586e-31, 3.6817e-33, 4.4594e-38,\n",
            "        5.0607e-24, 3.5481e-19, 1.0000e+00, 2.3500e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([4.0864e-40, 4.8986e-29, 0.0000e+00, 9.2753e-33, 1.6800e-25, 3.4212e-30,\n",
            "        0.0000e+00, 1.0103e-36, 0.0000e+00, 6.5858e-31, 2.4160e-33, 2.7332e-38,\n",
            "        3.7377e-24, 2.7927e-19, 1.0000e+00, 1.7884e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([6.8156e-40, 7.0957e-29, 0.0000e+00, 1.4073e-32, 2.3133e-25, 5.0084e-30,\n",
            "        0.0000e+00, 1.6074e-36, 0.0000e+00, 9.7586e-31, 3.6817e-33, 4.4594e-38,\n",
            "        5.0607e-24, 3.5481e-19, 1.0000e+00, 2.3500e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([4.0864e-40, 4.8986e-29, 0.0000e+00, 9.2753e-33, 1.6800e-25, 3.4212e-30,\n",
            "        0.0000e+00, 1.0103e-36, 0.0000e+00, 6.5858e-31, 2.4160e-33, 2.7332e-38,\n",
            "        3.7377e-24, 2.7927e-19, 1.0000e+00, 1.7884e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([6.8156e-40, 7.0957e-29, 0.0000e+00, 1.4073e-32, 2.3133e-25, 5.0084e-30,\n",
            "        0.0000e+00, 1.6074e-36, 0.0000e+00, 9.7586e-31, 3.6817e-33, 4.4594e-38,\n",
            "        5.0607e-24, 3.5481e-19, 1.0000e+00, 2.3500e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([4.0864e-40, 4.8986e-29, 0.0000e+00, 9.2753e-33, 1.6800e-25, 3.4212e-30,\n",
            "        0.0000e+00, 1.0103e-36, 0.0000e+00, 6.5858e-31, 2.4160e-33, 2.7332e-38,\n",
            "        3.7377e-24, 2.7927e-19, 1.0000e+00, 1.7884e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([6.8156e-40, 7.0957e-29, 0.0000e+00, 1.4073e-32, 2.3133e-25, 5.0084e-30,\n",
            "        0.0000e+00, 1.6074e-36, 0.0000e+00, 9.7586e-31, 3.6817e-33, 4.4594e-38,\n",
            "        5.0607e-24, 3.5481e-19, 1.0000e+00, 2.3500e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([4.0864e-40, 4.8986e-29, 0.0000e+00, 9.2753e-33, 1.6800e-25, 3.4212e-30,\n",
            "        0.0000e+00, 1.0103e-36, 0.0000e+00, 6.5858e-31, 2.4160e-33, 2.7332e-38,\n",
            "        3.7377e-24, 2.7927e-19, 1.0000e+00, 1.7884e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([6.8156e-40, 7.0957e-29, 0.0000e+00, 1.4073e-32, 2.3133e-25, 5.0084e-30,\n",
            "        0.0000e+00, 1.6074e-36, 0.0000e+00, 9.7586e-31, 3.6817e-33, 4.4594e-38,\n",
            "        5.0607e-24, 3.5481e-19, 1.0000e+00, 2.3500e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([4.0864e-40, 4.8986e-29, 0.0000e+00, 9.2753e-33, 1.6800e-25, 3.4212e-30,\n",
            "        0.0000e+00, 1.0103e-36, 0.0000e+00, 6.5858e-31, 2.4160e-33, 2.7332e-38,\n",
            "        3.7377e-24, 2.7927e-19, 1.0000e+00, 1.7884e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([6.8156e-40, 7.0957e-29, 0.0000e+00, 1.4073e-32, 2.3133e-25, 5.0084e-30,\n",
            "        0.0000e+00, 1.6074e-36, 0.0000e+00, 9.7586e-31, 3.6817e-33, 4.4594e-38,\n",
            "        5.0607e-24, 3.5481e-19, 1.0000e+00, 2.3500e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([4.0864e-40, 4.8986e-29, 0.0000e+00, 9.2753e-33, 1.6800e-25, 3.4212e-30,\n",
            "        0.0000e+00, 1.0103e-36, 0.0000e+00, 6.5858e-31, 2.4160e-33, 2.7332e-38,\n",
            "        3.7377e-24, 2.7927e-19, 1.0000e+00, 1.7884e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([6.8156e-40, 7.0957e-29, 0.0000e+00, 1.4073e-32, 2.3133e-25, 5.0084e-30,\n",
            "        0.0000e+00, 1.6074e-36, 0.0000e+00, 9.7586e-31, 3.6817e-33, 4.4594e-38,\n",
            "        5.0607e-24, 3.5481e-19, 1.0000e+00, 2.3500e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([4.0864e-40, 4.8986e-29, 0.0000e+00, 9.2753e-33, 1.6800e-25, 3.4212e-30,\n",
            "        0.0000e+00, 1.0103e-36, 0.0000e+00, 6.5858e-31, 2.4160e-33, 2.7332e-38,\n",
            "        3.7377e-24, 2.7927e-19, 1.0000e+00, 1.7884e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([6.8156e-40, 7.0957e-29, 0.0000e+00, 1.4073e-32, 2.3133e-25, 5.0084e-30,\n",
            "        0.0000e+00, 1.6074e-36, 0.0000e+00, 9.7586e-31, 3.6817e-33, 4.4594e-38,\n",
            "        5.0607e-24, 3.5481e-19, 1.0000e+00, 2.3500e-21],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.3154, grad_fn=<SubBackward0>), tensor(-0.4959, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-0.1894)\n",
            "return\n",
            "tensor(0.8653)\n",
            "return\n",
            "tensor(-0.9754)\n",
            "return\n",
            "tensor(-1.0140)\n",
            "return\n",
            "tensor(1.0877)\n",
            "return\n",
            "tensor(0.4712)\n",
            "return\n",
            "tensor(-0.4850)\n",
            "return\n",
            "tensor(-0.8659)\n",
            "return\n",
            "tensor(1.2782)\n",
            "return\n",
            "tensor(0.7291)\n",
            "return\n",
            "tensor(1.3295)\n",
            "return\n",
            "tensor(0.9243)\n",
            "return\n",
            "tensor(-1.5398)\n",
            "return\n",
            "tensor(-0.5106)\n",
            "return\n",
            "tensor(-0.7980)\n",
            "return\n",
            "tensor(-1.0081)\n",
            "return\n",
            "tensor(1.6113)\n",
            "return\n",
            "tensor(0.7518)\n",
            "return\n",
            "tensor(-0.4918)\n",
            "return\n",
            "tensor(-1.1705)\n",
            "loss\n",
            "tensor(-2.8422e-15, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([5.6052e-45, 3.4077e-33, 0.0000e+00, 5.8848e-37, 6.2904e-29, 3.9103e-34,\n",
            "        0.0000e+00, 2.8109e-41, 0.0000e+00, 4.8285e-35, 1.0176e-37, 3.3631e-43,\n",
            "        2.9705e-27, 1.6441e-21, 1.0000e+00, 1.5656e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1210e-44, 5.1336e-33, 0.0000e+00, 9.2744e-37, 8.9385e-29, 5.9336e-34,\n",
            "        0.0000e+00, 4.6558e-41, 0.0000e+00, 7.4324e-35, 1.6135e-37, 5.7313e-43,\n",
            "        4.1362e-27, 2.1297e-21, 1.0000e+00, 2.1175e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([5.6052e-45, 3.4077e-33, 0.0000e+00, 5.8848e-37, 6.2904e-29, 3.9103e-34,\n",
            "        0.0000e+00, 2.8109e-41, 0.0000e+00, 4.8285e-35, 1.0176e-37, 3.3631e-43,\n",
            "        2.9705e-27, 1.6441e-21, 1.0000e+00, 1.5656e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1210e-44, 5.1336e-33, 0.0000e+00, 9.2744e-37, 8.9385e-29, 5.9336e-34,\n",
            "        0.0000e+00, 4.6558e-41, 0.0000e+00, 7.4324e-35, 1.6135e-37, 5.7313e-43,\n",
            "        4.1362e-27, 2.1297e-21, 1.0000e+00, 2.1175e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([5.6052e-45, 3.4077e-33, 0.0000e+00, 5.8848e-37, 6.2904e-29, 3.9103e-34,\n",
            "        0.0000e+00, 2.8109e-41, 0.0000e+00, 4.8285e-35, 1.0176e-37, 3.3631e-43,\n",
            "        2.9705e-27, 1.6441e-21, 1.0000e+00, 1.5656e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1210e-44, 5.1336e-33, 0.0000e+00, 9.2744e-37, 8.9385e-29, 5.9336e-34,\n",
            "        0.0000e+00, 4.6558e-41, 0.0000e+00, 7.4324e-35, 1.6135e-37, 5.7313e-43,\n",
            "        4.1362e-27, 2.1297e-21, 1.0000e+00, 2.1175e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([5.6052e-45, 3.4077e-33, 0.0000e+00, 5.8848e-37, 6.2904e-29, 3.9103e-34,\n",
            "        0.0000e+00, 2.8109e-41, 0.0000e+00, 4.8285e-35, 1.0176e-37, 3.3631e-43,\n",
            "        2.9705e-27, 1.6441e-21, 1.0000e+00, 1.5656e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1210e-44, 5.1336e-33, 0.0000e+00, 9.2744e-37, 8.9385e-29, 5.9336e-34,\n",
            "        0.0000e+00, 4.6558e-41, 0.0000e+00, 7.4324e-35, 1.6135e-37, 5.7313e-43,\n",
            "        4.1362e-27, 2.1297e-21, 1.0000e+00, 2.1175e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([5.6052e-45, 3.4077e-33, 0.0000e+00, 5.8848e-37, 6.2904e-29, 3.9103e-34,\n",
            "        0.0000e+00, 2.8109e-41, 0.0000e+00, 4.8285e-35, 1.0176e-37, 3.3631e-43,\n",
            "        2.9705e-27, 1.6441e-21, 1.0000e+00, 1.5656e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1210e-44, 5.1336e-33, 0.0000e+00, 9.2744e-37, 8.9385e-29, 5.9336e-34,\n",
            "        0.0000e+00, 4.6558e-41, 0.0000e+00, 7.4324e-35, 1.6135e-37, 5.7313e-43,\n",
            "        4.1362e-27, 2.1297e-21, 1.0000e+00, 2.1175e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([5.6052e-45, 3.4077e-33, 0.0000e+00, 5.8848e-37, 6.2904e-29, 3.9103e-34,\n",
            "        0.0000e+00, 2.8109e-41, 0.0000e+00, 4.8285e-35, 1.0176e-37, 3.3631e-43,\n",
            "        2.9705e-27, 1.6441e-21, 1.0000e+00, 1.5656e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1210e-44, 5.1336e-33, 0.0000e+00, 9.2744e-37, 8.9385e-29, 5.9336e-34,\n",
            "        0.0000e+00, 4.6558e-41, 0.0000e+00, 7.4324e-35, 1.6135e-37, 5.7313e-43,\n",
            "        4.1362e-27, 2.1297e-21, 1.0000e+00, 2.1175e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([5.6052e-45, 3.4077e-33, 0.0000e+00, 5.8848e-37, 6.2904e-29, 3.9103e-34,\n",
            "        0.0000e+00, 2.8109e-41, 0.0000e+00, 4.8285e-35, 1.0176e-37, 3.3631e-43,\n",
            "        2.9705e-27, 1.6441e-21, 1.0000e+00, 1.5656e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1210e-44, 5.1336e-33, 0.0000e+00, 9.2744e-37, 8.9385e-29, 5.9336e-34,\n",
            "        0.0000e+00, 4.6558e-41, 0.0000e+00, 7.4324e-35, 1.6135e-37, 5.7313e-43,\n",
            "        4.1362e-27, 2.1297e-21, 1.0000e+00, 2.1175e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([5.6052e-45, 3.4077e-33, 0.0000e+00, 5.8848e-37, 6.2904e-29, 3.9103e-34,\n",
            "        0.0000e+00, 2.8109e-41, 0.0000e+00, 4.8285e-35, 1.0176e-37, 3.3631e-43,\n",
            "        2.9705e-27, 1.6441e-21, 1.0000e+00, 1.5656e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1210e-44, 5.1336e-33, 0.0000e+00, 9.2744e-37, 8.9385e-29, 5.9336e-34,\n",
            "        0.0000e+00, 4.6558e-41, 0.0000e+00, 7.4324e-35, 1.6135e-37, 5.7313e-43,\n",
            "        4.1362e-27, 2.1297e-21, 1.0000e+00, 2.1175e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([5.6052e-45, 3.4077e-33, 0.0000e+00, 5.8848e-37, 6.2904e-29, 3.9103e-34,\n",
            "        0.0000e+00, 2.8109e-41, 0.0000e+00, 4.8285e-35, 1.0176e-37, 3.3631e-43,\n",
            "        2.9705e-27, 1.6441e-21, 1.0000e+00, 1.5656e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1210e-44, 5.1336e-33, 0.0000e+00, 9.2744e-37, 8.9385e-29, 5.9336e-34,\n",
            "        0.0000e+00, 4.6558e-41, 0.0000e+00, 7.4324e-35, 1.6135e-37, 5.7313e-43,\n",
            "        4.1362e-27, 2.1297e-21, 1.0000e+00, 2.1175e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([5.6052e-45, 3.4077e-33, 0.0000e+00, 5.8848e-37, 6.2904e-29, 3.9103e-34,\n",
            "        0.0000e+00, 2.8109e-41, 0.0000e+00, 4.8285e-35, 1.0176e-37, 3.3631e-43,\n",
            "        2.9705e-27, 1.6441e-21, 1.0000e+00, 1.5656e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([1.1210e-44, 5.1336e-33, 0.0000e+00, 9.2744e-37, 8.9385e-29, 5.9336e-34,\n",
            "        0.0000e+00, 4.6558e-41, 0.0000e+00, 7.4324e-35, 1.6135e-37, 5.7313e-43,\n",
            "        4.1362e-27, 2.1297e-21, 1.0000e+00, 2.1175e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.1641, grad_fn=<SubBackward0>), tensor(0.2336, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-1.8686)\n",
            "return\n",
            "tensor(-1.1540)\n",
            "return\n",
            "tensor(1.4163)\n",
            "return\n",
            "tensor(0.7540)\n",
            "return\n",
            "tensor(-0.1655)\n",
            "return\n",
            "tensor(0.6871)\n",
            "return\n",
            "tensor(0.5159)\n",
            "return\n",
            "tensor(0.6581)\n",
            "return\n",
            "tensor(0.9235)\n",
            "return\n",
            "tensor(0.0813)\n",
            "return\n",
            "tensor(1.7264)\n",
            "return\n",
            "tensor(0.7185)\n",
            "return\n",
            "tensor(-0.0534)\n",
            "return\n",
            "tensor(-0.4488)\n",
            "return\n",
            "tensor(-0.5989)\n",
            "return\n",
            "tensor(-1.4787)\n",
            "return\n",
            "tensor(-1.3814)\n",
            "return\n",
            "tensor(-1.0361)\n",
            "return\n",
            "tensor(0.5370)\n",
            "return\n",
            "tensor(0.1675)\n",
            "loss\n",
            "tensor(-7.1054e-16, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.1110e-37, 0.0000e+00, 3.6096e-41, 2.2073e-32, 4.2763e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 3.3103e-39, 4.0624e-42, 0.0000e+00,\n",
            "        2.2995e-30, 9.9424e-24, 1.0000e+00, 1.2559e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 3.3034e-37, 0.0000e+00, 5.8999e-41, 3.2333e-32, 6.7167e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 5.2861e-39, 6.6940e-42, 0.0000e+00,\n",
            "        3.2893e-30, 1.3119e-23, 1.0000e+00, 1.7469e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.1110e-37, 0.0000e+00, 3.6096e-41, 2.2073e-32, 4.2763e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 3.3103e-39, 4.0624e-42, 0.0000e+00,\n",
            "        2.2995e-30, 9.9424e-24, 1.0000e+00, 1.2559e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 3.3034e-37, 0.0000e+00, 5.8999e-41, 3.2333e-32, 6.7167e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 5.2861e-39, 6.6940e-42, 0.0000e+00,\n",
            "        3.2893e-30, 1.3119e-23, 1.0000e+00, 1.7469e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.1110e-37, 0.0000e+00, 3.6096e-41, 2.2073e-32, 4.2763e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 3.3103e-39, 4.0624e-42, 0.0000e+00,\n",
            "        2.2995e-30, 9.9424e-24, 1.0000e+00, 1.2559e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 3.3034e-37, 0.0000e+00, 5.8999e-41, 3.2333e-32, 6.7167e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 5.2861e-39, 6.6940e-42, 0.0000e+00,\n",
            "        3.2893e-30, 1.3119e-23, 1.0000e+00, 1.7469e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.1110e-37, 0.0000e+00, 3.6096e-41, 2.2073e-32, 4.2763e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 3.3103e-39, 4.0624e-42, 0.0000e+00,\n",
            "        2.2995e-30, 9.9424e-24, 1.0000e+00, 1.2559e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 3.3034e-37, 0.0000e+00, 5.8999e-41, 3.2333e-32, 6.7167e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 5.2861e-39, 6.6940e-42, 0.0000e+00,\n",
            "        3.2893e-30, 1.3119e-23, 1.0000e+00, 1.7469e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.1110e-37, 0.0000e+00, 3.6096e-41, 2.2073e-32, 4.2763e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 3.3103e-39, 4.0624e-42, 0.0000e+00,\n",
            "        2.2995e-30, 9.9424e-24, 1.0000e+00, 1.2559e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 3.3034e-37, 0.0000e+00, 5.8999e-41, 3.2333e-32, 6.7167e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 5.2861e-39, 6.6940e-42, 0.0000e+00,\n",
            "        3.2893e-30, 1.3119e-23, 1.0000e+00, 1.7469e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.1110e-37, 0.0000e+00, 3.6096e-41, 2.2073e-32, 4.2763e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 3.3103e-39, 4.0624e-42, 0.0000e+00,\n",
            "        2.2995e-30, 9.9424e-24, 1.0000e+00, 1.2559e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 3.3034e-37, 0.0000e+00, 5.8999e-41, 3.2333e-32, 6.7167e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 5.2861e-39, 6.6940e-42, 0.0000e+00,\n",
            "        3.2893e-30, 1.3119e-23, 1.0000e+00, 1.7469e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.1110e-37, 0.0000e+00, 3.6096e-41, 2.2073e-32, 4.2763e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 3.3103e-39, 4.0624e-42, 0.0000e+00,\n",
            "        2.2995e-30, 9.9424e-24, 1.0000e+00, 1.2559e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 3.3034e-37, 0.0000e+00, 5.8999e-41, 3.2333e-32, 6.7167e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 5.2861e-39, 6.6940e-42, 0.0000e+00,\n",
            "        3.2893e-30, 1.3119e-23, 1.0000e+00, 1.7469e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.1110e-37, 0.0000e+00, 3.6096e-41, 2.2073e-32, 4.2763e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 3.3103e-39, 4.0624e-42, 0.0000e+00,\n",
            "        2.2995e-30, 9.9424e-24, 1.0000e+00, 1.2559e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 3.3034e-37, 0.0000e+00, 5.8999e-41, 3.2333e-32, 6.7167e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 5.2861e-39, 6.6940e-42, 0.0000e+00,\n",
            "        3.2893e-30, 1.3119e-23, 1.0000e+00, 1.7469e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.1110e-37, 0.0000e+00, 3.6096e-41, 2.2073e-32, 4.2763e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 3.3103e-39, 4.0624e-42, 0.0000e+00,\n",
            "        2.2995e-30, 9.9424e-24, 1.0000e+00, 1.2559e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 3.3034e-37, 0.0000e+00, 5.8999e-41, 3.2333e-32, 6.7167e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 5.2861e-39, 6.6940e-42, 0.0000e+00,\n",
            "        3.2893e-30, 1.3119e-23, 1.0000e+00, 1.7469e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.1110e-37, 0.0000e+00, 3.6096e-41, 2.2073e-32, 4.2763e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 3.3103e-39, 4.0624e-42, 0.0000e+00,\n",
            "        2.2995e-30, 9.9424e-24, 1.0000e+00, 1.2559e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 3.3034e-37, 0.0000e+00, 5.8999e-41, 3.2333e-32, 6.7167e-38,\n",
            "        0.0000e+00, 1.4013e-45, 0.0000e+00, 5.2861e-39, 6.6940e-42, 0.0000e+00,\n",
            "        3.2893e-30, 1.3119e-23, 1.0000e+00, 1.7469e-27],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.4361, grad_fn=<SubBackward0>), tensor(0.4540, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-0.1294)\n",
            "return\n",
            "tensor(0.4230)\n",
            "return\n",
            "tensor(0.8794)\n",
            "return\n",
            "tensor(0.0367)\n",
            "return\n",
            "tensor(-0.0807)\n",
            "return\n",
            "tensor(-0.1368)\n",
            "return\n",
            "tensor(1.4973)\n",
            "return\n",
            "tensor(0.4643)\n",
            "return\n",
            "tensor(0.7828)\n",
            "return\n",
            "tensor(0.1221)\n",
            "return\n",
            "tensor(-1.6127)\n",
            "return\n",
            "tensor(-1.5717)\n",
            "return\n",
            "tensor(-2.0499)\n",
            "return\n",
            "tensor(-1.5653)\n",
            "return\n",
            "tensor(-0.2444)\n",
            "return\n",
            "tensor(0.4689)\n",
            "return\n",
            "tensor(0.8650)\n",
            "return\n",
            "tensor(-0.0098)\n",
            "return\n",
            "tensor(1.3975)\n",
            "return\n",
            "tensor(0.4635)\n",
            "loss\n",
            "tensor(-9.2371e-15, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.2899e-41, 0.0000e+00, 2.8026e-45, 7.8602e-36, 4.8849e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3262e-43, 0.0000e+00, 0.0000e+00,\n",
            "        1.8557e-33, 6.4452e-26, 1.0000e+00, 9.9558e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.0878e-41, 0.0000e+00, 4.2039e-45, 1.1825e-35, 7.9061e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8536e-43, 0.0000e+00, 0.0000e+00,\n",
            "        2.7174e-33, 8.6389e-26, 1.0000e+00, 1.4198e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.2899e-41, 0.0000e+00, 2.8026e-45, 7.8602e-36, 4.8849e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3262e-43, 0.0000e+00, 0.0000e+00,\n",
            "        1.8557e-33, 6.4452e-26, 1.0000e+00, 9.9558e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.0878e-41, 0.0000e+00, 4.2039e-45, 1.1825e-35, 7.9061e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8536e-43, 0.0000e+00, 0.0000e+00,\n",
            "        2.7174e-33, 8.6389e-26, 1.0000e+00, 1.4198e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.2899e-41, 0.0000e+00, 2.8026e-45, 7.8602e-36, 4.8849e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3262e-43, 0.0000e+00, 0.0000e+00,\n",
            "        1.8557e-33, 6.4452e-26, 1.0000e+00, 9.9558e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.0878e-41, 0.0000e+00, 4.2039e-45, 1.1825e-35, 7.9061e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8536e-43, 0.0000e+00, 0.0000e+00,\n",
            "        2.7174e-33, 8.6389e-26, 1.0000e+00, 1.4198e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.2899e-41, 0.0000e+00, 2.8026e-45, 7.8602e-36, 4.8849e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3262e-43, 0.0000e+00, 0.0000e+00,\n",
            "        1.8557e-33, 6.4452e-26, 1.0000e+00, 9.9558e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.0878e-41, 0.0000e+00, 4.2039e-45, 1.1825e-35, 7.9061e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8536e-43, 0.0000e+00, 0.0000e+00,\n",
            "        2.7174e-33, 8.6389e-26, 1.0000e+00, 1.4198e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.2899e-41, 0.0000e+00, 2.8026e-45, 7.8602e-36, 4.8849e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3262e-43, 0.0000e+00, 0.0000e+00,\n",
            "        1.8557e-33, 6.4452e-26, 1.0000e+00, 9.9558e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.0878e-41, 0.0000e+00, 4.2039e-45, 1.1825e-35, 7.9061e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8536e-43, 0.0000e+00, 0.0000e+00,\n",
            "        2.7174e-33, 8.6389e-26, 1.0000e+00, 1.4198e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.2899e-41, 0.0000e+00, 2.8026e-45, 7.8602e-36, 4.8849e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3262e-43, 0.0000e+00, 0.0000e+00,\n",
            "        1.8557e-33, 6.4452e-26, 1.0000e+00, 9.9558e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.0878e-41, 0.0000e+00, 4.2039e-45, 1.1825e-35, 7.9061e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8536e-43, 0.0000e+00, 0.0000e+00,\n",
            "        2.7174e-33, 8.6389e-26, 1.0000e+00, 1.4198e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.2899e-41, 0.0000e+00, 2.8026e-45, 7.8602e-36, 4.8849e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3262e-43, 0.0000e+00, 0.0000e+00,\n",
            "        1.8557e-33, 6.4452e-26, 1.0000e+00, 9.9558e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.0878e-41, 0.0000e+00, 4.2039e-45, 1.1825e-35, 7.9061e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8536e-43, 0.0000e+00, 0.0000e+00,\n",
            "        2.7174e-33, 8.6389e-26, 1.0000e+00, 1.4198e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.2899e-41, 0.0000e+00, 2.8026e-45, 7.8602e-36, 4.8849e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3262e-43, 0.0000e+00, 0.0000e+00,\n",
            "        1.8557e-33, 6.4452e-26, 1.0000e+00, 9.9558e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.0878e-41, 0.0000e+00, 4.2039e-45, 1.1825e-35, 7.9061e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8536e-43, 0.0000e+00, 0.0000e+00,\n",
            "        2.7174e-33, 8.6389e-26, 1.0000e+00, 1.4198e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.2899e-41, 0.0000e+00, 2.8026e-45, 7.8602e-36, 4.8849e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3262e-43, 0.0000e+00, 0.0000e+00,\n",
            "        1.8557e-33, 6.4452e-26, 1.0000e+00, 9.9558e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.0878e-41, 0.0000e+00, 4.2039e-45, 1.1825e-35, 7.9061e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8536e-43, 0.0000e+00, 0.0000e+00,\n",
            "        2.7174e-33, 8.6389e-26, 1.0000e+00, 1.4198e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.2899e-41, 0.0000e+00, 2.8026e-45, 7.8602e-36, 4.8849e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3262e-43, 0.0000e+00, 0.0000e+00,\n",
            "        1.8557e-33, 6.4452e-26, 1.0000e+00, 9.9558e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 2.0878e-41, 0.0000e+00, 4.2039e-45, 1.1825e-35, 7.9061e-42,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8536e-43, 0.0000e+00, 0.0000e+00,\n",
            "        2.7174e-33, 8.6389e-26, 1.0000e+00, 1.4198e-30],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(-0.2934, grad_fn=<SubBackward0>), tensor(0.2674, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(-0.5309)\n",
            "return\n",
            "tensor(1.0595)\n",
            "return\n",
            "tensor(-0.0967)\n",
            "return\n",
            "tensor(0.9437)\n",
            "return\n",
            "tensor(-1.3880)\n",
            "return\n",
            "tensor(-1.8870)\n",
            "return\n",
            "tensor(-0.5655)\n",
            "return\n",
            "tensor(-0.2319)\n",
            "return\n",
            "tensor(0.4566)\n",
            "return\n",
            "tensor(1.2124)\n",
            "return\n",
            "tensor(-0.0201)\n",
            "return\n",
            "tensor(0.1753)\n",
            "return\n",
            "tensor(0.2878)\n",
            "return\n",
            "tensor(-1.2412)\n",
            "return\n",
            "tensor(1.9946)\n",
            "return\n",
            "tensor(1.1814)\n",
            "return\n",
            "tensor(-0.1599)\n",
            "return\n",
            "tensor(-1.2750)\n",
            "return\n",
            "tensor(-0.4439)\n",
            "return\n",
            "tensor(0.5289)\n",
            "loss\n",
            "tensor(-8.5265e-15, grad_fn=<DivBackward0>)\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 3.0465e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6562e-36, 4.6440e-28, 1.0000e+00, 8.3389e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 4.7072e-39, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4829e-36, 6.3233e-28, 1.0000e+00, 1.2191e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 3.0465e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6562e-36, 4.6440e-28, 1.0000e+00, 8.3389e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 4.7072e-39, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4829e-36, 6.3233e-28, 1.0000e+00, 1.2191e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 3.0465e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6562e-36, 4.6440e-28, 1.0000e+00, 8.3389e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 4.7072e-39, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4829e-36, 6.3233e-28, 1.0000e+00, 1.2191e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 3.0465e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6562e-36, 4.6440e-28, 1.0000e+00, 8.3389e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 4.7072e-39, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4829e-36, 6.3233e-28, 1.0000e+00, 1.2191e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 3.0465e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6562e-36, 4.6440e-28, 1.0000e+00, 8.3389e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 4.7072e-39, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4829e-36, 6.3233e-28, 1.0000e+00, 1.2191e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 3.0465e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6562e-36, 4.6440e-28, 1.0000e+00, 8.3389e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 4.7072e-39, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4829e-36, 6.3233e-28, 1.0000e+00, 1.2191e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 3.0465e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6562e-36, 4.6440e-28, 1.0000e+00, 8.3389e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 4.7072e-39, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4829e-36, 6.3233e-28, 1.0000e+00, 1.2191e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 3.0465e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6562e-36, 4.6440e-28, 1.0000e+00, 8.3389e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 4.7072e-39, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4829e-36, 6.3233e-28, 1.0000e+00, 1.2191e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 3.0465e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6562e-36, 4.6440e-28, 1.0000e+00, 8.3389e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 4.7072e-39, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4829e-36, 6.3233e-28, 1.0000e+00, 1.2191e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "for loop newdegree counter\n",
            "0\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 3.0465e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6562e-36, 4.6440e-28, 1.0000e+00, 8.3389e-34],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "for loop newdegree counter\n",
            "1\n",
            "softmax\n",
            "tensor([0.0000e+00, 1.4013e-45, 0.0000e+00, 0.0000e+00, 4.7072e-39, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.4829e-36, 6.3233e-28, 1.0000e+00, 1.2191e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "explainer output\n",
            "tensor(14)\n",
            "reward\n",
            "2\n",
            "reward\n",
            "2\n",
            "[tensor(0.3895, grad_fn=<SubBackward0>), tensor(-0.4992, grad_fn=<SubBackward0>)]\n",
            "DiscountedReturns\n",
            "20\n",
            "Advantage Function\n",
            "20\n",
            "return\n",
            "tensor(1.4407)\n",
            "return\n",
            "tensor(0.6129)\n",
            "return\n",
            "tensor(0.9556)\n",
            "return\n",
            "tensor(0.5923)\n",
            "return\n",
            "tensor(0.5581)\n",
            "return\n",
            "tensor(-0.4859)\n",
            "return\n",
            "tensor(0.2741)\n",
            "return\n",
            "tensor(0.6096)\n",
            "return\n",
            "tensor(0.9175)\n",
            "return\n",
            "tensor(0.4075)\n",
            "return\n",
            "tensor(-0.2631)\n",
            "return\n",
            "tensor(-0.9145)\n",
            "return\n",
            "tensor(-0.7612)\n",
            "return\n",
            "tensor(-1.5121)\n",
            "return\n",
            "tensor(1.6180)\n",
            "return\n",
            "tensor(0.6263)\n",
            "return\n",
            "tensor(-0.5626)\n",
            "return\n",
            "tensor(-1.6664)\n",
            "return\n",
            "tensor(-0.7684)\n",
            "return\n",
            "tensor(-1.6784)\n",
            "loss\n",
            "tensor(1.4211e-15, grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXRU5cHH8e9kX4CyBgyrgAZJIEJAEAEVopVNkLYmLQqoLNVGRUCILOqrVttKET2voi+gILaIooCy7xrKmrAkYRMkQlVOWCSBkJBt7vvHlUgkCRPIzJ2Z/D7n5ESZOzO/yPE3T577PPfaDMNARERcw8fqACIi1YlKV0TEhVS6IiIupNIVEXEhla6IiAv5VfRg/fr1jRYtWrgoioiId0hJSTltGEaDsh6rsHRbtGhBcnKyc1KJiHgpm812rLzHNL0gIuJCKl0RERdS6YqIuJBKV0TEhVS6IiIupNIVEXEhla6IiAupdEVEXEilKyLiQipdEREXqnAbsIiISxw+DDt3Qn4+hIdDr17g7291KqdQ6YqIdTZsgEmTIDUV/PzAbgdfX/DxgSeegMmTISTE6pRVStMLImKN996D/v1h+3bIy4Pz5+HCBTh3DrKyYPp06NIFsrOtTlqlVLoi4nobNsAzz5hlW56LF81ph0GDXJfLBVS6IuJ6kydXXLiX5OfDjh2wZ4/zM7mISldEXOvwYdi71/Hj8/PNqQYvodIVEddKTjZPmjmquBj+8x/n5XExla6IuFZ+vrlKoTIKCpyTxQIqXRFxrRtuMJeFVfY5XkKlKyKu1auXuQ7XQUaNGvCXvzgxkGupdEXEtfz9zRINCnLo8Ny8PI537erkUK6j0hUR15s0iTN165J/lcOM4GBWPPwwMd27M3fuXAzDcEk8Z1LpiojLffzFF9xht2Pv0sXc5vvrOd4aNaBGDWyLFvGHDz5g3bp1TJ8+ncGDB3Py5ElrQlcRla6IuNSqVat4+umn+XTNGoK3bTOXg/3pT9CyJTRpAp07w//+L5w8CX37AhAdHc3OnTuJiIggOjqapUuXWvxTXDtbRcP1Tp06GcnJyS6MIyLebMuWLQwcOJClS5fSrVu3a3qNzZs3M2zYMO68805mzJhBrVq1yj6woABOnzZP2tWvX7m1wdfJZrOlGIbRqazHNNIVEZdITU3lgQceYP78+ddcuADdu3dnz549+Pv70759ezZt2lT6gAMHYNQoqF0bWrc2R9B168K4cXDs2PX9EFXBMIxyv2JiYgwRket15MgRIzw83Pj444+r9HWXLVtmhIeHG2PHjjXy8vIM4913DSM42DD8/AwDSn8FBBhGSIhhLFlSpRnKAiQb5fSqRroi4lQnTpzg3nvvZerUqcTFxVXpa/fr14+9e/dy/PhxJrVujX3MGPNCOkVFVx5cUAC5ueb88VdfVWmOytCcrog4zdmzZ+nZsyfx8fFMnjzZae9jFBZSUKcOgRcuOPaENm3MaQgn0ZyuiLjchQsX6NevH/fccw+TJk1y6nvZli8nsBK73Dh+3Lw9kAVUuiJS5QoKCvjd737HzTffzLRp07DZbM59w08/Ne884aiLF2HZMuflqYBKV0SqVHFxMUOHDiUoKIjZs2fjU5kR6LU6c6Zyx9vtlX9OFdGNKUWkyhiGQUJCApmZmaxcuRI/F6yNPXfuHOfy8mhSmSf5+EC9es6KVPFbW/KuIuKVpk6dys6dO1m6dClBDl7QprIKCgpISkrihRde4I477qBx48bMysoiPzDQ8RcJCoIBA5yS72o00hWRKvHGG2+waNEikpKSyt8ldg0Mw2Dfvn2sXbuWdevWsXnzZm6++WZiY2N56aWX6NatG8H+/tCwoXmBdEc0awadylxc4HQqXRG5bvPmzWPGjBkkJSXRoEGD636977//nnXr1pV81ahRg9jYWB555BE+/PBD6pU1NfDOO/Doo+Za3IqEhMC77153xmul0hWRq8rPz+fUqVP4+vrSoEGDUnO1S5cuJTExkY0bN9KsWbNrev3s7Gw2bdrEunXrWLt2LadPn6Z3797Exsby8ssvc+ONN179ReLiIDsbxoyBwsIrN0gEBJjXX1iwAO6885pyVgWVroiUKy0tjWnTpvHJJ5/g4+ODYRj4+fkxatQonnrqKY4ePcrIkSNZsWIFbdq0cfh1CwoK2Lp1a8lINj09nW7duhEbG8uCBQuIjo6+tlUPo0ZBz57wxhswf765ARjMC6ePHg0JCdC8eeVftwppR5qIlGnGjBlMmjSJgoICiouLSz0WEBCAj48PAQEBLFmyhLvvvrvC1zIMg7S0tJKS3bx5M23atCE2NpbY2Fi6detW9SfeCgvNZWE+PuYFb9zkKmMa6YrIFT744AMmT55MXl5emY8X/Hx3XrvdTkBAQJnH/Pe//y01L1urVi1iY2MZMWIEH330EXXr1nVafsAc3TZq5Nz3uAYa6YpIKQUFBTRo0IBz5845dHx0dDR79uwhKyuLjRs3lpTs2bNnS+Zle/fuTYsWLZwb3I1opCsiDvvss8+w2+0OH79v3z7at2/Pd999VzIvu3DhQtq3b++a3WgeRqUrIqUsXLiQnJwch4+32+107dqVnTt3EliZDQrVlD6GRKSUs2fPVup4u91O7dq1VbgOUumKSCllbjyogJ+fn/NPinkRla6IlBIXF0doaKjDx/v7+9O/f38nJvIuKl0RKZGXl8ehQ4fIvdpW2su0adOGqKgoJ6byLipdEcEwDBYsWECbNm1ITU3l9ddfJyQk5KrPCw4O5p133nFBQu+h1Qsi1dyWLVsYO3YsxcXFfPTRR/To0QOAwMBAJkyYQGFhIUW/uo5BYGAgfn5+fPbZZ3Tt2tWK2B5LI12RaiojI4O4uDji4+NJSEhg+/btJYULkJCQQHJyMsOHDyc4OJigoCACAwOpXbs2Y8eO5dChQ/z2t7+18CfwTNqRJlLNZGdn8+qrrzJnzhzGjBnD2LFjrzqVUFhYyNmzZ/H19aVOnTra9HAVuhuwiFBUVMTMmTOJiIjgzJkzpKWlMWXKFIfmbv39/QkLC6NevXoq3OukOV0RL2cYBqtWrWLcuHHccMMNrF69mujoaKtjVVsqXREvlpaWxvjx4zl27BjTpk2jX79+zr8dulRIvyeIeKHMzExGjx5NbGwsAwYMIC0tjf79+6tw3YBKV8SL5OXl8dprrxEZGUmNGjU4ePAgCQkJ+Pv7Wx1NfqbpBREvYBgGH3/8MYmJiXTq1Ilt27bRunVrq2NJGVS6Ih7u0uaGoqIi5s+fT8+ePa2OJBVQ6Yp4qIyMDBITE9myZQuvvvoqQ4YM0XIuD6C/IREPk52dzcSJE+nUqRNRUVEcOnSIhx9+WIXrIfS3JOIhLt/ccPr0adLS0pg6dapDmxvEfWh6QcQDrFy5kvHjx9OwYUNWrVrFrbfeanUkuUYqXRE3lp6ezvjx48nIyGDatGlaa+sFNL0g4oYyMzP585//TK9evejXrx/p6ekMGDBAhesFVLoibuTixYv87W9/IzIyktDQUA4dOsSTTz6pzQ1eRNMLIm7AMAwWLlxIYmIiMTEx2tzgxVS6IlXo4kVYtAhefx2OHAHDgMaNYcwYePhhqFXryuds3bqVsWPHUlhYyIcffqjNDV5O0wsiVWTvXmjWDB5/HFJTITcX8vLM8p040Szfdet+Of67774jPj6eBx98kCeeeIIdO3aocKsBla5IFfjmG+jZE06dgpycKx+/cMH884EDYeXKnJJphLZt23Lw4EFtbqhGNL0gUgVGjIDz569+XG4u9O+fzdChJ0lLSyM8PNz54cStqHRFrtO338LOneb8rSOCghoxdOj7qG+rJ/0+I3KdFi2C4mLHj8/L82XuXKfFETen0hW5Tj/+CIWFjh9vGHDihPPyiHvT9IJIJdjtdr777jv279/PgQMHOHDgAKtXdweGU5kxTGiosxKKu1PpipShsLCQI0eOlJTrpe+HDh2ifv36tG3blltuuYWuXbvSvn1npkwxVyg4okYN6NfPufnFfdmMCmb/O3XqZCQnJ7swjnizoiL44gvYsMFcPtWkCQwZArfcYl2m3NxcDh06VKpYDxw4wNGjR2natGlJuV763qZNG2rWrFnqNQwDmjaFH35w7D1DQuDkSY12vZnNZksxDKNTWY9ppCsu8c47MGWKWbyXllb5+cH06RAZCR9+6Nzyzc7OLinUy0evJ06coHXr1iXF+uCDD9K2bVtuuukmgoKCHHptmw2mTYPHHjOXhFUkNBQSE1W41ZlKV5xuwgR4++0rC6moyPxKSYEuXeDrr+F6LxN76tSpK6YE9u/fT3Z2Nm3atCkp1xEjRtC2bVtatmyJn9/1/28QHw/ffw8vvAC5uQZw5dXAQkPNrcCTJ1/324kH0/SCONWXX5qFdLURIECDBmZxBQRUfJxhGHz//fdXFOuBAwew2+2lpgMufW/atKlLdnx99RUMHLiT3NyOhIT4AlBQAFFRMGkSDBrk9AjiBjS9IJZ56SXHChfM6xR8/rlZ0gDFxcVkZGRcUa4HDx4kNDS0pFCjo6OJj4+nbdu2hIWFWXrN2bCwA4SEDGTPnmNkZPhit8ONN0LLlpZFEjejka44zZEj0L69WaaOCg//kR49xnLgwAEOHz5Mw4YNS41YL33VqVPHecGvw7hx4wgMDOTVV1+1OopYSCNdscQ335hTBZUp3TNn6tC/f38mTJhAREQEoR50xik/P5/58+ezdetWq6OIG1PpitM4ei2CywUHB/PQQw9VfRgXWLp0Ke3ataNVq1ZWRxE3pm3A4jStW5snkSqjRQunRHGJ2bNnM2LECKtjiJtT6YrTRETAzTc7PtytUQPGjXNiICfKyMhg9+7dPPDAA1ZHETen0hWnSUtLIycnER8fxyZ1/f3h9793cignmTNnDkOGDHF4Q4VUXypdqXIFBQW8+OKL9O7dm8TEm/jzn4MICan4OaGhsGoVeGJnFRUV8cEHH2hqQRyiE2lSpXbs2MGjjz5Kq1at2L17N40bN8YwoHlzeOUV8+TapdvZ+PiYJXvjjfDRR9e/G80qK1eupFmzZkRFRVkdRTyASleqRG5uLs8//zwfffQRM2bMIC4urmSTgs1mbgV++mnzgt9r15rF27SpuS22Y0eLw1+n2bNnM3LkSKtjiIdQ6cp127RpEyNGjKBLly6kp6dTv379Mo8LDDSvKjZkiIsDOtGPP/5IUlIS//rXv6yOIh5CpSvXLDs7mwkTJrBixQpmzpxJ//79rY7kcnPnzuUPf/gDNWrUsDqKeAidSJNrsnz5ctq1awdAenp6tSxcu92utblSaRrpSqWcPn2aMWPGsG3bNubNm8fdd99tdSTLbNy4kVq1atGpU5lb7EXKpJGuOMQwDBYuXEi7du1o2LAhqamp1bpwAWbNmsXIkSMtvaqZeB6NdOWqfvzxRx5//HG+/fZblixZQpcuXayOZLnTp0+zatUqZs6caXUU8TAa6Uq5DMNgzpw53HrrrXTo0IGUlBQV7s/mz5/P/fff77aXmBT3pZGulOno0aOMGjWK7Oxs1q9fX3LSTMwPo9mzZ2uUK9dEI10ppbi4mBkzZnDbbbdx3333sXXrVhXur2zdupWioiJ69OhhdRTxQBrpSokDBw7w2GOP4e/vz9atW7npppusjuSWLi0T0wk0uRYa6QqFhYX89a9/pWfPngwdOpSNGzeqcMtx7tw5Fi9ezLBhw6yOIh5KI91qbteuXTz66KOEh4eza9cumjZtanUkt7ZgwQJ69+5NWFiY1VHEQ2mk62WKiiArCwoLKz4uLy+PxMRE+vTpw/jx41m+fLkK9zJ2O6xeDb17Q0iIea3funVh6tTa9O37tNXxxIOpdL3A5QURFAQNG5rfu3aFxYvNIr7c5s2bufXWW8nIyCA1NZWHHnpI85OXOXMGOnc2L6i+YYN5Y82iIjh7Fk6deoCEhO5Mnnxt94AT0fSCh8vLg4EDYevWX65TW1xsft++HYYONW+bs3Yt+Pmd57nnnmPx4sW8/fbbDBo0yLrgburCBejRA779trz7uwWQlwczZpjXA375ZVcnFE+nka4Hs9vNwk1K+qVwfy0nB9LSoHPnbKKiYsjNzSU9PV2FW46334bvvrv6DTVzc2HaNMjIcEks8SIqXQ+2dq05wr14seLjCgrg6FE/Hnzwc95//33toiqH3Q7Tp5u/PTh6/NtvOzeTeB+Vrgf7xz/KH+H+mmGEsny5bidTkd27zRGsowoKYP585+UR76TS9VBFRfDVV5V7ztGjcOKEc/J4g9OnzXnayjh3zjlZxHupdD1UTg74+lbuOQEB5nIyKdvV7lhclsDAqs8h3k2l66FCQ69cCnY1hYVQq5Zz8niDjh2vvr75cjYb3HWX0+KIl1Lpeih/f3MtaWU0agTh4c7J4w1CQ2Hw4AvYbI59moWEwLPPOjmUeB2VrgebOBEcvR/ipYLQHoiyGYbBggULWLnyTvz9r166gYEQEwPdurkgnHgVbY7wYAMGQJs2kJpa8bpSPz+44QbQNVrKdurUKR5//HH279/PypXzsNuDuPdec+lYWdMNISHQti0sW6YPMak8jXQ9mJ8frFkDkZHmr8ZlCQmB5s3h66/LP6Y6+/zzz2nfvj0tW7Zk165ddO7cmS5dzA+y0aPN/2a1asFvfmP+c/Pm5lK9zZuhZk2r04snshkVbCDv1KmTkZyc7MI4ci0KCuDjj2Hs2EyysuoREuJHYaE5hzthgrkVWIVb2tmzZ3nyySfZvn07c+fO5Y477ijzuNxc2LfP/N6gAdxyi0a3cnU2my3FMIwybxOt6QUvEBBgFuubb/Zlzpx3iIjoQs2a5kkzFcSVVqxYwahRoxg8eDB79uwhtIJPpJCQyp+wFKmIStdL/PTTTxw+fJg+fToQEGB1Gvd07tw5nnnmGTZs2MD8+fOr/S3kxRqa0/USGzdupHv37gSoccu0fv162rdvj6+vL6mpqSpcsYxGul5i3bp1xMbGWh3D7eTk5DBx4kS++OILZs2axX333Wd1JKnmNNL1EuvXr6d3795Wx3ArSUlJREdHk5OTQ2pqqgpX3IJGul7g+PHjZGVl6VbpP8vLy2PKlCksWLCAmTNnMnDgQKsjiZTQSNcLrF+/nl69euFT2UtkeaEdO3bQsWNHvv/+e1JTU1W44nY00vUCmlqA/Px8XnrpJWbPns1bb71FXFyc1ZFEyqShkYczDKPal+6ePXvo3Lkz6enp7N27V4Urbk2l6+H2799PcHAwLVu2tDqKyxUWFvLyyy9z7733Mn78eJYsWUKjRo2sjiVSIU0veLjqOsrdt28fw4YNo169euzatYsmTZpYHUnEIRrperjqVrrFxcX84x//4K677mLUqFGsWrVKhSseRSNdD1ZUVMRXX33FrFmzrI5yXX76ybw/WXAwNG5c/n3KvvnmG4YPH05gYCA7d+6kRYsWLs0pUhU00vVgycnJNG/enLCwMKujVJrdDl9+CXfcYV7rNyYGIiLMK6O9+iqcOXP5sXbeeustunXrRnx8POvXr1fhisfSSNeDeerUQkEBxMXB2rVw4cIvfwbmhcNfeQWmT4dNmyA0NINHH32U/Px8tmzZws0332xZbpGqoJGuB/PU6y0MHw6rV/9SuL+Wlwdnzhh06XKRmJj76du3L0lJSSpc8Qoa6Xqo3NxckpOT6dmzp9VRKmXfPliyxCzWitnIzfVl4MBNPPtsPVdEE3EJjXQ91H/+8x+io6Op4eidKd3EG29UfD+30vz54ot65OY6M5GIa6l0PZSnTi18+SUUFzt+vK8vbN/uvDwirqbS9VCeehItN7f8e/KV5/x5JwQRsYjmdD3QTz/9xDfffEOXLl2sjlKu4uJijh49Snp6Ovv27Sv5npOzFqjcVt3atZ2TUcQKKl0P5E635rHb7Rw/frxUsaanp3Po0CHCwsKIiooiMjKS/v37M3HiRP7v/+oxZw4UFjr+Hm782SJSaSpdN2cYsGOHuW71q6/Mk1DFxT24444GnD4N9eu7KofBiRMnSE9PL1Wu+/fv5ze/+Q2RkZFERUVx1113kZCQQNu2bcs8yTduHMyd61jpBgTA6NEQGFj1P4+IVWyGUf4cW6dOnYzk5GQXxpHLnTsHAwZASoq5xMpu/+WxwMBibDZfZswwi6kqnTp16oppgfT0dPz9/UtGrpe+R0ZGUqdOnUq9fkICfPABFa5K8PGBhg0hNdV1HywiVcVms6UYhtGprMc00nVTeXlw551w4ADk51/5eH6+LwBjx5r/fi3Fm5WVdUWx7tu3j4KCgpJijYqKIi4ujsjIyCrbbvzmm+aI/d//Nov315/7oaFQt645slfhirfRSNdN/f3v8D//48gmAggKguPHoUGDsh/Pyclh//79V5RrVlZWyWj1UsFGRkYSHh6OzWar2h+oDFu3wj//CV98ATabuZSsVSuYOBHi4yEkxOkRRJyiopGuStcN2e3mRWBOnnTs+OBgmDIFnnkmj4MHD14xes3MzCQiIqJUsUZFRdGsWTO3uK9aUZG5LCw42PwAEfF0Kl0Ps20b3Htv5dan+vn9F1/fm2jduvUV866tWrXC19fXeYFFpBTN6XqYzEzz1+3KCAwM56efzrnFMjIRKZ9K1w0FBVW+dIODfQkI0GhWxN1ZP6EnV4iJKXvFQnlsNuje3Xl5RKTqqHTdUP360KePgc1mv/rBmGf5x493cigRqRIqXTd0/vx5Ll58Drj6cDcgANq1g27dnJ9LRK6fStfNpKSk0LFjR5o2PcuiRTZCQsqf3w0OhptughUrKj8HLCLWUOm6CcMwmDFjBn369OGVV17hvffeY/DgILZsgYEDzZNrtWqZXzVrmlMQzz1nXpehkrtwRcRCWr3gBk6fPs0jjzxCZmYm27Zto2XLliWPRUfD4sXmRonkZHOHWliYOZ2gpbcinkela7Gvv/6aIUOGEB8fz2effVbuOtuwMOjb18XhRKTKqXQtUlxczCuvvMK7777L+++/T58+fayOJCIuoNK1wA8//MCQIUPw8fEhJSWF8PBwqyOJiIvoRJqLLV++nJiYGGJjY1m7dq0KV6Sa0UjXRQoKCkhMTGTRokV8+umn9OjRw+pIImIBla4LHDlyhPj4eJo0acKePXuoW7eu1ZFExCKaXnCyBQsWcPvttzNs2DAWL16swhWp5jTSdZILFy7w1FNPkZSUxJo1a+jQoYPVkUTEDWik6wRpaWl07tyZwsJCUlJSVLgiUkKlW4UMw+Ddd9+lV69eJCYm8uGHH1KzZk2rY4mIG9H0QhXJyspi5MiRHD58mM2bNxMREWF1JBFxQxrpVoFt27bRoUMHGjVqxLZt21S4IlIujXSvg91uZ9q0afzzn//kvffeY9CgQVZHEhE3p9K9RpmZmQwdOpQLFy6wc+dOmjVrZnUkEfEAml64BuvWraNDhw507tyZTZs2qXBFxGEa6f7s4EHYswcKC6FZM+jRA3x+9ZFUWFjICy+8wLx585g/fz69e/e2JqyIeKxqX7orV8LUqbB/P/j5gWGYt74JCYFx42DMGPD3h2PHjvGnP/2JmjVrsnv3bsLCwqyOLiIeqFpPL/ztb/D730NKinlHhvPnISfH/J6ZCS++CL17w8cfL6Fz584MGjSIFStWqHBF5JpV25Hu4sXw8suQm1v+Mbm5sGVLAbt2+bJ+/Zd06dLFdQFFxCtVy9I1DJgwoeLCvaS4OICiov6Eh+t2uyJy/arl9MKOHXDihOPHG4aNt992Xh4RqT6qbekWFTl+fEEBbNjgvDwiUn1Uy9K9eBHs9so9Jz/fOVlEpHqplqV7ww0QGFi55zRt6pwsIlK9VMvSvf9+KC52/PiaNWH0aOflEZHqo1qWbq1aEBt7Cihw6PigIOjb17mZRKR6qHalaxgG06dPZ8uWO6hfvwi/qyyaCwmBzz4DX1/X5BMR71at1umeOXOG4cOHc/LkSXbuXE1ISAj33QeHD5trdg3jl2Nr1DCLdskS8zoMIiJVodqMdDdv3kyHDh2IiIggKSmJG2+8kYYNYdcuWLMGBg0yL3QTHg633QbvvWduBb7rLquTi4g38fqRrt1u5+9//ztvvvkms2fPpn///qUet9mgWzf4/HOLAopIteLVpZuZmcnDDz9MXl4eycnJNGnSxOpIIlLNee30wvr16+nYsSO33XYbGzduVOGKiFvwupFucXExL730ErNmzWLevHncc889VkcSESnhVaX7ww8/MGTIEHx9fdm1axeNGjWyOpKISCleM72wcuVKYmJiiI2NZc2aNSpcEXFLHj/SLSwsZMqUKfz73//mk08+oWfPnlZHEhEpl0eX7rFjx/jjH/9I7dq12bVrFw0aNLA6kohIhTx2emHp0qXcdtttPPDAAyxbtkyFKyIeweNGuvn5+UycOJElS5awZMkSbr/9dqsjiYg4zD1KNysL5s2D9evN2/I2awaPPQa3325uGfvZt99+S1xcHE2bNmX37t3UqVPHwtAiIpVnbekWF8Ozz8LMmeDj88udIm02WLjQvNr4p5/CrbfyySef8Je//IXnn3+ehIQEbDbdKFJEPI91pWu3w4MPwqpV5v1zLmcYcOECHDmC0b07r/32t7y/dy+rVq0iJibGmrwiIlXAutKdNcss3KvcB9124QIJy5aR8OOP1KpXz0XhREScw5rVC4YBr7121cK9pGZgILU2bnRyKBER57OmdHfsgDNnHD7cdv48vPGGEwOJiLiGNaV79GipVQkOychwThYREReypnR9ruFttVpBRLyANaXbtm3l7oEOEBXlnCwiIi5kTem2awetWjl+fI0aMG6c8/KIiLiIdddeePFF8/7mV+PjA2FhEBvr9EgiIs5mXekOHgxPPFFx8fr6Qp06sHbttc0Di4i4GWub7PXXYfp0aNAAatb85c8DA82ve+6BPXugZUvrMoqIVCHrL3gzejSMGAGrV8PWreaGiSZNzC3CjRtbnU5EpEpZX7pgTiP07Wt+iYh4MU2Uioi4kEpXRMSFVLoiIi6k0hURcSGVroiIC6l0RURcSKUrIuJCKl0RERdS6YqIuJBKV0TEhVS6IiIuZDMMo/wHbbZTwDHXxRER8QrNDcNoUNYDFT0dkJgAAAAnSURBVJauiIhULU0viIi4kEpXRMSFVLoiIi6k0hURcSGVroiIC/0/Xl7r4RuekHkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "torch.manual_seed(6)\n",
        "task='node'\n",
        "#explainer=GCNPolicy(1,32,1,task=task)\n",
        "temp=10\n",
        "testdat=[]\n",
        "\n",
        "discount=1\n",
        "num_gennode_features=7\n",
        "num_hidden_features=64\n",
        "  \n",
        "#for classes in range(2):\n",
        "  #model = GNNStack(max(3, 1), 32, 2, task=task)\n",
        "\n",
        "loss1=nn.BCELoss()\n",
        "newdegree=2 # This is the Maxdeg parameter\n",
        "rollout=3\n",
        "numepisodes=10\n",
        "\n",
        "for j in range(len(lisdataset)):#len(lisdataset)\n",
        "  data=lisdataset[j]\n",
        "  num_gennodes=len(data.y)\n",
        "  explainer=GCNPolicy()\n",
        "  opt = torch.optim.Adam(explainer.parameters(), lr=1e-2)\n",
        "  classes=classid[j]\n",
        "\n",
        "  #explainer.train()\n",
        "  \n",
        "  for epoch in range(30):\n",
        "      data=lisdataset[j]\n",
        "      geph=nx.Graph()\n",
        "      G=nx.Graph()\n",
        "      geph=graphlist[j]\n",
        "      G.add_nodes_from(geph)\n",
        "      G.add_edges_from(geph.edges)\n",
        "      #newdegree=2\n",
        "      \n",
        "      label=data.y\n",
        "      newmask=torch.ones(num_gennodes-1)\n",
        "      Actions=[]\n",
        "      Rewards=[]\n",
        "      States=[]\n",
        "      DiscountedReturns=[]\n",
        "\n",
        "      loss=0\n",
        "      \n",
        "      #print(label)\n",
        "      for episodes in range(numepisodes):\n",
        "        data=lisdataset[j]\n",
        "        geph=nx.Graph()\n",
        "        G=nx.Graph()\n",
        "        geph=graphlist[j]\n",
        "        G.add_nodes_from(geph)\n",
        "        G.add_edges_from(geph.edges)\n",
        "      #newdegree=2\n",
        "      \n",
        "        label=data.y\n",
        "        Rewards=[]\n",
        "        newmask=torch.ones(num_gennodes-1)\n",
        "\n",
        "        for k in range(newdegree):\n",
        "          #plt.figure()\n",
        "          #nx.draw_networkx(G, node_size=150,with_labels=True, node_color='pink')\n",
        "        \n",
        "          rollmask=torch.ones(num_gennodes-1)\n",
        "          print(\"for loop newdegree counter\")\n",
        "          print(k)\n",
        "          output=explainer(data)\n",
        "          States.append(data)\n",
        "          print(\"softmax\")\n",
        "        \n",
        "          print(output)\n",
        "          #o=output.numpy()\n",
        "          #o=np.multiply(o,newmask)\n",
        "          #target=output*newmask\n",
        "          #output=output*newmask\n",
        "          #print(output)\n",
        "          m = Categorical(output)\n",
        "          #print(m)\n",
        "          action = m.sample()\n",
        "          print(\"explainer output\")\n",
        "          print(action)\n",
        "          Actions.append(action)\n",
        "          a=action.item()\n",
        "          #output=output*newmask\n",
        "\n",
        "          rollmask[a]=0\n",
        "          G.add_edge(a,num_gennodes-1)\n",
        "          deg1=G.degree()\n",
        "          #print(\"degree of G while entering for loop\")\n",
        "          #print(deg1)\n",
        "          reward=0\n",
        "          #for r in range(rollout):\n",
        "            #V=nx.Graph()\n",
        "            #V.add_nodes_from(G)\n",
        "            #V.add_edges_from(G.edges)\n",
        "            #degroll=V.degree()\n",
        "            #print(\"degree of V before rollout\")\n",
        "            #print(degroll)\n",
        "            #degroll=list(degroll)\n",
        "            #degroll.sort(key=takeFirst)\n",
        "            #print(degroll)\n",
        "            #degroll=[degroll[i][1] for i in range(num_gennodes)]\n",
        "            #degcounter=degroll[num_gennodes-1]\n",
        "            #degroll=torch.FloatTensor(degroll)\n",
        "            #degroll=torch.reshape(deg,(num_gennodes,1))\n",
        "            #rolldata=pyg_utils.from_networkx(V)\n",
        "            #rolldata.x=degroll\n",
        "            #plt.figure()\n",
        "            #nx.draw_networkx(V, node_size=150,with_labels=True, node_color='white')\n",
        "          \n",
        "            #if(k!=newdegree-1):\n",
        "              #rolloutput=explainer(rolldata)\n",
        "              #rolloutput=rolloutput*rollmask\n",
        "              #rollm=Categorical(rolloutput)\n",
        "              #rollaction=rollm.sample()\n",
        "              #rollaction=rollaction.item()\n",
        "              #print(\"rollout action\")\n",
        "              #print(rollaction)\n",
        "              #V.add_edge(rollaction,num_gennodes-1)\n",
        "            #degroll=V.degree()\n",
        "            #degroll=list(degroll)\n",
        "            #degroll.sort(key=takeFirst)\n",
        "            #print(\"degree of V after rollout\")\n",
        "            #print(degroll)\n",
        "            #degroll=[degroll[i][1] for i in range(num_gennodes)]\n",
        "            #degroll=torch.FloatTensor(degroll)\n",
        "            #degroll=torch.reshape(deg,(num_gennodes,1))\n",
        "            #rolldata=pyg_utils.from_networkx(V)\n",
        "            #rolldata.x=degroll\n",
        "            #rollemb,classifierreward,rollpred=model(rolldata)\n",
        "            #pred=rollpred.argmax(dim=1)\n",
        "            #reward+=(classifierreward[num_gennodes-1][classes]-0.5)*100\n",
        "            #plt.figure()\n",
        "            #nx.draw_networkx(V, node_size=150,with_labels=True, node_color='yellow')\n",
        "            #pred.eq(label).sum().item()+\n",
        "            #pred.eq(label).sum().item()\n",
        "          #reward=reward/rollout\n",
        "         \n",
        "        \n",
        "          \n",
        "          \n",
        "         \n",
        "          expnewdata=pyg_utils.from_networkx(G)\n",
        "          expnewdata.x=data.x\n",
        "          expnewdata.y=data.y\n",
        "          data=expnewdata\n",
        "          #print(data.x)\n",
        "          #if(k!=newdegree-1):\n",
        "            #reward=0\n",
        "          #else:\n",
        "          rollemb,classifierreward,rollpred=model(data)\n",
        "            #print(classifierreward)\n",
        "          reward=(classifierreward[num_gennodes-1][classes]-0.5)\n",
        "         \n",
        "         \n",
        "          Rewards.append(reward)\n",
        "          #emb1,rew1,pred1=model(data)\n",
        "          #pred=pred1.argmax(dim=1)\n",
        "          #reward2=(rew1[num_gennodes-1][classes]-0.5)\n",
        "          #reward2=0\n",
        "          #pred.eq(label).sum().item()+\n",
        "          #reward=reward+reward2\n",
        "          #opt.zero_grad()\n",
        "          #loss+=-m.log_prob(action)*(reward)\n",
        "          #if(epoch%10==0):\n",
        "          #print(\"loss\")\n",
        "          #print(loss)\n",
        "     #compute discounted returns\n",
        "      #DiscountedReturns=[]\n",
        "        for t in range(len(Rewards)):\n",
        "          print(\"reward\")\n",
        "          print(len(Rewards))\n",
        "          sum=0.0\n",
        "          for v,r in enumerate(Rewards[t:]):\n",
        "            sum+=r\n",
        "          DiscountedReturns.append(sum)\n",
        "      #print(\"DiscountedReturns\")\n",
        "      #print(DiscountedReturns)\n",
        "      print(Rewards)\n",
        "      #for x in range(1):\n",
        "        \n",
        "        #print(\"enter loss calculation\")\n",
        "        #States=torch.FloatTensor(States)\n",
        "        #probs=explainer(States)\n",
        "        #dist=torch.distributions.Categorical(probs=probs)\n",
        "        #log_prob = dist.log_prob(Actions)\n",
        "        #loss=-(log_prob*DiscountedReturns).sum()/num_episodes\n",
        "        #opt.zero_grad()\n",
        "        #opt.step()\n",
        "\n",
        "\n",
        "      loss=0\n",
        "      print(\"DiscountedReturns\")\n",
        "      print(len(DiscountedReturns))\n",
        "      DiscountedReturns=torch.tensor(DiscountedReturns)\n",
        "      DiscountedReturns=(DiscountedReturns-DiscountedReturns.mean())/(DiscountedReturns.std()+1e-9)\n",
        "      #compute baseline for advantage functions\n",
        "      b1=0\n",
        "      b2=0\n",
        "      ele=0\n",
        "      ele1=0\n",
        "      Advantage=[]\n",
        "      countstep=0\n",
        "      while(ele<len(DiscountedReturns)):\n",
        "        if(ele%2==0):\n",
        "          b1+=DiscountedReturns[ele]\n",
        "          countstep+=1\n",
        "        else:\n",
        "          b2+=DiscountedReturns[ele]\n",
        "        ele+=1\n",
        "      b1=b1/countstep\n",
        "      b2=b2/countstep\n",
        "      while(ele1<len(DiscountedReturns)):\n",
        "        if(ele1%2==0):\n",
        "         Advantage.append(DiscountedReturns[ele1]-b1)\n",
        "        else:\n",
        "          Advantage.append(DiscountedReturns[ele1]-b2)\n",
        "        ele1+=1\n",
        "      print(\"Advantage Function\")\n",
        "      print(len(Advantage))\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "      for State, Action, R in zip(States, Actions, DiscountedReturns):\n",
        "        print(\"return\")\n",
        "        print(R)\n",
        "        probs = explainer(State)\n",
        "        dist = torch.distributions.Categorical(probs=probs)    \n",
        "        log_prob = dist.log_prob(Action)\n",
        "        \n",
        "        loss+= - log_prob*R\n",
        "        \n",
        "      newloss=loss/numepisodes\n",
        "      print(\"loss\")\n",
        "      print(newloss)\n",
        "      opt.zero_grad()\n",
        "      newloss.backward()\n",
        "      opt.step()\n",
        "\n",
        "  \n",
        "  #nx.draw_networkx(G, node_size=150,with_labels=False, node_color=color_map)\n",
        "  testdat.append(data)\n",
        "  plt.figure(j)\n",
        "  nx.draw_networkx(G, node_size=150,node_color=label,cmap=cmap,vmin=0,vmax=6,with_labels=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x7JyPuPSwba",
        "outputId": "f59c04e5-718c-4274-b306-effa15d1117d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.5924e-14, 2.1695e-08, 1.0000e+00, 6.6313e-14, 3.6795e-11, 4.3781e-15,\n",
            "        5.3888e-12], grad_fn=<SelectBackward0>)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2])\n",
            "tensor([3.4214e-02, 6.7425e-04, 1.3966e-04, 9.3660e-01, 7.3219e-04, 2.7348e-02,\n",
            "        2.9546e-04], grad_fn=<SelectBackward0>)\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 3])\n",
            "tensor([3.8277e-03, 1.4830e-06, 1.4512e-07, 2.3828e-06, 1.1164e-05, 9.9572e-01,\n",
            "        4.3709e-04], grad_fn=<SelectBackward0>)\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 2, 2, 5])\n",
            "tensor([2.1275e-01, 1.5358e-02, 4.1900e-04, 4.9417e-04, 1.3672e-01, 1.0710e-01,\n",
            "        5.2717e-01], grad_fn=<SelectBackward0>)\n",
            "tensor([0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 6])\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(testdat)):\n",
        "  rolldata=testdat[i]\n",
        "  rollemb,classifierreward,rollpred=model(rolldata)\n",
        "  #print(rollpred)\n",
        "  print(classifierreward[-1])\n",
        "  print(rollpred.argmax(dim=1))"
      ]
    }
  ]
}
